2025-02-17 14:20:16,773 - INFO - Using device: cpu
2025-02-17 14:20:21,803 - INFO - BiRefNet model loaded successfully
2025-02-17 14:20:50,679 - INFO - Using device: cpu
2025-02-17 14:20:55,654 - INFO - BiRefNet model loaded successfully
2025-02-17 14:21:22,610 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 14:21:22,619 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 14:21:53,641 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 31.02s
2025-02-17 14:21:53,643 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 31.03s
2025-02-17 14:24:50,529 - INFO - Method: GET Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 14:24:50,539 - INFO - Method: GET Path: /remove-background/ Status: 405 Duration: 0.00s
2025-02-17 14:24:55,485 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 14:24:55,491 - INFO - Method: POST Path: /remove-background/ Status: 422 Duration: 0.00s
2025-02-17 14:25:04,934 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 14:25:04,940 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 14:25:31,714 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 26.77s
2025-02-17 14:25:31,715 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 26.78s
2025-02-17 14:26:58,424 - ERROR - CUDA is not available. This will significantly impact performance!
2025-02-17 14:26:58,425 - INFO - Using device: cpu
2025-02-17 14:27:02,973 - INFO - BiRefNet model loaded successfully
2025-02-17 14:36:49,765 - ERROR - CUDA is not available. This will significantly impact performance!
2025-02-17 14:36:49,766 - INFO - Using device: cpu
2025-02-17 14:36:54,545 - INFO - BiRefNet model loaded successfully
2025-02-17 14:37:48,689 - INFO - Python version: 3.12.2
2025-02-17 14:37:48,689 - INFO - PyTorch version: 2.6.0+cpu
2025-02-17 14:37:48,690 - INFO - CUDA available: False
2025-02-17 14:37:48,690 - INFO - CUDA version: Not available
2025-02-17 14:37:48,691 - ERROR - CUDA is not available. This could be due to:
2025-02-17 14:37:48,691 - ERROR - 1. No NVIDIA GPU present
2025-02-17 14:37:48,692 - ERROR - 2. NVIDIA drivers not installed
2025-02-17 14:37:48,692 - ERROR - 3. PyTorch not built with CUDA support
2025-02-17 14:37:48,693 - ERROR - 4. CUDA toolkit not installed
2025-02-17 14:37:48,693 - INFO - Final device selection: cpu
2025-02-17 14:37:53,764 - INFO - BiRefNet model loaded successfully
2025-02-17 14:42:40,378 - INFO - Python version: 3.12.2
2025-02-17 14:42:40,379 - INFO - PyTorch version: 2.6.0+cpu
2025-02-17 14:42:40,379 - INFO - CUDA available: False
2025-02-17 14:42:40,379 - INFO - CUDA version: Not available
2025-02-17 14:42:40,379 - ERROR - CUDA is not available. This could be due to:
2025-02-17 14:42:40,381 - ERROR - 1. No NVIDIA GPU present
2025-02-17 14:42:40,381 - ERROR - 2. NVIDIA drivers not installed
2025-02-17 14:42:40,381 - ERROR - 3. PyTorch not built with CUDA support
2025-02-17 14:42:40,382 - ERROR - 4. CUDA toolkit not installed
2025-02-17 14:42:40,382 - INFO - Final device selection: cpu
2025-02-17 14:42:45,839 - INFO - BiRefNet model loaded successfully
2025-02-17 14:43:08,590 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 14:43:08,598 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 14:43:39,046 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 30.45s
2025-02-17 14:43:39,047 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 30.45s
2025-02-17 15:39:45,585 - INFO - Python version: 3.12.2
2025-02-17 15:39:45,586 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:39:45,629 - INFO - CUDA available: True
2025-02-17 15:39:45,630 - INFO - CUDA version: 12.4
2025-02-17 15:39:45,630 - INFO - Number of CUDA devices: 1
2025-02-17 15:39:45,638 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:39:45,638 - INFO -   Memory: 8.00GB
2025-02-17 15:39:45,639 - INFO -   CUDA Capability: 8.6
2025-02-17 15:39:45,844 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:39:45,845 - INFO - Final device selection: cuda
2025-02-17 15:39:53,854 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:39:53,855 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:39:53,856 - INFO - Memory cached: 582.00MB
2025-02-17 15:39:53,856 - INFO - BiRefNet model loaded successfully
2025-02-17 15:41:02,659 - INFO - Python version: 3.12.2
2025-02-17 15:41:02,660 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:41:02,698 - INFO - CUDA available: True
2025-02-17 15:41:02,699 - INFO - CUDA version: 12.4
2025-02-17 15:41:02,700 - INFO - Number of CUDA devices: 1
2025-02-17 15:41:02,704 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:41:02,705 - INFO -   Memory: 8.00GB
2025-02-17 15:41:02,705 - INFO -   CUDA Capability: 8.6
2025-02-17 15:41:02,863 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:41:02,863 - INFO - Final device selection: cuda
2025-02-17 15:41:10,329 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:41:10,330 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:41:10,331 - INFO - Memory cached: 582.00MB
2025-02-17 15:41:10,331 - INFO - BiRefNet model loaded successfully
2025-02-17 15:41:14,154 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:41:14,161 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 15:41:14,171 - ERROR - Error in extract_object: name 'transforms' is not defined
2025-02-17 15:41:14,171 - ERROR - Errror processing 31332d0750de45f5a4ad08afcc785c5b.jpg: name 'transforms' is not defined
2025-02-17 15:41:37,887 - INFO - Python version: 3.12.2
2025-02-17 15:41:37,888 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:41:37,926 - INFO - CUDA available: True
2025-02-17 15:41:37,927 - INFO - CUDA version: 12.4
2025-02-17 15:41:37,927 - INFO - Number of CUDA devices: 1
2025-02-17 15:41:37,931 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:41:37,931 - INFO -   Memory: 8.00GB
2025-02-17 15:41:37,932 - INFO -   CUDA Capability: 8.6
2025-02-17 15:41:38,086 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:41:38,086 - INFO - Final device selection: cuda
2025-02-17 15:41:43,330 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:41:43,331 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:41:43,331 - INFO - Memory cached: 582.00MB
2025-02-17 15:41:43,332 - INFO - BiRefNet model loaded successfully
2025-02-17 15:41:45,423 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:41:45,429 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 15:41:48,093 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 2.66s
2025-02-17 15:41:48,094 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 2.67s
2025-02-17 15:42:12,569 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:42:12,590 - WARNING - Expected boundary character 45, got 97 at index 2
2025-02-17 15:42:12,591 - INFO - Method: POST Path: /remove-background/ Status: 400 Duration: 0.00s
2025-02-17 15:42:33,111 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:42:33,117 - WARNING - Expected boundary character 45, got 97 at index 2
2025-02-17 15:42:33,118 - INFO - Method: POST Path: /remove-background/ Status: 400 Duration: 0.00s
2025-02-17 15:43:00,150 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:43:00,154 - INFO - Processing image: bike.png
2025-02-17 15:43:00,187 - ERROR - Error in extract_object: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
2025-02-17 15:43:00,188 - ERROR - Errror processing bike.png: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
2025-02-17 15:43:16,721 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:43:16,726 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg
2025-02-17 15:43:17,389 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 0.66s
2025-02-17 15:43:17,390 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.66s
2025-02-17 15:44:06,232 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:44:06,253 - INFO - Processing image: AbsoluteTeamsport_RheinPfalz_Bon.jpg
2025-02-17 15:44:06,797 - INFO - Successfully processed AbsoluteTeamsport_RheinPfalz_Bon.jpg in 0.54s
2025-02-17 15:44:06,797 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.55s
2025-02-17 15:44:29,212 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:44:29,216 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png
2025-02-17 15:44:29,241 - ERROR - Error in extract_object: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
2025-02-17 15:44:29,242 - ERROR - Errror processing logo4_eger_rainer_ingenieurbuero.png: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
2025-02-17 15:46:13,938 - INFO - Python version: 3.12.2
2025-02-17 15:46:13,938 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:46:13,974 - INFO - CUDA available: True
2025-02-17 15:46:13,974 - INFO - CUDA version: 12.4
2025-02-17 15:46:13,975 - INFO - Number of CUDA devices: 1
2025-02-17 15:46:13,981 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:46:13,982 - INFO -   Memory: 8.00GB
2025-02-17 15:46:13,982 - INFO -   CUDA Capability: 8.6
2025-02-17 15:46:14,158 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:46:14,159 - INFO - Final device selection: cuda
2025-02-17 15:46:21,463 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:46:21,464 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:46:21,465 - INFO - Memory cached: 582.00MB
2025-02-17 15:46:21,466 - INFO - BiRefNet model loaded successfully
2025-02-17 15:46:31,381 - INFO - Python version: 3.12.2
2025-02-17 15:46:31,381 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:46:31,416 - INFO - CUDA available: True
2025-02-17 15:46:31,417 - INFO - CUDA version: 12.4
2025-02-17 15:46:31,418 - INFO - Number of CUDA devices: 1
2025-02-17 15:46:31,422 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:46:31,423 - INFO -   Memory: 8.00GB
2025-02-17 15:46:31,423 - INFO -   CUDA Capability: 8.6
2025-02-17 15:46:31,583 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:46:31,584 - INFO - Final device selection: cuda
2025-02-17 15:46:37,461 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:46:37,462 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:46:37,463 - INFO - Memory cached: 582.00MB
2025-02-17 15:46:37,464 - INFO - BiRefNet model loaded successfully
2025-02-17 15:46:37,480 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:46:37,485 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png
2025-02-17 15:46:40,222 - INFO - Successfully processed logo4_eger_rainer_ingenieurbuero.png in 2.74s
2025-02-17 15:46:40,223 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 2.74s
2025-02-17 15:46:51,649 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:46:51,654 - WARNING - Expected boundary character 45, got 230 at index 2
2025-02-17 15:46:51,655 - INFO - Method: POST Path: /remove-background/ Status: 400 Duration: 0.00s
2025-02-17 15:51:24,799 - INFO - Python version: 3.12.2
2025-02-17 15:51:24,800 - INFO - PyTorch version: 2.6.0+cu124
2025-02-17 15:51:24,834 - INFO - CUDA available: True
2025-02-17 15:51:24,834 - INFO - CUDA version: 12.4
2025-02-17 15:51:24,835 - INFO - Number of CUDA devices: 1
2025-02-17 15:51:24,839 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-02-17 15:51:24,839 - INFO -   Memory: 8.00GB
2025-02-17 15:51:24,840 - INFO -   CUDA Capability: 8.6
2025-02-17 15:51:24,979 - INFO - CUDA test successful - tensor operation completed
2025-02-17 15:51:24,980 - INFO - Final device selection: cuda
2025-02-17 15:51:30,563 - INFO - Model loaded on GPU. Memory allocated: 442.87MB
2025-02-17 15:51:30,563 - INFO - Max memory allocated: 851.77MB
2025-02-17 15:51:30,564 - INFO - Memory cached: 582.00MB
2025-02-17 15:51:30,565 - INFO - BiRefNet model loaded successfully
2025-02-17 15:51:32,236 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:51:32,241 - WARNING - Expected boundary character 45, got 97 at index 2
2025-02-17 15:51:32,242 - INFO - Method: POST Path: /remove-background/ Status: 400 Duration: 0.00s
2025-02-17 15:53:44,536 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:53:44,541 - INFO - Processing image: signal-2023-02-04-212737.jpeg
2025-02-17 15:53:47,810 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 3.27s
2025-02-17 15:53:47,811 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 3.27s
2025-02-17 15:54:42,011 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 15:54:42,017 - INFO - Processing image: 0_0.jpeg
2025-02-17 15:54:43,135 - INFO - Successfully processed 0_0.jpeg in 1.12s
2025-02-17 15:54:43,137 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.12s
2025-02-17 16:19:14,378 - INFO - Method: POST Path: /remove-background Status: 307 Duration: 0.00s
2025-02-17 16:19:14,384 - INFO - Processing image: omnitraklogo.png
2025-02-17 16:19:14,936 - INFO - Successfully processed omnitraklogo.png in 0.55s
2025-02-17 16:19:14,937 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.56s
2025-03-09 13:33:53,011 - INFO - Python version: 3.12.2
2025-03-09 13:33:53,012 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:33:53,012 - INFO - CUDA available: True
2025-03-09 13:33:53,012 - INFO - CUDA version: 12.4
2025-03-09 13:33:53,013 - INFO - Number of CUDA devices: 1
2025-03-09 13:33:53,018 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:33:53,019 - INFO -   Memory: 8.00GB
2025-03-09 13:33:53,019 - INFO -   CUDA Capability: 8.6
2025-03-09 13:33:53,139 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:33:53,139 - INFO - Final device selection: cuda
2025-03-09 13:33:53,206 - INFO - Starting Background Removal API server
2025-03-09 13:33:59,536 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:33:59,541 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:34:08,497 - INFO - Created new instance of birefnet
2025-03-09 13:34:08,498 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 5.91s
2025-03-09 13:34:08,502 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:34:33,859 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png with model: birefnet
2025-03-09 13:34:35,097 - ERROR - Error processing logo4_eger_rainer_ingenieurbuero.png: Error processing image:  Error while processing rearrange-reduction pattern "b c (hg h) (wg w) -> b (c hg wg) h w".
 Input tensor shape: torch.Size([1, 3, 217, 441]). Additional info: {'hg': 31, 'wg': 31}.
 Shape mismatch, can't divide axis of length 441 in chunks of 31
2025-03-09 13:34:35,098 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 1.24s
2025-03-09 13:34:46,714 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg with model: birefnet
2025-03-09 13:34:46,890 - ERROR - Error processing 31332d0750de45f5a4ad08afcc785c5b.jpg: Error processing image:  Error while processing rearrange-reduction pattern "b c (hg h) (wg w) -> b (c hg wg) h w".
 Input tensor shape: torch.Size([1, 3, 168, 146]). Additional info: {'hg': 28, 'wg': 29}.
 Shape mismatch, can't divide axis of length 146 in chunks of 29
2025-03-09 13:34:46,891 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.18s
2025-03-09 13:35:02,447 - INFO - Processing image: AbsoluteTeamsport_RheinPfalz_Bon.jpg with model: birefnet
2025-03-09 13:35:02,653 - ERROR - Error processing AbsoluteTeamsport_RheinPfalz_Bon.jpg: Error processing image:  Error while processing rearrange-reduction pattern "b c (hg h) (wg w) -> b (c hg wg) h w".
 Input tensor shape: torch.Size([1, 3, 116, 464]). Additional info: {'hg': 29, 'wg': 30}.
 Shape mismatch, can't divide axis of length 464 in chunks of 30
2025-03-09 13:35:02,655 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.21s
2025-03-09 13:38:15,182 - INFO - Method: GET Path: /models/birefnet/info Status: 404 Duration: 0.00s
2025-03-09 13:38:29,376 - INFO - Processing image: AbsoluteTeamsport_RheinPfalz_Bon.jpg with model: birefnet
2025-03-09 13:38:29,657 - ERROR - Error processing AbsoluteTeamsport_RheinPfalz_Bon.jpg: Error processing image:  Error while processing rearrange-reduction pattern "b c (hg h) (wg w) -> b (c hg wg) h w".
 Input tensor shape: torch.Size([1, 3, 116, 464]). Additional info: {'hg': 29, 'wg': 30}.
 Shape mismatch, can't divide axis of length 464 in chunks of 30
2025-03-09 13:38:29,658 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.28s
2025-03-09 13:39:03,348 - INFO - Python version: 3.12.2
2025-03-09 13:39:03,348 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:39:03,349 - INFO - CUDA available: True
2025-03-09 13:39:03,349 - INFO - CUDA version: 12.4
2025-03-09 13:39:03,350 - INFO - Number of CUDA devices: 1
2025-03-09 13:39:03,353 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:39:03,353 - INFO -   Memory: 8.00GB
2025-03-09 13:39:03,353 - INFO -   CUDA Capability: 8.6
2025-03-09 13:39:03,447 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:39:03,447 - INFO - Final device selection: cuda
2025-03-09 13:39:03,574 - INFO - Starting Background Removal API server
2025-03-09 13:41:02,659 - INFO - Python version: 3.12.2
2025-03-09 13:41:02,660 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:41:02,660 - INFO - CUDA available: True
2025-03-09 13:41:02,660 - INFO - CUDA version: 12.4
2025-03-09 13:41:02,660 - INFO - Number of CUDA devices: 1
2025-03-09 13:41:02,664 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:41:02,664 - INFO -   Memory: 8.00GB
2025-03-09 13:41:02,664 - INFO -   CUDA Capability: 8.6
2025-03-09 13:41:02,771 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:41:02,771 - INFO - Final device selection: cuda
2025-03-09 13:41:02,891 - INFO - Starting Background Removal API server
2025-03-09 13:41:15,135 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png with model: birefnet
2025-03-09 13:41:19,476 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-09 13:41:19,530 - INFO - Created new instance of birefnet
2025-03-09 13:41:19,536 - INFO - Original image size: (441, 217), mode: RGBA
2025-03-09 13:41:19,536 - INFO - Resizing image from (441, 217) to (450, 240) to ensure dimensions are multiples of 30
2025-03-09 13:41:19,544 - INFO - Converting RGBA image to RGB with white background
2025-03-09 13:41:19,546 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 240, 450])
2025-03-09 13:41:19,546 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:41:19,547 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 240, 450])
2025-03-09 13:41:20,235 - ERROR - Prediction failed with error: Given groups=1, weight of size [64, 3072, 3, 3], expected input[1, 2700, 8, 15] to have 3072 channels, but got 2700 channels instead
2025-03-09 13:41:20,236 - ERROR - Error processing logo4_eger_rainer_ingenieurbuero.png: Error processing image: 'Config' object has no attribute 'get'
2025-03-09 13:41:20,237 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 5.10s
2025-03-09 13:44:59,197 - INFO - Python version: 3.12.2
2025-03-09 13:44:59,197 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:44:59,198 - INFO - CUDA available: True
2025-03-09 13:44:59,198 - INFO - CUDA version: 12.4
2025-03-09 13:44:59,199 - INFO - Number of CUDA devices: 1
2025-03-09 13:44:59,202 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:44:59,202 - INFO -   Memory: 8.00GB
2025-03-09 13:44:59,202 - INFO -   CUDA Capability: 8.6
2025-03-09 13:44:59,306 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:44:59,307 - INFO - Final device selection: cuda
2025-03-09 13:44:59,436 - INFO - Starting Background Removal API server
2025-03-09 13:45:03,362 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png with model: birefnet
2025-03-09 13:45:07,635 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-09 13:45:07,683 - INFO - Created new instance of birefnet
2025-03-09 13:45:07,691 - INFO - Original image size: (441, 217), mode: RGBA
2025-03-09 13:45:07,691 - INFO - Resizing image from (441, 217) to (448, 224) to ensure dimensions are multiples of 32
2025-03-09 13:45:07,694 - INFO - Expected patch count: 14x7, patch size: 32x32
2025-03-09 13:45:07,694 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-09 13:45:07,695 - INFO - Converting RGBA image to RGB with white background
2025-03-09 13:45:07,697 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 224, 448])
2025-03-09 13:45:07,697 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:45:07,697 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 224, 448])
2025-03-09 13:45:08,741 - INFO - Prediction successful, output shape: torch.Size([1, 1, 224, 448])
2025-03-09 13:45:08,750 - INFO - Successfully processed logo4_eger_rainer_ingenieurbuero.png in 5.39s
2025-03-09 13:45:08,751 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 5.39s
2025-03-09 13:45:56,241 - ERROR - Failed to create model ben2: BEN2 model requires ben2 package. Please install it first.
2025-03-09 13:45:56,242 - INFO - Method: POST Path: /models/ben2/load Status: 404 Duration: 0.00s
2025-03-09 13:46:04,265 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-09 13:46:04,266 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.51s
2025-03-09 13:46:41,486 - ERROR - Failed to create model ben2: BEN2 model requires ben2 package. Please install it first.
2025-03-09 13:46:41,486 - INFO - Method: POST Path: /models/ben2/load Status: 404 Duration: 0.00s
2025-03-09 13:48:45,715 - INFO - Python version: 3.12.2
2025-03-09 13:48:45,716 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:48:45,716 - INFO - CUDA available: True
2025-03-09 13:48:45,717 - INFO - CUDA version: 12.4
2025-03-09 13:48:45,718 - INFO - Number of CUDA devices: 1
2025-03-09 13:48:45,721 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:48:45,721 - INFO -   Memory: 8.00GB
2025-03-09 13:48:45,722 - INFO -   CUDA Capability: 8.6
2025-03-09 13:48:45,842 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:48:45,842 - INFO - Final device selection: cuda
2025-03-09 13:48:45,961 - INFO - Starting Background Removal API server
2025-03-09 13:48:47,804 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:48:47,808 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:50:24,521 - INFO - Created new instance of ben2
2025-03-09 13:50:24,523 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 89.97s
2025-03-09 13:50:24,527 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:50:31,993 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:50:31,995 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:50:34,799 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:50:34,819 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:50:41,548 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png with model: ben2
2025-03-09 13:50:41,553 - ERROR - Error processing logo4_eger_rainer_ingenieurbuero.png: Error processing image: 'PngImageFile' object has no attribute 'half'
2025-03-09 13:50:41,555 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.01s
2025-03-09 13:51:18,561 - INFO - Processing image: logo4_eger_rainer_ingenieurbuero.png with model: ben2
2025-03-09 13:51:18,562 - ERROR - Error processing logo4_eger_rainer_ingenieurbuero.png: Error processing image: 'PngImageFile' object has no attribute 'half'
2025-03-09 13:51:18,562 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.00s
2025-03-09 13:52:08,310 - INFO - Python version: 3.12.2
2025-03-09 13:52:08,310 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:52:08,311 - INFO - CUDA available: True
2025-03-09 13:52:08,311 - INFO - CUDA version: 12.4
2025-03-09 13:52:08,312 - INFO - Number of CUDA devices: 1
2025-03-09 13:52:08,315 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:52:08,315 - INFO -   Memory: 8.00GB
2025-03-09 13:52:08,315 - INFO -   CUDA Capability: 8.6
2025-03-09 13:52:08,407 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:52:08,408 - INFO - Final device selection: cuda
2025-03-09 13:52:08,531 - INFO - Starting Background Removal API server
2025-03-09 13:52:21,847 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-09 13:52:21,912 - INFO - Created new instance of birefnet
2025-03-09 13:52:21,913 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 4.19s
2025-03-09 13:52:21,918 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:52:27,208 - INFO - Created new instance of ben2
2025-03-09 13:52:27,208 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.60s
2025-03-09 13:52:27,213 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:52:39,980 - INFO - Processing image: 0_0.jpeg with model: ben2
2025-03-09 13:52:41,419 - INFO - Successfully processed 0_0.jpeg in 1.44s
2025-03-09 13:52:41,423 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.44s
2025-03-09 13:52:53,131 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 0.00s
2025-03-09 13:52:53,137 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:53:08,325 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg with model: birefnet
2025-03-09 13:53:08,326 - INFO - Original image size: (146, 168), mode: RGB
2025-03-09 13:53:08,326 - INFO - Resizing image from (146, 168) to (160, 192) to ensure dimensions are multiples of 32
2025-03-09 13:53:08,327 - INFO - Expected patch count: 5x6, patch size: 32x32
2025-03-09 13:53:08,327 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-09 13:53:08,328 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 192, 160])
2025-03-09 13:53:08,329 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:53:08,329 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 192, 160])
2025-03-09 13:53:08,593 - INFO - Prediction successful, output shape: torch.Size([1, 1, 192, 160])
2025-03-09 13:53:08,600 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 0.27s
2025-03-09 13:53:08,601 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.28s
2025-03-09 13:53:16,046 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:53:16,051 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:53:17,031 - INFO - Processing image: 31332d0750de45f5a4ad08afcc785c5b.jpg with model: ben2
2025-03-09 13:53:17,552 - INFO - Successfully processed 31332d0750de45f5a4ad08afcc785c5b.jpg in 0.52s
2025-03-09 13:53:17,552 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.52s
2025-03-09 13:53:23,154 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 0.00s
2025-03-09 13:53:23,171 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:53:39,864 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-09 13:53:39,864 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.30s
2025-03-09 13:53:50,051 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:53:50,074 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:54:02,183 - INFO - Processing image: signal-2024-03-20-111722.jpeg with model: ben2
2025-03-09 13:54:03,494 - INFO - Successfully processed signal-2024-03-20-111722.jpeg in 1.31s
2025-03-09 13:54:03,495 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.31s
2025-03-09 13:54:11,606 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 0.00s
2025-03-09 13:54:11,625 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:54:13,095 - INFO - Processing image: signal-2024-03-20-111722.jpeg with model: birefnet
2025-03-09 13:54:13,096 - INFO - Original image size: (2048, 1536), mode: RGB
2025-03-09 13:54:13,136 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1536, 2048])
2025-03-09 13:54:13,136 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:54:13,151 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1536, 2048])
2025-03-09 13:54:14,492 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1536, 2048])
2025-03-09 13:54:15,477 - INFO - Successfully processed signal-2024-03-20-111722.jpeg in 2.38s
2025-03-09 13:54:15,480 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 2.39s
2025-03-09 13:54:39,460 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:54:39,483 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:54:49,688 - INFO - Processing image: signal-2024-03-20-111722.jpeg with model: ben2
2025-03-09 13:54:51,963 - INFO - Successfully processed signal-2024-03-20-111722.jpeg in 2.28s
2025-03-09 13:54:51,965 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 2.28s
2025-03-09 13:57:17,322 - INFO - Python version: 3.12.2
2025-03-09 13:57:17,323 - INFO - PyTorch version: 2.6.0+cu124
2025-03-09 13:57:17,323 - INFO - CUDA available: True
2025-03-09 13:57:17,323 - INFO - CUDA version: 12.4
2025-03-09 13:57:17,325 - INFO - Number of CUDA devices: 1
2025-03-09 13:57:17,328 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-09 13:57:17,328 - INFO -   Memory: 8.00GB
2025-03-09 13:57:17,329 - INFO -   CUDA Capability: 8.6
2025-03-09 13:57:17,429 - INFO - CUDA test successful - tensor operation completed
2025-03-09 13:57:17,429 - INFO - Final device selection: cuda
2025-03-09 13:57:17,563 - INFO - Starting Background Removal API server
2025-03-09 13:57:20,533 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:57:20,536 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:57:23,339 - INFO - Created new instance of ben2
2025-03-09 13:57:23,339 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.47s
2025-03-09 13:57:23,343 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:57:28,306 - INFO - Processing image: DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp with model: ben2
2025-03-09 13:57:29,760 - INFO - Successfully processed DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp in 1.45s
2025-03-09 13:57:29,763 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.46s
2025-03-09 13:57:37,756 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-09 13:57:37,772 - INFO - Created new instance of birefnet
2025-03-09 13:57:37,773 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 4.11s
2025-03-09 13:57:37,781 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:57:40,178 - INFO - Processing image: DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp with model: birefnet
2025-03-09 13:57:40,179 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-09 13:57:40,267 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-09 13:57:40,267 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:57:40,270 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-09 13:57:40,806 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-09 13:57:41,163 - INFO - Successfully processed DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp in 0.98s
2025-03-09 13:57:41,164 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.99s
2025-03-09 13:57:51,078 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:57:51,100 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:57:53,801 - INFO - Processing image: DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp with model: ben2
2025-03-09 13:57:54,963 - INFO - Successfully processed DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp in 1.16s
2025-03-09 13:57:54,963 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.16s
2025-03-09 13:58:01,816 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 0.00s
2025-03-09 13:58:01,834 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:58:03,571 - INFO - Processing image: DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp with model: birefnet
2025-03-09 13:58:03,572 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-09 13:58:03,595 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-09 13:58:03,595 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:58:03,600 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-09 13:58:04,133 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-09 13:58:04,492 - INFO - Successfully processed DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp in 0.92s
2025-03-09 13:58:04,493 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.92s
2025-03-09 13:58:27,440 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: birefnet
2025-03-09 13:58:27,441 - INFO - Original image size: (931, 966), mode: RGB
2025-03-09 13:58:27,441 - INFO - Resizing image from (931, 966) to (960, 992) to ensure dimensions are multiples of 32
2025-03-09 13:58:27,460 - INFO - Expected patch count: 30x31, patch size: 32x32
2025-03-09 13:58:27,460 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-09 13:58:27,467 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 992, 960])
2025-03-09 13:58:27,467 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:58:27,470 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 992, 960])
2025-03-09 13:58:27,947 - INFO - Prediction successful, output shape: torch.Size([1, 1, 992, 960])
2025-03-09 13:58:28,267 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 0.83s
2025-03-09 13:58:28,267 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.83s
2025-03-09 13:58:37,704 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 13:58:37,726 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:58:39,059 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: ben2
2025-03-09 13:58:40,151 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 1.09s
2025-03-09 13:58:40,151 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.09s
2025-03-09 13:58:47,896 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 0.00s
2025-03-09 13:58:47,900 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 13:58:52,159 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: birefnet
2025-03-09 13:58:52,159 - INFO - Original image size: (931, 966), mode: RGB
2025-03-09 13:58:52,159 - INFO - Resizing image from (931, 966) to (960, 992) to ensure dimensions are multiples of 32
2025-03-09 13:58:52,181 - INFO - Expected patch count: 30x31, patch size: 32x32
2025-03-09 13:58:52,181 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-09 13:58:52,188 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 992, 960])
2025-03-09 13:58:52,188 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-09 13:58:52,194 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 992, 960])
2025-03-09 13:58:52,508 - INFO - Prediction successful, output shape: torch.Size([1, 1, 992, 960])
2025-03-09 13:58:52,825 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 0.67s
2025-03-09 13:58:52,826 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.67s
2025-03-09 14:03:33,319 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 14:03:33,322 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 14:03:33,324 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 14:03:33,328 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 21:43:15,947 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-09 21:43:15,951 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-09 21:43:33,546 - INFO - Processing image: images.png with model: ben2
2025-03-09 21:43:33,969 - INFO - Successfully processed images.png in 0.42s
2025-03-09 21:43:33,969 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.43s
2025-03-10 09:55:49,945 - INFO - Python version: 3.12.2
2025-03-10 09:55:49,946 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 09:55:49,946 - INFO - CUDA available: True
2025-03-10 09:55:49,946 - INFO - CUDA version: 12.4
2025-03-10 09:55:49,947 - INFO - Number of CUDA devices: 1
2025-03-10 09:55:49,951 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 09:55:49,951 - INFO -   Memory: 8.00GB
2025-03-10 09:55:49,951 - INFO -   CUDA Capability: 8.6
2025-03-10 09:55:50,059 - INFO - CUDA test successful - tensor operation completed
2025-03-10 09:55:50,060 - INFO - Final device selection: cuda
2025-03-10 09:55:50,192 - INFO - Starting Background Removal API server
2025-03-10 09:56:13,111 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 09:56:13,115 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 09:56:20,714 - INFO - Created new instance of ben2
2025-03-10 09:56:20,714 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.93s
2025-03-10 09:56:20,719 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 09:56:27,944 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-10 09:56:27,978 - INFO - Created new instance of birefnet
2025-03-10 09:56:27,979 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 4.06s
2025-03-10 09:56:27,982 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 09:56:35,504 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 09:56:35,505 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.25s
2025-03-10 10:01:45,207 - INFO - Python version: 3.12.2
2025-03-10 10:01:45,208 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:01:45,208 - INFO - CUDA available: True
2025-03-10 10:01:45,208 - INFO - CUDA version: 12.4
2025-03-10 10:01:45,210 - INFO - Number of CUDA devices: 1
2025-03-10 10:01:45,213 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:01:45,214 - INFO -   Memory: 8.00GB
2025-03-10 10:01:45,214 - INFO -   CUDA Capability: 8.6
2025-03-10 10:01:45,322 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:01:45,322 - INFO - Final device selection: cuda
2025-03-10 10:01:45,456 - INFO - Starting Background Removal API server
2025-03-10 10:02:02,758 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:02:02,762 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:02:09,327 - INFO - Created new instance of ben2
2025-03-10 10:02:09,328 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.94s
2025-03-10 10:02:09,332 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:02:11,155 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:02:11,155 - INFO - Cache directory exists: True
2025-03-10 10:02:11,155 - INFO - Transformers version: 4.35.2
2025-03-10 10:02:11,187 - INFO - Available AutoModel classes: ['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ALIGN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALIGN_PRETRAINED_MODEL_ARCHIVE_LIST', 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALTCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ALTCLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'ASTConfig', 'ASTFeatureExtractor', 'ASTForAudioClassification', 'ASTModel', 'ASTPreTrainedModel', 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'AUTOFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'AUTOFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'Adafactor', 'AdamW', 'AdamWeightDecay', 'AdaptiveEmbedding', 'AddedToken', 'Agent', 'AlbertConfig', 'AlbertForMaskedLM', 'AlbertForMultipleChoice', 'AlbertForPreTraining', 'AlbertForQuestionAnswering', 'AlbertForSequenceClassification', 'AlbertForTokenClassification', 'AlbertModel', 'AlbertPreTrainedModel', 'AlbertTokenizer', 'AlbertTokenizerFast', 'AlignConfig', 'AlignModel', 'AlignPreTrainedModel', 'AlignProcessor', 'AlignTextConfig', 'AlignTextModel', 'AlignVisionConfig', 'AlignVisionModel', 'AltCLIPConfig', 'AltCLIPModel', 'AltCLIPPreTrainedModel', 'AltCLIPProcessor', 'AltCLIPTextConfig', 'AltCLIPTextModel', 'AltCLIPVisionConfig', 'AltCLIPVisionModel', 'AlternatingCodebooksLogitsProcessor', 'AudioClassificationPipeline', 'AutoBackbone', 'AutoConfig', 'AutoFeatureExtractor', 'AutoImageProcessor', 'AutoModel', 'AutoModelForAudioClassification', 'AutoModelForAudioFrameClassification', 'AutoModelForAudioXVector', 'AutoModelForCTC', 'AutoModelForCausalLM', 'AutoModelForDepthEstimation', 'AutoModelForDocumentQuestionAnswering', 'AutoModelForImageClassification', 'AutoModelForImageSegmentation', 'AutoModelForImageToImage', 'AutoModelForInstanceSegmentation', 'AutoModelForMaskGeneration', 'AutoModelForMaskedImageModeling', 'AutoModelForMaskedLM', 'AutoModelForMultipleChoice', 'AutoModelForNextSentencePrediction', 'AutoModelForObjectDetection', 'AutoModelForPreTraining', 'AutoModelForQuestionAnswering', 'AutoModelForSemanticSegmentation', 'AutoModelForSeq2SeqLM', 'AutoModelForSequenceClassification', 'AutoModelForSpeechSeq2Seq', 'AutoModelForTableQuestionAnswering', 'AutoModelForTextEncoding', 'AutoModelForTextToSpectrogram', 'AutoModelForTextToWaveform', 'AutoModelForTokenClassification', 'AutoModelForUniversalSegmentation', 'AutoModelForVideoClassification', 'AutoModelForVision2Seq', 'AutoModelForVisualQuestionAnswering', 'AutoModelForZeroShotImageClassification', 'AutoModelForZeroShotObjectDetection', 'AutoModelWithLMHead', 'AutoProcessor', 'AutoTokenizer', 'AutoformerConfig', 'AutoformerForPrediction', 'AutoformerModel', 'AutoformerPreTrainedModel', 'AutomaticSpeechRecognitionPipeline', 'AwqConfig', 'AzureOpenAiAgent', 'BARK_PRETRAINED_MODEL_ARCHIVE_LIST', 'BART_PRETRAINED_MODEL_ARCHIVE_LIST', 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIOGPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIOGPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLIP_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST', 'BRIDGETOWER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BRIDGETOWER_PRETRAINED_MODEL_ARCHIVE_LIST', 'BROS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'BROS_PRETRAINED_MODEL_ARCHIVE_LIST', 'BarkCausalModel', 'BarkCoarseConfig', 'BarkCoarseModel', 'BarkConfig', 'BarkFineConfig', 'BarkFineModel', 'BarkModel', 'BarkPreTrainedModel', 'BarkProcessor', 'BarkSemanticConfig', 'BarkSemanticModel', 'BartConfig', 'BartForCausalLM', 'BartForConditionalGeneration', 'BartForQuestionAnswering', 'BartForSequenceClassification', 'BartModel', 'BartPreTrainedModel', 'BartPretrainedModel', 'BartTokenizer', 'BartTokenizerFast', 'BarthezTokenizer', 'BarthezTokenizerFast', 'BartphoTokenizer', 'BasicTokenizer', 'BatchEncoding', 'BatchFeature', 'BeamScorer', 'BeamSearchScorer', 'BeitConfig', 'BeitFeatureExtractor', 'BeitForImageClassification', 'BeitForMaskedImageModeling', 'BeitForSemanticSegmentation', 'BeitImageProcessor', 'BeitModel', 'BeitPreTrainedModel', 'BertConfig', 'BertForMaskedLM', 'BertForMultipleChoice', 'BertForNextSentencePrediction', 'BertForPreTraining', 'BertForQuestionAnswering', 'BertForSequenceClassification', 'BertForTokenClassification', 'BertGenerationConfig', 'BertGenerationDecoder', 'BertGenerationEncoder', 'BertGenerationPreTrainedModel', 'BertGenerationTokenizer', 'BertJapaneseTokenizer', 'BertLMHeadModel', 'BertLayer', 'BertModel', 'BertPreTrainedModel', 'BertTokenizer', 'BertTokenizerFast', 'BertweetTokenizer', 'BigBirdConfig', 'BigBirdForCausalLM', 'BigBirdForMaskedLM', 'BigBirdForMultipleChoice', 'BigBirdForPreTraining', 'BigBirdForQuestionAnswering', 'BigBirdForSequenceClassification', 'BigBirdForTokenClassification', 'BigBirdLayer', 'BigBirdModel', 'BigBirdPegasusConfig', 'BigBirdPegasusForCausalLM', 'BigBirdPegasusForConditionalGeneration', 'BigBirdPegasusForQuestionAnswering', 'BigBirdPegasusForSequenceClassification', 'BigBirdPegasusModel', 'BigBirdPegasusPreTrainedModel', 'BigBirdPreTrainedModel', 'BigBirdTokenizer', 'BigBirdTokenizerFast', 'BioGptConfig', 'BioGptForCausalLM', 'BioGptForSequenceClassification', 'BioGptForTokenClassification', 'BioGptModel', 'BioGptPreTrainedModel', 'BioGptTokenizer', 'BitBackbone', 'BitConfig', 'BitForImageClassification', 'BitImageProcessor', 'BitModel', 'BitPreTrainedModel', 'BitsAndBytesConfig', 'BlenderbotConfig', 'BlenderbotForCausalLM', 'BlenderbotForConditionalGeneration', 'BlenderbotModel', 'BlenderbotPreTrainedModel', 'BlenderbotSmallConfig', 'BlenderbotSmallForCausalLM', 'BlenderbotSmallForConditionalGeneration', 'BlenderbotSmallModel', 'BlenderbotSmallPreTrainedModel', 'BlenderbotSmallTokenizer', 'BlenderbotSmallTokenizerFast', 'BlenderbotTokenizer', 'BlenderbotTokenizerFast', 'Blip2Config', 'Blip2ForConditionalGeneration', 'Blip2Model', 'Blip2PreTrainedModel', 'Blip2Processor', 'Blip2QFormerConfig', 'Blip2QFormerModel', 'Blip2VisionConfig', 'Blip2VisionModel', 'BlipConfig', 'BlipForConditionalGeneration', 'BlipForImageTextRetrieval', 'BlipForQuestionAnswering', 'BlipImageProcessor', 'BlipModel', 'BlipPreTrainedModel', 'BlipProcessor', 'BlipTextConfig', 'BlipTextModel', 'BlipVisionConfig', 'BlipVisionModel', 'BloomConfig', 'BloomForCausalLM', 'BloomForQuestionAnswering', 'BloomForSequenceClassification', 'BloomForTokenClassification', 'BloomModel', 'BloomPreTrainedModel', 'BloomTokenizerFast', 'BridgeTowerConfig', 'BridgeTowerForContrastiveLearning', 'BridgeTowerForImageAndTextRetrieval', 'BridgeTowerForMaskedLM', 'BridgeTowerImageProcessor', 'BridgeTowerModel', 'BridgeTowerPreTrainedModel', 'BridgeTowerProcessor', 'BridgeTowerTextConfig', 'BridgeTowerVisionConfig', 'BrosConfig', 'BrosForTokenClassification', 'BrosModel', 'BrosPreTrainedModel', 'BrosProcessor', 'BrosSpadeEEForTokenClassification', 'BrosSpadeELForTokenClassification', 'ByT5Tokenizer', 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST', 'CHINESE_CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLAP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLIPConfig', 'CLIPFeatureExtractor', 'CLIPImageProcessor', 'CLIPModel', 'CLIPPreTrainedModel', 'CLIPProcessor', 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST', 'CLIPSegConfig', 'CLIPSegForImageSegmentation', 'CLIPSegModel', 'CLIPSegPreTrainedModel', 'CLIPSegProcessor', 'CLIPSegTextConfig', 'CLIPSegTextModel', 'CLIPSegVisionConfig', 'CLIPSegVisionModel', 'CLIPTextConfig', 'CLIPTextModel', 'CLIPTextModelWithProjection', 'CLIPTokenizer', 'CLIPTokenizerFast', 'CLIPVisionConfig', 'CLIPVisionModel', 'CLIPVisionModelWithProjection', 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONDITIONAL_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONDITIONAL_DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONFIG_MAPPING', 'CONFIG_NAME', 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONVNEXTV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVNEXTV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CPMANT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CPMANT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CTRLConfig', 'CTRLForSequenceClassification', 'CTRLLMHeadModel', 'CTRLModel', 'CTRLPreTrainedModel', 'CTRLTokenizer', 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST', 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'CamembertConfig', 'CamembertForCausalLM', 'CamembertForMaskedLM', 'CamembertForMultipleChoice', 'CamembertForQuestionAnswering', 'CamembertForSequenceClassification', 'CamembertForTokenClassification', 'CamembertModel', 'CamembertPreTrainedModel', 'CamembertTokenizer', 'CamembertTokenizerFast', 'CanineConfig', 'CanineForMultipleChoice', 'CanineForQuestionAnswering', 'CanineForSequenceClassification', 'CanineForTokenClassification', 'CanineLayer', 'CanineModel', 'CaninePreTrainedModel', 'CanineTokenizer', 'CharSpan', 'CharacterTokenizer', 'ChineseCLIPConfig', 'ChineseCLIPFeatureExtractor', 'ChineseCLIPImageProcessor', 'ChineseCLIPModel', 'ChineseCLIPPreTrainedModel', 'ChineseCLIPProcessor', 'ChineseCLIPTextConfig', 'ChineseCLIPTextModel', 'ChineseCLIPVisionConfig', 'ChineseCLIPVisionModel', 'ClapAudioConfig', 'ClapAudioModel', 'ClapAudioModelWithProjection', 'ClapConfig', 'ClapFeatureExtractor', 'ClapModel', 'ClapPreTrainedModel', 'ClapProcessor', 'ClapTextConfig', 'ClapTextModel', 'ClapTextModelWithProjection', 'ClassifierFreeGuidanceLogitsProcessor', 'CodeGenConfig', 'CodeGenForCausalLM', 'CodeGenModel', 'CodeGenPreTrainedModel', 'CodeGenTokenizer', 'CodeGenTokenizerFast', 'CodeLlamaTokenizer', 'CodeLlamaTokenizerFast', 'ConditionalDetrConfig', 'ConditionalDetrFeatureExtractor', 'ConditionalDetrForObjectDetection', 'ConditionalDetrForSegmentation', 'ConditionalDetrImageProcessor', 'ConditionalDetrModel', 'ConditionalDetrPreTrainedModel', 'ConstrainedBeamSearchScorer', 'Constraint', 'ConstraintListState', 'Conv1D', 'ConvBertConfig', 'ConvBertForMaskedLM', 'ConvBertForMultipleChoice', 'ConvBertForQuestionAnswering', 'ConvBertForSequenceClassification', 'ConvBertForTokenClassification', 'ConvBertLayer', 'ConvBertModel', 'ConvBertPreTrainedModel', 'ConvBertTokenizer', 'ConvBertTokenizerFast', 'ConvNextBackbone', 'ConvNextConfig', 'ConvNextFeatureExtractor', 'ConvNextForImageClassification', 'ConvNextImageProcessor', 'ConvNextModel', 'ConvNextPreTrainedModel', 'ConvNextV2Backbone', 'ConvNextV2Config', 'ConvNextV2ForImageClassification', 'ConvNextV2Model', 'ConvNextV2PreTrainedModel', 'Conversation', 'ConversationalPipeline', 'CpmAntConfig', 'CpmAntForCausalLM', 'CpmAntModel', 'CpmAntPreTrainedModel', 'CpmAntTokenizer', 'CpmTokenizer', 'CpmTokenizerFast', 'CsvPipelineDataFormat', 'CvtConfig', 'CvtForImageClassification', 'CvtModel', 'CvtPreTrainedModel', 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST', 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEFORMABLE_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEFORMABLE_DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DETA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DETA_PRETRAINED_MODEL_ARCHIVE_LIST', 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST', 'DINAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DINAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DINOV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DINOV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'DONUT_SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DONUT_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPRConfig', 'DPRContextEncoder', 'DPRContextEncoderTokenizer', 'DPRContextEncoderTokenizerFast', 'DPRPreTrainedModel', 'DPRPretrainedContextEncoder', 'DPRPretrainedQuestionEncoder', 'DPRPretrainedReader', 'DPRQuestionEncoder', 'DPRQuestionEncoderTokenizer', 'DPRQuestionEncoderTokenizerFast', 'DPRReader', 'DPRReaderOutput', 'DPRReaderTokenizer', 'DPRReaderTokenizerFast', 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST', 'DPTConfig', 'DPTFeatureExtractor', 'DPTForDepthEstimation', 'DPTForSemanticSegmentation', 'DPTImageProcessor', 'DPTModel', 'DPTPreTrainedModel', 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'Data2VecAudioConfig', 'Data2VecAudioForAudioFrameClassification', 'Data2VecAudioForCTC', 'Data2VecAudioForSequenceClassification', 'Data2VecAudioForXVector', 'Data2VecAudioModel', 'Data2VecAudioPreTrainedModel', 'Data2VecTextConfig', 'Data2VecTextForCausalLM', 'Data2VecTextForMaskedLM', 'Data2VecTextForMultipleChoice', 'Data2VecTextForQuestionAnswering', 'Data2VecTextForSequenceClassification', 'Data2VecTextForTokenClassification', 'Data2VecTextModel', 'Data2VecTextPreTrainedModel', 'Data2VecVisionConfig', 'Data2VecVisionForImageClassification', 'Data2VecVisionForSemanticSegmentation', 'Data2VecVisionModel', 'Data2VecVisionPreTrainedModel', 'DataCollator', 'DataCollatorForLanguageModeling', 'DataCollatorForPermutationLanguageModeling', 'DataCollatorForSOP', 'DataCollatorForSeq2Seq', 'DataCollatorForTokenClassification', 'DataCollatorForWholeWordMask', 'DataCollatorWithPadding', 'DataProcessor', 'DebertaConfig', 'DebertaForMaskedLM', 'DebertaForQuestionAnswering', 'DebertaForSequenceClassification', 'DebertaForTokenClassification', 'DebertaModel', 'DebertaPreTrainedModel', 'DebertaTokenizer', 'DebertaTokenizerFast', 'DebertaV2Config', 'DebertaV2ForMaskedLM', 'DebertaV2ForMultipleChoice', 'DebertaV2ForQuestionAnswering', 'DebertaV2ForSequenceClassification', 'DebertaV2ForTokenClassification', 'DebertaV2Model', 'DebertaV2PreTrainedModel', 'DebertaV2Tokenizer', 'DebertaV2TokenizerFast', 'DecisionTransformerConfig', 'DecisionTransformerGPT2Model', 'DecisionTransformerGPT2PreTrainedModel', 'DecisionTransformerModel', 'DecisionTransformerPreTrainedModel', 'DefaultDataCollator', 'DefaultFlowCallback', 'DeformableDetrConfig', 'DeformableDetrFeatureExtractor', 'DeformableDetrForObjectDetection', 'DeformableDetrImageProcessor', 'DeformableDetrModel', 'DeformableDetrPreTrainedModel', 'DeiTConfig', 'DeiTFeatureExtractor', 'DeiTForImageClassification', 'DeiTForImageClassificationWithTeacher', 'DeiTForMaskedImageModeling', 'DeiTImageProcessor', 'DeiTModel', 'DeiTPreTrainedModel', 'DepthEstimationPipeline', 'DetaConfig', 'DetaForObjectDetection', 'DetaImageProcessor', 'DetaModel', 'DetaPreTrainedModel', 'DetrConfig', 'DetrFeatureExtractor', 'DetrForObjectDetection', 'DetrForSegmentation', 'DetrImageProcessor', 'DetrModel', 'DetrPreTrainedModel', 'DinatBackbone', 'DinatConfig', 'DinatForImageClassification', 'DinatModel', 'DinatPreTrainedModel', 'Dinov2Backbone', 'Dinov2Config', 'Dinov2ForImageClassification', 'Dinov2Model', 'Dinov2PreTrainedModel', 'DisjunctiveConstraint', 'DistilBertConfig', 'DistilBertForMaskedLM', 'DistilBertForMultipleChoice', 'DistilBertForQuestionAnswering', 'DistilBertForSequenceClassification', 'DistilBertForTokenClassification', 'DistilBertModel', 'DistilBertPreTrainedModel', 'DistilBertTokenizer', 'DistilBertTokenizerFast', 'DocumentQuestionAnsweringPipeline', 'DonutFeatureExtractor', 'DonutImageProcessor', 'DonutProcessor', 'DonutSwinConfig', 'DonutSwinModel', 'DonutSwinPreTrainedModel', 'DummyObject', 'EFFICIENTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'EFFICIENTNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'EFFICIENTNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'ENCODEC_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ENCODEC_PRETRAINED_MODEL_ARCHIVE_LIST', 'ERNIE_M_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ERNIE_M_PRETRAINED_MODEL_ARCHIVE_LIST', 'ERNIE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ERNIE_PRETRAINED_MODEL_ARCHIVE_LIST', 'ESM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ESM_PRETRAINED_MODEL_ARCHIVE_LIST', 'EarlyStoppingCallback', 'EfficientFormerConfig', 'EfficientFormerForImageClassification', 'EfficientFormerForImageClassificationWithTeacher', 'EfficientFormerImageProcessor', 'EfficientFormerModel', 'EfficientFormerPreTrainedModel', 'EfficientNetConfig', 'EfficientNetForImageClassification', 'EfficientNetImageProcessor', 'EfficientNetModel', 'EfficientNetPreTrainedModel', 'ElectraConfig', 'ElectraForCausalLM', 'ElectraForMaskedLM', 'ElectraForMultipleChoice', 'ElectraForPreTraining', 'ElectraForQuestionAnswering', 'ElectraForSequenceClassification', 'ElectraForTokenClassification', 'ElectraModel', 'ElectraPreTrainedModel', 'ElectraTokenizer', 'ElectraTokenizerFast', 'EncodecConfig', 'EncodecFeatureExtractor', 'EncodecModel', 'EncodecPreTrainedModel', 'EncoderDecoderConfig', 'EncoderDecoderModel', 'EncoderNoRepeatNGramLogitsProcessor', 'EncoderRepetitionPenaltyLogitsProcessor', 'EpsilonLogitsWarper', 'ErnieConfig', 'ErnieForCausalLM', 'ErnieForMaskedLM', 'ErnieForMultipleChoice', 'ErnieForNextSentencePrediction', 'ErnieForPreTraining', 'ErnieForQuestionAnswering', 'ErnieForSequenceClassification', 'ErnieForTokenClassification', 'ErnieMConfig', 'ErnieMForInformationExtraction', 'ErnieMForMultipleChoice', 'ErnieMForQuestionAnswering', 'ErnieMForSequenceClassification', 'ErnieMForTokenClassification', 'ErnieMModel', 'ErnieMPreTrainedModel', 'ErnieMTokenizer', 'ErnieModel', 'ErniePreTrainedModel', 'EsmConfig', 'EsmFoldPreTrainedModel', 'EsmForMaskedLM', 'EsmForProteinFolding', 'EsmForSequenceClassification', 'EsmForTokenClassification', 'EsmModel', 'EsmPreTrainedModel', 'EsmTokenizer', 'EtaLogitsWarper', 'EvalPrediction', 'ExponentialDecayLengthPenalty', 'FALCON_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FALCON_PRETRAINED_MODEL_ARCHIVE_LIST', 'FEATURE_EXTRACTOR_MAPPING', 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST', 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_MASKED_LM_MAPPING', 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'FLAX_MODEL_FOR_PRETRAINING_MAPPING', 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING', 'FLAX_MODEL_MAPPING', 'FLAX_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'FNetConfig', 'FNetForMaskedLM', 'FNetForMultipleChoice', 'FNetForNextSentencePrediction', 'FNetForPreTraining', 'FNetForQuestionAnswering', 'FNetForSequenceClassification', 'FNetForTokenClassification', 'FNetLayer', 'FNetModel', 'FNetPreTrainedModel', 'FNetTokenizer', 'FNetTokenizerFast', 'FOCALNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FOCALNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'FSMTConfig', 'FSMTForConditionalGeneration', 'FSMTModel', 'FSMTTokenizer', 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST', 'FUYU_PRETRAINED_CONFIG_ARCHIVE_MAP', 'FalconConfig', 'FalconForCausalLM', 'FalconForQuestionAnswering', 'FalconForSequenceClassification', 'FalconForTokenClassification', 'FalconModel', 'FalconPreTrainedModel', 'FeatureExtractionMixin', 'FeatureExtractionPipeline', 'FillMaskPipeline', 'FlaubertConfig', 'FlaubertForMultipleChoice', 'FlaubertForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FlaubertForSequenceClassification', 'FlaubertForTokenClassification', 'FlaubertModel', 'FlaubertPreTrainedModel', 'FlaubertTokenizer', 'FlaubertWithLMHeadModel', 'FlavaConfig', 'FlavaFeatureExtractor', 'FlavaForPreTraining', 'FlavaImageCodebook', 'FlavaImageCodebookConfig', 'FlavaImageConfig', 'FlavaImageModel', 'FlavaImageProcessor', 'FlavaModel', 'FlavaMultimodalConfig', 'FlavaMultimodalModel', 'FlavaPreTrainedModel', 'FlavaProcessor', 'FlavaTextConfig', 'FlavaTextModel', 'FlaxAlbertForMaskedLM', 'FlaxAlbertForMultipleChoice', 'FlaxAlbertForPreTraining', 'FlaxAlbertForQuestionAnswering', 'FlaxAlbertForSequenceClassification', 'FlaxAlbertForTokenClassification', 'FlaxAlbertModel', 'FlaxAlbertPreTrainedModel', 'FlaxAutoModel', 'FlaxAutoModelForCausalLM', 'FlaxAutoModelForImageClassification', 'FlaxAutoModelForMaskedLM', 'FlaxAutoModelForMultipleChoice', 'FlaxAutoModelForNextSentencePrediction', 'FlaxAutoModelForPreTraining', 'FlaxAutoModelForQuestionAnswering', 'FlaxAutoModelForSeq2SeqLM', 'FlaxAutoModelForSequenceClassification', 'FlaxAutoModelForSpeechSeq2Seq', 'FlaxAutoModelForTokenClassification', 'FlaxAutoModelForVision2Seq', 'FlaxBartDecoderPreTrainedModel', 'FlaxBartForCausalLM', 'FlaxBartForConditionalGeneration', 'FlaxBartForQuestionAnswering', 'FlaxBartForSequenceClassification', 'FlaxBartModel', 'FlaxBartPreTrainedModel', 'FlaxBeitForImageClassification', 'FlaxBeitForMaskedImageModeling', 'FlaxBeitModel', 'FlaxBeitPreTrainedModel', 'FlaxBertForCausalLM', 'FlaxBertForMaskedLM', 'FlaxBertForMultipleChoice', 'FlaxBertForNextSentencePrediction', 'FlaxBertForPreTraining', 'FlaxBertForQuestionAnswering', 'FlaxBertForSequenceClassification', 'FlaxBertForTokenClassification', 'FlaxBertModel', 'FlaxBertPreTrainedModel', 'FlaxBigBirdForCausalLM', 'FlaxBigBirdForMaskedLM', 'FlaxBigBirdForMultipleChoice', 'FlaxBigBirdForPreTraining', 'FlaxBigBirdForQuestionAnswering', 'FlaxBigBirdForSequenceClassification', 'FlaxBigBirdForTokenClassification', 'FlaxBigBirdModel', 'FlaxBigBirdPreTrainedModel', 'FlaxBlenderbotForConditionalGeneration', 'FlaxBlenderbotModel', 'FlaxBlenderbotPreTrainedModel', 'FlaxBlenderbotSmallForConditionalGeneration', 'FlaxBlenderbotSmallModel', 'FlaxBlenderbotSmallPreTrainedModel', 'FlaxBloomForCausalLM', 'FlaxBloomModel', 'FlaxBloomPreTrainedModel', 'FlaxCLIPModel', 'FlaxCLIPPreTrainedModel', 'FlaxCLIPTextModel', 'FlaxCLIPTextModelWithProjection', 'FlaxCLIPTextPreTrainedModel', 'FlaxCLIPVisionModel', 'FlaxCLIPVisionPreTrainedModel', 'FlaxDistilBertForMaskedLM', 'FlaxDistilBertForMultipleChoice', 'FlaxDistilBertForQuestionAnswering', 'FlaxDistilBertForSequenceClassification', 'FlaxDistilBertForTokenClassification', 'FlaxDistilBertModel', 'FlaxDistilBertPreTrainedModel', 'FlaxElectraForCausalLM', 'FlaxElectraForMaskedLM', 'FlaxElectraForMultipleChoice', 'FlaxElectraForPreTraining', 'FlaxElectraForQuestionAnswering', 'FlaxElectraForSequenceClassification', 'FlaxElectraForTokenClassification', 'FlaxElectraModel', 'FlaxElectraPreTrainedModel', 'FlaxEncoderDecoderModel', 'FlaxForceTokensLogitsProcessor', 'FlaxForcedBOSTokenLogitsProcessor', 'FlaxForcedEOSTokenLogitsProcessor', 'FlaxGPT2LMHeadModel', 'FlaxGPT2Model', 'FlaxGPT2PreTrainedModel', 'FlaxGPTJForCausalLM', 'FlaxGPTJModel', 'FlaxGPTJPreTrainedModel', 'FlaxGPTNeoForCausalLM', 'FlaxGPTNeoModel', 'FlaxGPTNeoPreTrainedModel', 'FlaxGenerationMixin', 'FlaxLogitsProcessor', 'FlaxLogitsProcessorList', 'FlaxLogitsWarper', 'FlaxLongT5ForConditionalGeneration', 'FlaxLongT5Model', 'FlaxLongT5PreTrainedModel', 'FlaxMBartForConditionalGeneration', 'FlaxMBartForQuestionAnswering', 'FlaxMBartForSequenceClassification', 'FlaxMBartModel', 'FlaxMBartPreTrainedModel', 'FlaxMT5EncoderModel', 'FlaxMT5ForConditionalGeneration', 'FlaxMT5Model', 'FlaxMarianMTModel', 'FlaxMarianModel', 'FlaxMarianPreTrainedModel', 'FlaxMinLengthLogitsProcessor', 'FlaxOPTForCausalLM', 'FlaxOPTModel', 'FlaxOPTPreTrainedModel', 'FlaxPegasusForConditionalGeneration', 'FlaxPegasusModel', 'FlaxPegasusPreTrainedModel', 'FlaxPreTrainedModel', 'FlaxRegNetForImageClassification', 'FlaxRegNetModel', 'FlaxRegNetPreTrainedModel', 'FlaxResNetForImageClassification', 'FlaxResNetModel', 'FlaxResNetPreTrainedModel', 'FlaxRoFormerForMaskedLM', 'FlaxRoFormerForMultipleChoice', 'FlaxRoFormerForQuestionAnswering', 'FlaxRoFormerForSequenceClassification', 'FlaxRoFormerForTokenClassification', 'FlaxRoFormerModel', 'FlaxRoFormerPreTrainedModel', 'FlaxRobertaForCausalLM', 'FlaxRobertaForMaskedLM', 'FlaxRobertaForMultipleChoice', 'FlaxRobertaForQuestionAnswering', 'FlaxRobertaForSequenceClassification', 'FlaxRobertaForTokenClassification', 'FlaxRobertaModel', 'FlaxRobertaPreLayerNormForCausalLM', 'FlaxRobertaPreLayerNormForMaskedLM', 'FlaxRobertaPreLayerNormForMultipleChoice', 'FlaxRobertaPreLayerNormForQuestionAnswering', 'FlaxRobertaPreLayerNormForSequenceClassification', 'FlaxRobertaPreLayerNormForTokenClassification', 'FlaxRobertaPreLayerNormModel', 'FlaxRobertaPreLayerNormPreTrainedModel', 'FlaxRobertaPreTrainedModel', 'FlaxSpeechEncoderDecoderModel', 'FlaxSuppressTokensAtBeginLogitsProcessor', 'FlaxSuppressTokensLogitsProcessor', 'FlaxT5EncoderModel', 'FlaxT5ForConditionalGeneration', 'FlaxT5Model', 'FlaxT5PreTrainedModel', 'FlaxTemperatureLogitsWarper', 'FlaxTopKLogitsWarper', 'FlaxTopPLogitsWarper', 'FlaxViTForImageClassification', 'FlaxViTModel', 'FlaxViTPreTrainedModel', 'FlaxVisionEncoderDecoderModel', 'FlaxVisionTextDualEncoderModel', 'FlaxWav2Vec2ForCTC', 'FlaxWav2Vec2ForPreTraining', 'FlaxWav2Vec2Model', 'FlaxWav2Vec2PreTrainedModel', 'FlaxWhisperForAudioClassification', 'FlaxWhisperForConditionalGeneration', 'FlaxWhisperModel', 'FlaxWhisperPreTrainedModel', 'FlaxWhisperTimeStampLogitsProcessor', 'FlaxXGLMForCausalLM', 'FlaxXGLMModel', 'FlaxXGLMPreTrainedModel', 'FlaxXLMRobertaForCausalLM', 'FlaxXLMRobertaForMaskedLM', 'FlaxXLMRobertaForMultipleChoice', 'FlaxXLMRobertaForQuestionAnswering', 'FlaxXLMRobertaForSequenceClassification', 'FlaxXLMRobertaForTokenClassification', 'FlaxXLMRobertaModel', 'FlaxXLMRobertaPreTrainedModel', 'FocalNetBackbone', 'FocalNetConfig', 'FocalNetForImageClassification', 'FocalNetForMaskedImageModeling', 'FocalNetModel', 'FocalNetPreTrainedModel', 'ForceTokensLogitsProcessor', 'ForcedBOSTokenLogitsProcessor', 'ForcedEOSTokenLogitsProcessor', 'FunnelBaseModel', 'FunnelConfig', 'FunnelForMaskedLM', 'FunnelForMultipleChoice', 'FunnelForPreTraining', 'FunnelForQuestionAnswering', 'FunnelForSequenceClassification', 'FunnelForTokenClassification', 'FunnelModel', 'FunnelPreTrainedModel', 'FunnelTokenizer', 'FunnelTokenizerFast', 'FuyuConfig', 'FuyuForCausalLM', 'FuyuImageProcessor', 'FuyuPreTrainedModel', 'FuyuProcessor', 'GIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'GLPNConfig', 'GLPNFeatureExtractor', 'GLPNForDepthEstimation', 'GLPNImageProcessor', 'GLPNModel', 'GLPNPreTrainedModel', 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT2Config', 'GPT2DoubleHeadsModel', 'GPT2ForQuestionAnswering', 'GPT2ForSequenceClassification', 'GPT2ForTokenClassification', 'GPT2LMHeadModel', 'GPT2Model', 'GPT2PreTrainedModel', 'GPT2Tokenizer', 'GPT2TokenizerFast', 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTBigCodeConfig', 'GPTBigCodeForCausalLM', 'GPTBigCodeForSequenceClassification', 'GPTBigCodeForTokenClassification', 'GPTBigCodeModel', 'GPTBigCodePreTrainedModel', 'GPTJConfig', 'GPTJForCausalLM', 'GPTJForQuestionAnswering', 'GPTJForSequenceClassification', 'GPTJModel', 'GPTJPreTrainedModel', 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTNeoConfig', 'GPTNeoForCausalLM', 'GPTNeoForQuestionAnswering', 'GPTNeoForSequenceClassification', 'GPTNeoForTokenClassification', 'GPTNeoModel', 'GPTNeoPreTrainedModel', 'GPTNeoXConfig', 'GPTNeoXForCausalLM', 'GPTNeoXForQuestionAnswering', 'GPTNeoXForSequenceClassification', 'GPTNeoXForTokenClassification', 'GPTNeoXJapaneseConfig', 'GPTNeoXJapaneseForCausalLM', 'GPTNeoXJapaneseLayer', 'GPTNeoXJapaneseModel', 'GPTNeoXJapanesePreTrainedModel', 'GPTNeoXJapaneseTokenizer', 'GPTNeoXLayer', 'GPTNeoXModel', 'GPTNeoXPreTrainedModel', 'GPTNeoXTokenizerFast', 'GPTQConfig', 'GPTSAN_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPTSAN_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPTSanJapaneseConfig', 'GPTSanJapaneseForConditionalGeneration', 'GPTSanJapaneseModel', 'GPTSanJapanesePreTrainedModel', 'GPTSanJapaneseTokenizer', 'GPTSw3Tokenizer', 'GPT_BIGCODE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_BIGCODE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEOX_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEOX_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEOX_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEOX_PRETRAINED_MODEL_ARCHIVE_LIST', 'GPT_NEO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GPT_NEO_PRETRAINED_MODEL_ARCHIVE_LIST', 'GRAPHORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GRAPHORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'GROUPVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'GenerationConfig', 'GenerationMixin', 'GitConfig', 'GitForCausalLM', 'GitModel', 'GitPreTrainedModel', 'GitProcessor', 'GitVisionConfig', 'GitVisionModel', 'GlueDataTrainingArguments', 'GlueDataset', 'GradientAccumulator', 'GraphormerConfig', 'GraphormerForGraphClassification', 'GraphormerModel', 'GraphormerPreTrainedModel', 'GroupViTConfig', 'GroupViTModel', 'GroupViTPreTrainedModel', 'GroupViTTextConfig', 'GroupViTTextModel', 'GroupViTVisionConfig', 'GroupViTVisionModel', 'HUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'HammingDiversityLogitsProcessor', 'HerbertTokenizer', 'HerbertTokenizerFast', 'HfAgent', 'HfArgumentParser', 'HubertConfig', 'HubertForCTC', 'HubertForSequenceClassification', 'HubertModel', 'HubertPreTrainedModel', 'IBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'IBertConfig', 'IBertForMaskedLM', 'IBertForMultipleChoice', 'IBertForQuestionAnswering', 'IBertForSequenceClassification', 'IBertForTokenClassification', 'IBertModel', 'IBertPreTrainedModel', 'IDEFICS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IDEFICS_PRETRAINED_MODEL_ARCHIVE_LIST', 'IMAGEGPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'IMAGEGPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'IMAGE_PROCESSOR_MAPPING', 'INFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'INFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'INSTRUCTBLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'INSTRUCTBLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'IdeficsConfig', 'IdeficsForVisionText2Text', 'IdeficsImageProcessor', 'IdeficsModel', 'IdeficsPreTrainedModel', 'IdeficsProcessor', 'ImageClassificationPipeline', 'ImageFeatureExtractionMixin', 'ImageGPTConfig', 'ImageGPTFeatureExtractor', 'ImageGPTForCausalImageModeling', 'ImageGPTForImageClassification', 'ImageGPTImageProcessor', 'ImageGPTModel', 'ImageGPTPreTrainedModel', 'ImageProcessingMixin', 'ImageSegmentationPipeline', 'ImageToImagePipeline', 'ImageToTextPipeline', 'InfNanRemoveLogitsProcessor', 'InformerConfig', 'InformerForPrediction', 'InformerModel', 'InformerPreTrainedModel', 'InputExample', 'InputFeatures', 'InstructBlipConfig', 'InstructBlipForConditionalGeneration', 'InstructBlipPreTrainedModel', 'InstructBlipProcessor', 'InstructBlipQFormerConfig', 'InstructBlipQFormerModel', 'InstructBlipVisionConfig', 'InstructBlipVisionModel', 'IntervalStrategy', 'JUKEBOX_PRETRAINED_CONFIG_ARCHIVE_MAP', 'JUKEBOX_PRETRAINED_MODEL_ARCHIVE_LIST', 'JsonPipelineDataFormat', 'JukeboxConfig', 'JukeboxModel', 'JukeboxPreTrainedModel', 'JukeboxPrior', 'JukeboxPriorConfig', 'JukeboxTokenizer', 'JukeboxVQVAE', 'JukeboxVQVAEConfig', 'KOSMOS2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'KOSMOS2_PRETRAINED_MODEL_ARCHIVE_LIST', 'KerasMetricCallback', 'Kosmos2Config', 'Kosmos2ForConditionalGeneration', 'Kosmos2Model', 'Kosmos2PreTrainedModel', 'Kosmos2Processor', 'LAYOUTLMV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLMV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'LAYOUTLMV3_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLMV3_PRETRAINED_MODEL_ARCHIVE_LIST', 'LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'LEDConfig', 'LEDForConditionalGeneration', 'LEDForQuestionAnswering', 'LEDForSequenceClassification', 'LEDModel', 'LEDPreTrainedModel', 'LEDTokenizer', 'LEDTokenizerFast', 'LED_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LED_PRETRAINED_MODEL_ARCHIVE_LIST', 'LEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'LILT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LILT_PRETRAINED_MODEL_ARCHIVE_LIST', 'LLAMA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LONGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'LONGT5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LONGT5_PRETRAINED_MODEL_ARCHIVE_LIST', 'LUKE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LUKE_PRETRAINED_MODEL_ARCHIVE_LIST', 'LXMERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'LayoutLMConfig', 'LayoutLMForMaskedLM', 'LayoutLMForQuestionAnswering', 'LayoutLMForSequenceClassification', 'LayoutLMForTokenClassification', 'LayoutLMModel', 'LayoutLMPreTrainedModel', 'LayoutLMTokenizer', 'LayoutLMTokenizerFast', 'LayoutLMv2Config', 'LayoutLMv2FeatureExtractor', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv2ImageProcessor', 'LayoutLMv2Model', 'LayoutLMv2PreTrainedModel', 'LayoutLMv2Processor', 'LayoutLMv2Tokenizer', 'LayoutLMv2TokenizerFast', 'LayoutLMv3Config', 'LayoutLMv3FeatureExtractor', 'LayoutLMv3ForQuestionAnswering', 'LayoutLMv3ForSequenceClassification', 'LayoutLMv3ForTokenClassification', 'LayoutLMv3ImageProcessor', 'LayoutLMv3Model', 'LayoutLMv3PreTrainedModel', 'LayoutLMv3Processor', 'LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast', 'LayoutXLMProcessor', 'LayoutXLMTokenizer', 'LayoutXLMTokenizerFast', 'LevitConfig', 'LevitFeatureExtractor', 'LevitForImageClassification', 'LevitForImageClassificationWithTeacher', 'LevitImageProcessor', 'LevitModel', 'LevitPreTrainedModel', 'LiltConfig', 'LiltForQuestionAnswering', 'LiltForSequenceClassification', 'LiltForTokenClassification', 'LiltModel', 'LiltPreTrainedModel', 'LineByLineTextDataset', 'LineByLineWithRefDataset', 'LineByLineWithSOPTextDataset', 'LlamaConfig', 'LlamaForCausalLM', 'LlamaForSequenceClassification', 'LlamaModel', 'LlamaPreTrainedModel', 'LlamaTokenizer', 'LlamaTokenizerFast', 'LocalAgent', 'LogitNormalization', 'LogitsProcessor', 'LogitsProcessorList', 'LogitsWarper', 'LongT5Config', 'LongT5EncoderModel', 'LongT5ForConditionalGeneration', 'LongT5Model', 'LongT5PreTrainedModel', 'LongformerConfig', 'LongformerForMaskedLM', 'LongformerForMultipleChoice', 'LongformerForQuestionAnswering', 'LongformerForSequenceClassification', 'LongformerForTokenClassification', 'LongformerModel', 'LongformerPreTrainedModel', 'LongformerSelfAttention', 'LongformerTokenizer', 'LongformerTokenizerFast', 'LukeConfig', 'LukeForEntityClassification', 'LukeForEntityPairClassification', 'LukeForEntitySpanClassification', 'LukeForMaskedLM', 'LukeForMultipleChoice', 'LukeForQuestionAnswering', 'LukeForSequenceClassification', 'LukeForTokenClassification', 'LukeModel', 'LukePreTrainedModel', 'LukeTokenizer', 'LxmertConfig', 'LxmertEncoder', 'LxmertForPreTraining', 'LxmertForQuestionAnswering', 'LxmertModel', 'LxmertPreTrainedModel', 'LxmertTokenizer', 'LxmertTokenizerFast', 'LxmertVisualFeatureEncoder', 'LxmertXLayer', 'M2M100Config', 'M2M100ForConditionalGeneration', 'M2M100Model', 'M2M100PreTrainedModel', 'M2M100Tokenizer', 'M2M_100_PRETRAINED_CONFIG_ARCHIVE_MAP', 'M2M_100_PRETRAINED_MODEL_ARCHIVE_LIST', 'MARKUPLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MARKUPLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'MASK2FORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MASK2FORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'MASKFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MASKFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'MBart50Tokenizer', 'MBart50TokenizerFast', 'MBartConfig', 'MBartForCausalLM', 'MBartForConditionalGeneration', 'MBartForQuestionAnswering', 'MBartForSequenceClassification', 'MBartModel', 'MBartPreTrainedModel', 'MBartTokenizer', 'MBartTokenizerFast', 'MCTCTConfig', 'MCTCTFeatureExtractor', 'MCTCTForCTC', 'MCTCTModel', 'MCTCTPreTrainedModel', 'MCTCTProcessor', 'MCTCT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MCTCT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MEGATRON_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MEGATRON_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MEGA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MEGA_PRETRAINED_MODEL_ARCHIVE_LIST', 'MGP_STR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MGP_STR_PRETRAINED_MODEL_ARCHIVE_LIST', 'MISTRAL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MLukeTokenizer', 'MMBTConfig', 'MMBTForClassification', 'MMBTModel', 'MOBILEBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILENET_V1_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILENET_V1_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILENET_V2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILENET_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILEVITV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEVITV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'MOBILEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MOBILEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MODEL_CARD_NAME', 'MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING', 'MODEL_FOR_AUDIO_XVECTOR_MAPPING', 'MODEL_FOR_BACKBONE_MAPPING', 'MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING', 'MODEL_FOR_CAUSAL_LM_MAPPING', 'MODEL_FOR_CTC_MAPPING', 'MODEL_FOR_DEPTH_ESTIMATION_MAPPING', 'MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_IMAGE_SEGMENTATION_MAPPING', 'MODEL_FOR_IMAGE_TO_IMAGE_MAPPING', 'MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING', 'MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'MODEL_FOR_MASKED_LM_MAPPING', 'MODEL_FOR_MASK_GENERATION_MAPPING', 'MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'MODEL_FOR_OBJECT_DETECTION_MAPPING', 'MODEL_FOR_PRETRAINING_MAPPING', 'MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_TEXT_ENCODING_MAPPING', 'MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING', 'MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING', 'MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING', 'MODEL_FOR_VIDEO_CLASSIFICATION_MAPPING', 'MODEL_FOR_VISION_2_SEQ_MAPPING', 'MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING', 'MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING', 'MODEL_MAPPING', 'MODEL_NAMES_MAPPING', 'MODEL_WITH_LM_HEAD_MAPPING', 'MPNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MPNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'MPNetConfig', 'MPNetForMaskedLM', 'MPNetForMultipleChoice', 'MPNetForQuestionAnswering', 'MPNetForSequenceClassification', 'MPNetForTokenClassification', 'MPNetLayer', 'MPNetModel', 'MPNetPreTrainedModel', 'MPNetTokenizer', 'MPNetTokenizerFast', 'MPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'MRA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'MT5Config', 'MT5EncoderModel', 'MT5ForConditionalGeneration', 'MT5ForQuestionAnswering', 'MT5ForSequenceClassification', 'MT5Model', 'MT5PreTrainedModel', 'MT5Tokenizer', 'MT5TokenizerFast', 'MUSICGEN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'MUSICGEN_PRETRAINED_MODEL_ARCHIVE_LIST', 'MVP_PRETRAINED_MODEL_ARCHIVE_LIST', 'MarianConfig', 'MarianForCausalLM', 'MarianMTModel', 'MarianModel', 'MarianTokenizer', 'MarkupLMConfig', 'MarkupLMFeatureExtractor', 'MarkupLMForQuestionAnswering', 'MarkupLMForSequenceClassification', 'MarkupLMForTokenClassification', 'MarkupLMModel', 'MarkupLMPreTrainedModel', 'MarkupLMProcessor', 'MarkupLMTokenizer', 'MarkupLMTokenizerFast', 'Mask2FormerConfig', 'Mask2FormerForUniversalSegmentation', 'Mask2FormerImageProcessor', 'Mask2FormerModel', 'Mask2FormerPreTrainedModel', 'MaskFormerConfig', 'MaskFormerFeatureExtractor', 'MaskFormerForInstanceSegmentation', 'MaskFormerImageProcessor', 'MaskFormerModel', 'MaskFormerPreTrainedModel', 'MaskFormerSwinBackbone', 'MaskFormerSwinConfig', 'MaskGenerationPipeline', 'MaxLengthCriteria', 'MaxTimeCriteria', 'MecabTokenizer', 'MegaConfig', 'MegaForCausalLM', 'MegaForMaskedLM', 'MegaForMultipleChoice', 'MegaForQuestionAnswering', 'MegaForSequenceClassification', 'MegaForTokenClassification', 'MegaModel', 'MegaPreTrainedModel', 'MegatronBertConfig', 'MegatronBertForCausalLM', 'MegatronBertForMaskedLM', 'MegatronBertForMultipleChoice', 'MegatronBertForNextSentencePrediction', 'MegatronBertForPreTraining', 'MegatronBertForQuestionAnswering', 'MegatronBertForSequenceClassification', 'MegatronBertForTokenClassification', 'MegatronBertModel', 'MegatronBertPreTrainedModel', 'MgpstrConfig', 'MgpstrForSceneTextRecognition', 'MgpstrModel', 'MgpstrPreTrainedModel', 'MgpstrProcessor', 'MgpstrTokenizer', 'MinLengthLogitsProcessor', 'MinNewTokensLengthLogitsProcessor', 'MistralConfig', 'MistralForCausalLM', 'MistralForSequenceClassification', 'MistralModel', 'MistralPreTrainedModel', 'MobileBertConfig', 'MobileBertForMaskedLM', 'MobileBertForMultipleChoice', 'MobileBertForNextSentencePrediction', 'MobileBertForPreTraining', 'MobileBertForQuestionAnswering', 'MobileBertForSequenceClassification', 'MobileBertForTokenClassification', 'MobileBertLayer', 'MobileBertModel', 'MobileBertPreTrainedModel', 'MobileBertTokenizer', 'MobileBertTokenizerFast', 'MobileNetV1Config', 'MobileNetV1FeatureExtractor', 'MobileNetV1ForImageClassification', 'MobileNetV1ImageProcessor', 'MobileNetV1Model', 'MobileNetV1PreTrainedModel', 'MobileNetV2Config', 'MobileNetV2FeatureExtractor', 'MobileNetV2ForImageClassification', 'MobileNetV2ForSemanticSegmentation', 'MobileNetV2ImageProcessor', 'MobileNetV2Model', 'MobileNetV2PreTrainedModel', 'MobileViTConfig', 'MobileViTFeatureExtractor', 'MobileViTForImageClassification', 'MobileViTForSemanticSegmentation', 'MobileViTImageProcessor', 'MobileViTModel', 'MobileViTPreTrainedModel', 'MobileViTV2Config', 'MobileViTV2ForImageClassification', 'MobileViTV2ForSemanticSegmentation', 'MobileViTV2Model', 'MobileViTV2PreTrainedModel', 'ModalEmbeddings', 'ModelCard', 'MptConfig', 'MptForCausalLM', 'MptForQuestionAnswering', 'MptForSequenceClassification', 'MptForTokenClassification', 'MptModel', 'MptPreTrainedModel', 'MraConfig', 'MraForMaskedLM', 'MraForMultipleChoice', 'MraForQuestionAnswering', 'MraForSequenceClassification', 'MraForTokenClassification', 'MraModel', 'MraPreTrainedModel', 'MusicgenConfig', 'MusicgenDecoderConfig', 'MusicgenForCausalLM', 'MusicgenForConditionalGeneration', 'MusicgenModel', 'MusicgenPreTrainedModel', 'MusicgenProcessor', 'MvpConfig', 'MvpForCausalLM', 'MvpForConditionalGeneration', 'MvpForQuestionAnswering', 'MvpForSequenceClassification', 'MvpModel', 'MvpPreTrainedModel', 'MvpTokenizer', 'MvpTokenizerFast', 'NAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'NEZHA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NEZHA_PRETRAINED_MODEL_ARCHIVE_LIST', 'NLLB_MOE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NLLB_MOE_PRETRAINED_MODEL_ARCHIVE_LIST', 'NYSTROMFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'NYSTROMFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'NatBackbone', 'NatConfig', 'NatForImageClassification', 'NatModel', 'NatPreTrainedModel', 'NerPipeline', 'NezhaConfig', 'NezhaForMaskedLM', 'NezhaForMultipleChoice', 'NezhaForNextSentencePrediction', 'NezhaForPreTraining', 'NezhaForQuestionAnswering', 'NezhaForSequenceClassification', 'NezhaForTokenClassification', 'NezhaModel', 'NezhaPreTrainedModel', 'NllbMoeConfig', 'NllbMoeForConditionalGeneration', 'NllbMoeModel', 'NllbMoePreTrainedModel', 'NllbMoeSparseMLP', 'NllbMoeTop2Router', 'NllbTokenizer', 'NllbTokenizerFast', 'NoBadWordsLogitsProcessor', 'NoRepeatNGramLogitsProcessor', 'NougatImageProcessor', 'NougatProcessor', 'NougatTokenizerFast', 'NystromformerConfig', 'NystromformerForMaskedLM', 'NystromformerForMultipleChoice', 'NystromformerForQuestionAnswering', 'NystromformerForSequenceClassification', 'NystromformerForTokenClassification', 'NystromformerLayer', 'NystromformerModel', 'NystromformerPreTrainedModel', 'ONEFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ONEFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'OPEN_LLAMA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OPTConfig', 'OPTForCausalLM', 'OPTForQuestionAnswering', 'OPTForSequenceClassification', 'OPTModel', 'OPTPreTrainedModel', 'OPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'OWLV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OWLV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'OWLVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'OWLVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ObjectDetectionPipeline', 'OneFormerConfig', 'OneFormerForUniversalSegmentation', 'OneFormerImageProcessor', 'OneFormerModel', 'OneFormerPreTrainedModel', 'OneFormerProcessor', 'OpenAIGPTConfig', 'OpenAIGPTDoubleHeadsModel', 'OpenAIGPTForSequenceClassification', 'OpenAIGPTLMHeadModel', 'OpenAIGPTModel', 'OpenAIGPTPreTrainedModel', 'OpenAIGPTTokenizer', 'OpenAIGPTTokenizerFast', 'OpenAiAgent', 'OpenLlamaConfig', 'OpenLlamaForCausalLM', 'OpenLlamaForSequenceClassification', 'OpenLlamaModel', 'OpenLlamaPreTrainedModel', 'OwlViTConfig', 'OwlViTFeatureExtractor', 'OwlViTForObjectDetection', 'OwlViTImageProcessor', 'OwlViTModel', 'OwlViTPreTrainedModel', 'OwlViTProcessor', 'OwlViTTextConfig', 'OwlViTTextModel', 'OwlViTVisionConfig', 'OwlViTVisionModel', 'Owlv2Config', 'Owlv2ForObjectDetection', 'Owlv2ImageProcessor', 'Owlv2Model', 'Owlv2PreTrainedModel', 'Owlv2Processor', 'Owlv2TextConfig', 'Owlv2TextModel', 'Owlv2VisionConfig', 'Owlv2VisionModel', 'PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PEGASUS_X_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PEGASUS_X_PRETRAINED_MODEL_ARCHIVE_LIST', 'PERCEIVER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PERCEIVER_PRETRAINED_MODEL_ARCHIVE_LIST', 'PERSIMMON_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PIX2STRUCT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PIX2STRUCT_PRETRAINED_MODEL_ARCHIVE_LIST', 'PLBART_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PLBART_PRETRAINED_MODEL_ARCHIVE_LIST', 'PLBartConfig', 'PLBartForCausalLM', 'PLBartForConditionalGeneration', 'PLBartForSequenceClassification', 'PLBartModel', 'PLBartPreTrainedModel', 'PLBartTokenizer', 'POOLFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'POOLFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'POP2PIANO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'POP2PIANO_PRETRAINED_MODEL_ARCHIVE_LIST', 'PROCESSOR_MAPPING', 'PROPHETNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PROPHETNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'PVT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'PVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'PYTORCH_PRETRAINED_BERT_CACHE', 'PYTORCH_TRANSFORMERS_CACHE', 'PegasusConfig', 'PegasusForCausalLM', 'PegasusForConditionalGeneration', 'PegasusModel', 'PegasusPreTrainedModel', 'PegasusTokenizer', 'PegasusTokenizerFast', 'PegasusXConfig', 'PegasusXForConditionalGeneration', 'PegasusXModel', 'PegasusXPreTrainedModel', 'PerceiverConfig', 'PerceiverFeatureExtractor', 'PerceiverForImageClassificationConvProcessing', 'PerceiverForImageClassificationFourier', 'PerceiverForImageClassificationLearned', 'PerceiverForMaskedLM', 'PerceiverForMultimodalAutoencoding', 'PerceiverForOpticalFlow', 'PerceiverForSequenceClassification', 'PerceiverImageProcessor', 'PerceiverLayer', 'PerceiverModel', 'PerceiverPreTrainedModel', 'PerceiverTokenizer', 'PersimmonConfig', 'PersimmonForCausalLM', 'PersimmonForSequenceClassification', 'PersimmonModel', 'PersimmonPreTrainedModel', 'PhobertTokenizer', 'PhrasalConstraint', 'PipedPipelineDataFormat', 'Pipeline', 'PipelineDataFormat', 'PipelineTool', 'Pix2StructConfig', 'Pix2StructForConditionalGeneration', 'Pix2StructImageProcessor', 'Pix2StructPreTrainedModel', 'Pix2StructProcessor', 'Pix2StructTextConfig', 'Pix2StructTextModel', 'Pix2StructVisionConfig', 'Pix2StructVisionModel', 'PoolFormerConfig', 'PoolFormerFeatureExtractor', 'PoolFormerForImageClassification', 'PoolFormerImageProcessor', 'PoolFormerModel', 'PoolFormerPreTrainedModel', 'Pop2PianoConfig', 'Pop2PianoFeatureExtractor', 'Pop2PianoForConditionalGeneration', 'Pop2PianoPreTrainedModel', 'Pop2PianoProcessor', 'Pop2PianoTokenizer', 'PreTrainedModel', 'PreTrainedTokenizer', 'PreTrainedTokenizerBase', 'PreTrainedTokenizerFast', 'PrefixConstrainedLogitsProcessor', 'PretrainedBartModel', 'PretrainedConfig', 'PretrainedFSMTModel', 'PrinterCallback', 'ProcessorMixin', 'ProgressCallback', 'ProphetNetConfig', 'ProphetNetDecoder', 'ProphetNetEncoder', 'ProphetNetForCausalLM', 'ProphetNetForConditionalGeneration', 'ProphetNetModel', 'ProphetNetPreTrainedModel', 'ProphetNetTokenizer', 'PushToHubCallback', 'PvtConfig', 'PvtForImageClassification', 'PvtImageProcessor', 'PvtModel', 'PvtPreTrainedModel', 'PyTorchBenchmark', 'PyTorchBenchmarkArguments', 'QDQBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'QDQBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'QDQBertConfig', 'QDQBertForMaskedLM', 'QDQBertForMultipleChoice', 'QDQBertForNextSentencePrediction', 'QDQBertForQuestionAnswering', 'QDQBertForSequenceClassification', 'QDQBertForTokenClassification', 'QDQBertLMHeadModel', 'QDQBertLayer', 'QDQBertModel', 'QDQBertPreTrainedModel', 'QuestionAnsweringPipeline', 'REALM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REALM_PRETRAINED_MODEL_ARCHIVE_LIST', 'REFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'REGNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REGNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'REMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'REMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RESNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'RETRIBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RETRIBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROBERTA_PRELAYERNORM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROBERTA_PRELAYERNORM_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROC_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROC_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'ROFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'ROFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'RWKV_PRETRAINED_CONFIG_ARCHIVE_MAP', 'RWKV_PRETRAINED_MODEL_ARCHIVE_LIST', 'RagConfig', 'RagModel', 'RagPreTrainedModel', 'RagRetriever', 'RagSequenceForGeneration', 'RagTokenForGeneration', 'RagTokenizer', 'RealmConfig', 'RealmEmbedder', 'RealmForOpenQA', 'RealmKnowledgeAugEncoder', 'RealmPreTrainedModel', 'RealmReader', 'RealmRetriever', 'RealmScorer', 'RealmTokenizer', 'RealmTokenizerFast', 'ReformerAttention', 'ReformerConfig', 'ReformerForMaskedLM', 'ReformerForQuestionAnswering', 'ReformerForSequenceClassification', 'ReformerLayer', 'ReformerModel', 'ReformerModelWithLMHead', 'ReformerPreTrainedModel', 'ReformerTokenizer', 'ReformerTokenizerFast', 'RegNetConfig', 'RegNetForImageClassification', 'RegNetModel', 'RegNetPreTrainedModel', 'RemBertConfig', 'RemBertForCausalLM', 'RemBertForMaskedLM', 'RemBertForMultipleChoice', 'RemBertForQuestionAnswering', 'RemBertForSequenceClassification', 'RemBertForTokenClassification', 'RemBertLayer', 'RemBertModel', 'RemBertPreTrainedModel', 'RemBertTokenizer', 'RemBertTokenizerFast', 'RemoteTool', 'RepetitionPenaltyLogitsProcessor', 'ResNetBackbone', 'ResNetConfig', 'ResNetForImageClassification', 'ResNetModel', 'ResNetPreTrainedModel', 'RetriBertConfig', 'RetriBertModel', 'RetriBertPreTrainedModel', 'RetriBertTokenizer', 'RetriBertTokenizerFast', 'RoCBertConfig', 'RoCBertForCausalLM', 'RoCBertForMaskedLM', 'RoCBertForMultipleChoice', 'RoCBertForPreTraining', 'RoCBertForQuestionAnswering', 'RoCBertForSequenceClassification', 'RoCBertForTokenClassification', 'RoCBertLayer', 'RoCBertModel', 'RoCBertPreTrainedModel', 'RoCBertTokenizer', 'RoFormerConfig', 'RoFormerForCausalLM', 'RoFormerForMaskedLM', 'RoFormerForMultipleChoice', 'RoFormerForQuestionAnswering', 'RoFormerForSequenceClassification', 'RoFormerForTokenClassification', 'RoFormerLayer', 'RoFormerModel', 'RoFormerPreTrainedModel', 'RoFormerTokenizer', 'RoFormerTokenizerFast', 'RobertaConfig', 'RobertaForCausalLM', 'RobertaForMaskedLM', 'RobertaForMultipleChoice', 'RobertaForQuestionAnswering', 'RobertaForSequenceClassification', 'RobertaForTokenClassification', 'RobertaModel', 'RobertaPreLayerNormConfig', 'RobertaPreLayerNormForCausalLM', 'RobertaPreLayerNormForMaskedLM', 'RobertaPreLayerNormForMultipleChoice', 'RobertaPreLayerNormForQuestionAnswering', 'RobertaPreLayerNormForSequenceClassification', 'RobertaPreLayerNormForTokenClassification', 'RobertaPreLayerNormModel', 'RobertaPreLayerNormPreTrainedModel', 'RobertaPreTrainedModel', 'RobertaTokenizer', 'RobertaTokenizerFast', 'RwkvConfig', 'RwkvForCausalLM', 'RwkvModel', 'RwkvPreTrainedModel', 'SAM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SAM_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEAMLESS_M4T_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEAMLESS_M4T_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEWConfig', 'SEWDConfig', 'SEWDForCTC', 'SEWDForSequenceClassification', 'SEWDModel', 'SEWDPreTrainedModel', 'SEWForCTC', 'SEWForSequenceClassification', 'SEWModel', 'SEWPreTrainedModel', 'SEW_D_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEW_D_PRETRAINED_MODEL_ARCHIVE_LIST', 'SEW_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SEW_PRETRAINED_MODEL_ARCHIVE_LIST', 'SLOW_TO_FAST_CONVERTERS', 'SPEECHT5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECHT5_PRETRAINED_HIFIGAN_CONFIG_ARCHIVE_MAP', 'SPEECHT5_PRETRAINED_MODEL_ARCHIVE_LIST', 'SPEECH_TO_TEXT_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECH_TO_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPEECH_TO_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'SPIECE_UNDERLINE', 'SPLINTER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SPLINTER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SQUEEZEBERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SQUEEZEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWIFTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIFTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWIN2SR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIN2SR_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWINV2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWINV2_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'SWITCH_TRANSFORMERS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'SWITCH_TRANSFORMERS_PRETRAINED_MODEL_ARCHIVE_LIST', 'SamConfig', 'SamImageProcessor', 'SamMaskDecoderConfig', 'SamModel', 'SamPreTrainedModel', 'SamProcessor', 'SamPromptEncoderConfig', 'SamVisionConfig', 'SchedulerType', 'SeamlessM4TCodeHifiGan', 'SeamlessM4TConfig', 'SeamlessM4TFeatureExtractor', 'SeamlessM4TForSpeechToSpeech', 'SeamlessM4TForSpeechToText', 'SeamlessM4TForTextToSpeech', 'SeamlessM4TForTextToText', 'SeamlessM4THifiGan', 'SeamlessM4TModel', 'SeamlessM4TPreTrainedModel', 'SeamlessM4TProcessor', 'SeamlessM4TTextToUnitForConditionalGeneration', 'SeamlessM4TTextToUnitModel', 'SeamlessM4TTokenizer', 'SeamlessM4TTokenizerFast', 'SegformerConfig', 'SegformerDecodeHead', 'SegformerFeatureExtractor', 'SegformerForImageClassification', 'SegformerForSemanticSegmentation', 'SegformerImageProcessor', 'SegformerLayer', 'SegformerModel', 'SegformerPreTrainedModel', 'Seq2SeqTrainer', 'Seq2SeqTrainingArguments', 'SequenceBiasLogitsProcessor', 'SequenceFeatureExtractor', 'SingleSentenceClassificationProcessor', 'SpecialTokensMixin', 'Speech2Text2Config', 'Speech2Text2ForCausalLM', 'Speech2Text2PreTrainedModel', 'Speech2Text2Processor', 'Speech2Text2Tokenizer', 'Speech2TextConfig', 'Speech2TextFeatureExtractor', 'Speech2TextForConditionalGeneration', 'Speech2TextModel', 'Speech2TextPreTrainedModel', 'Speech2TextProcessor', 'Speech2TextTokenizer', 'SpeechEncoderDecoderConfig', 'SpeechEncoderDecoderModel', 'SpeechT5Config', 'SpeechT5FeatureExtractor', 'SpeechT5ForSpeechToSpeech', 'SpeechT5ForSpeechToText', 'SpeechT5ForTextToSpeech', 'SpeechT5HifiGan', 'SpeechT5HifiGanConfig', 'SpeechT5Model', 'SpeechT5PreTrainedModel', 'SpeechT5Processor', 'SpeechT5Tokenizer', 'SplinterConfig', 'SplinterForPreTraining', 'SplinterForQuestionAnswering', 'SplinterLayer', 'SplinterModel', 'SplinterPreTrainedModel', 'SplinterTokenizer', 'SplinterTokenizerFast', 'SquadDataTrainingArguments', 'SquadDataset', 'SquadExample', 'SquadFeatures', 'SquadV1Processor', 'SquadV2Processor', 'SqueezeBertConfig', 'SqueezeBertForMaskedLM', 'SqueezeBertForMultipleChoice', 'SqueezeBertForQuestionAnswering', 'SqueezeBertForSequenceClassification', 'SqueezeBertForTokenClassification', 'SqueezeBertModel', 'SqueezeBertModule', 'SqueezeBertPreTrainedModel', 'SqueezeBertTokenizer', 'SqueezeBertTokenizerFast', 'StoppingCriteria', 'StoppingCriteriaList', 'SummarizationPipeline', 'SuppressTokensAtBeginLogitsProcessor', 'SuppressTokensLogitsProcessor', 'SwiftFormerConfig', 'SwiftFormerForImageClassification', 'SwiftFormerModel', 'SwiftFormerPreTrainedModel', 'Swin2SRConfig', 'Swin2SRForImageSuperResolution', 'Swin2SRImageProcessor', 'Swin2SRModel', 'Swin2SRPreTrainedModel', 'SwinBackbone', 'SwinConfig', 'SwinForImageClassification', 'SwinForMaskedImageModeling', 'SwinModel', 'SwinPreTrainedModel', 'Swinv2Config', 'Swinv2ForImageClassification', 'Swinv2ForMaskedImageModeling', 'Swinv2Model', 'Swinv2PreTrainedModel', 'SwitchTransformersConfig', 'SwitchTransformersEncoderModel', 'SwitchTransformersForConditionalGeneration', 'SwitchTransformersModel', 'SwitchTransformersPreTrainedModel', 'SwitchTransformersSparseMLP', 'SwitchTransformersTop1Router', 'T5Config', 'T5EncoderModel', 'T5ForConditionalGeneration', 'T5ForQuestionAnswering', 'T5ForSequenceClassification', 'T5Model', 'T5PreTrainedModel', 'T5Tokenizer', 'T5TokenizerFast', 'T5_PRETRAINED_CONFIG_ARCHIVE_MAP', 'T5_PRETRAINED_MODEL_ARCHIVE_LIST', 'TABLE_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TABLE_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TAPAS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TAPAS_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF2_WEIGHTS_NAME', 'TFAdaptiveEmbedding', 'TFAlbertForMaskedLM', 'TFAlbertForMultipleChoice', 'TFAlbertForPreTraining', 'TFAlbertForQuestionAnswering', 'TFAlbertForSequenceClassification', 'TFAlbertForTokenClassification', 'TFAlbertMainLayer', 'TFAlbertModel', 'TFAlbertPreTrainedModel', 'TFAutoModel', 'TFAutoModelForAudioClassification', 'TFAutoModelForCausalLM', 'TFAutoModelForDocumentQuestionAnswering', 'TFAutoModelForImageClassification', 'TFAutoModelForMaskGeneration', 'TFAutoModelForMaskedImageModeling', 'TFAutoModelForMaskedLM', 'TFAutoModelForMultipleChoice', 'TFAutoModelForNextSentencePrediction', 'TFAutoModelForPreTraining', 'TFAutoModelForQuestionAnswering', 'TFAutoModelForSemanticSegmentation', 'TFAutoModelForSeq2SeqLM', 'TFAutoModelForSequenceClassification', 'TFAutoModelForSpeechSeq2Seq', 'TFAutoModelForTableQuestionAnswering', 'TFAutoModelForTextEncoding', 'TFAutoModelForTokenClassification', 'TFAutoModelForVision2Seq', 'TFAutoModelForZeroShotImageClassification', 'TFAutoModelWithLMHead', 'TFBartForConditionalGeneration', 'TFBartForSequenceClassification', 'TFBartModel', 'TFBartPretrainedModel', 'TFBertEmbeddings', 'TFBertForMaskedLM', 'TFBertForMultipleChoice', 'TFBertForNextSentencePrediction', 'TFBertForPreTraining', 'TFBertForQuestionAnswering', 'TFBertForSequenceClassification', 'TFBertForTokenClassification', 'TFBertLMHeadModel', 'TFBertMainLayer', 'TFBertModel', 'TFBertPreTrainedModel', 'TFBertTokenizer', 'TFBlenderbotForConditionalGeneration', 'TFBlenderbotModel', 'TFBlenderbotPreTrainedModel', 'TFBlenderbotSmallForConditionalGeneration', 'TFBlenderbotSmallModel', 'TFBlenderbotSmallPreTrainedModel', 'TFBlipForConditionalGeneration', 'TFBlipForImageTextRetrieval', 'TFBlipForQuestionAnswering', 'TFBlipModel', 'TFBlipPreTrainedModel', 'TFBlipTextModel', 'TFBlipVisionModel', 'TFCLIPModel', 'TFCLIPPreTrainedModel', 'TFCLIPTextModel', 'TFCLIPVisionModel', 'TFCTRLForSequenceClassification', 'TFCTRLLMHeadModel', 'TFCTRLModel', 'TFCTRLPreTrainedModel', 'TFCamembertForCausalLM', 'TFCamembertForMaskedLM', 'TFCamembertForMultipleChoice', 'TFCamembertForQuestionAnswering', 'TFCamembertForSequenceClassification', 'TFCamembertForTokenClassification', 'TFCamembertModel', 'TFCamembertPreTrainedModel', 'TFConvBertForMaskedLM', 'TFConvBertForMultipleChoice', 'TFConvBertForQuestionAnswering', 'TFConvBertForSequenceClassification', 'TFConvBertForTokenClassification', 'TFConvBertLayer', 'TFConvBertModel', 'TFConvBertPreTrainedModel', 'TFConvNextForImageClassification', 'TFConvNextModel', 'TFConvNextPreTrainedModel', 'TFConvNextV2ForImageClassification', 'TFConvNextV2Model', 'TFConvNextV2PreTrainedModel', 'TFCvtForImageClassification', 'TFCvtModel', 'TFCvtPreTrainedModel', 'TFDPRContextEncoder', 'TFDPRPretrainedContextEncoder', 'TFDPRPretrainedQuestionEncoder', 'TFDPRPretrainedReader', 'TFDPRQuestionEncoder', 'TFDPRReader', 'TFData2VecVisionForImageClassification', 'TFData2VecVisionForSemanticSegmentation', 'TFData2VecVisionModel', 'TFData2VecVisionPreTrainedModel', 'TFDebertaForMaskedLM', 'TFDebertaForQuestionAnswering', 'TFDebertaForSequenceClassification', 'TFDebertaForTokenClassification', 'TFDebertaModel', 'TFDebertaPreTrainedModel', 'TFDebertaV2ForMaskedLM', 'TFDebertaV2ForMultipleChoice', 'TFDebertaV2ForQuestionAnswering', 'TFDebertaV2ForSequenceClassification', 'TFDebertaV2ForTokenClassification', 'TFDebertaV2Model', 'TFDebertaV2PreTrainedModel', 'TFDeiTForImageClassification', 'TFDeiTForImageClassificationWithTeacher', 'TFDeiTForMaskedImageModeling', 'TFDeiTModel', 'TFDeiTPreTrainedModel', 'TFDistilBertForMaskedLM', 'TFDistilBertForMultipleChoice', 'TFDistilBertForQuestionAnswering', 'TFDistilBertForSequenceClassification', 'TFDistilBertForTokenClassification', 'TFDistilBertMainLayer', 'TFDistilBertModel', 'TFDistilBertPreTrainedModel', 'TFEfficientFormerForImageClassification', 'TFEfficientFormerForImageClassificationWithTeacher', 'TFEfficientFormerModel', 'TFEfficientFormerPreTrainedModel', 'TFElectraForMaskedLM', 'TFElectraForMultipleChoice', 'TFElectraForPreTraining', 'TFElectraForQuestionAnswering', 'TFElectraForSequenceClassification', 'TFElectraForTokenClassification', 'TFElectraModel', 'TFElectraPreTrainedModel', 'TFEncoderDecoderModel', 'TFEsmForMaskedLM', 'TFEsmForSequenceClassification', 'TFEsmForTokenClassification', 'TFEsmModel', 'TFEsmPreTrainedModel', 'TFFlaubertForMultipleChoice', 'TFFlaubertForQuestionAnsweringSimple', 'TFFlaubertForSequenceClassification', 'TFFlaubertForTokenClassification', 'TFFlaubertModel', 'TFFlaubertPreTrainedModel', 'TFFlaubertWithLMHeadModel', 'TFForceTokensLogitsProcessor', 'TFForcedBOSTokenLogitsProcessor', 'TFForcedEOSTokenLogitsProcessor', 'TFFunnelBaseModel', 'TFFunnelForMaskedLM', 'TFFunnelForMultipleChoice', 'TFFunnelForPreTraining', 'TFFunnelForQuestionAnswering', 'TFFunnelForSequenceClassification', 'TFFunnelForTokenClassification', 'TFFunnelModel', 'TFFunnelPreTrainedModel', 'TFGPT2DoubleHeadsModel', 'TFGPT2ForSequenceClassification', 'TFGPT2LMHeadModel', 'TFGPT2MainLayer', 'TFGPT2Model', 'TFGPT2PreTrainedModel', 'TFGPT2Tokenizer', 'TFGPTJForCausalLM', 'TFGPTJForQuestionAnswering', 'TFGPTJForSequenceClassification', 'TFGPTJModel', 'TFGPTJPreTrainedModel', 'TFGenerationMixin', 'TFGroupViTModel', 'TFGroupViTPreTrainedModel', 'TFGroupViTTextModel', 'TFGroupViTVisionModel', 'TFHubertForCTC', 'TFHubertModel', 'TFHubertPreTrainedModel', 'TFLEDForConditionalGeneration', 'TFLEDModel', 'TFLEDPreTrainedModel', 'TFLayoutLMForMaskedLM', 'TFLayoutLMForQuestionAnswering', 'TFLayoutLMForSequenceClassification', 'TFLayoutLMForTokenClassification', 'TFLayoutLMMainLayer', 'TFLayoutLMModel', 'TFLayoutLMPreTrainedModel', 'TFLayoutLMv3ForQuestionAnswering', 'TFLayoutLMv3ForSequenceClassification', 'TFLayoutLMv3ForTokenClassification', 'TFLayoutLMv3Model', 'TFLayoutLMv3PreTrainedModel', 'TFLogitsProcessor', 'TFLogitsProcessorList', 'TFLogitsWarper', 'TFLongformerForMaskedLM', 'TFLongformerForMultipleChoice', 'TFLongformerForQuestionAnswering', 'TFLongformerForSequenceClassification', 'TFLongformerForTokenClassification', 'TFLongformerModel', 'TFLongformerPreTrainedModel', 'TFLongformerSelfAttention', 'TFLxmertForPreTraining', 'TFLxmertMainLayer', 'TFLxmertModel', 'TFLxmertPreTrainedModel', 'TFLxmertVisualFeatureEncoder', 'TFMBartForConditionalGeneration', 'TFMBartModel', 'TFMBartPreTrainedModel', 'TFMPNetForMaskedLM', 'TFMPNetForMultipleChoice', 'TFMPNetForQuestionAnswering', 'TFMPNetForSequenceClassification', 'TFMPNetForTokenClassification', 'TFMPNetMainLayer', 'TFMPNetModel', 'TFMPNetPreTrainedModel', 'TFMT5EncoderModel', 'TFMT5ForConditionalGeneration', 'TFMT5Model', 'TFMarianMTModel', 'TFMarianModel', 'TFMarianPreTrainedModel', 'TFMinLengthLogitsProcessor', 'TFMobileBertForMaskedLM', 'TFMobileBertForMultipleChoice', 'TFMobileBertForNextSentencePrediction', 'TFMobileBertForPreTraining', 'TFMobileBertForQuestionAnswering', 'TFMobileBertForSequenceClassification', 'TFMobileBertForTokenClassification', 'TFMobileBertMainLayer', 'TFMobileBertModel', 'TFMobileBertPreTrainedModel', 'TFMobileViTForImageClassification', 'TFMobileViTForSemanticSegmentation', 'TFMobileViTModel', 'TFMobileViTPreTrainedModel', 'TFNoBadWordsLogitsProcessor', 'TFNoRepeatNGramLogitsProcessor', 'TFOPTForCausalLM', 'TFOPTModel', 'TFOPTPreTrainedModel', 'TFOpenAIGPTDoubleHeadsModel', 'TFOpenAIGPTForSequenceClassification', 'TFOpenAIGPTLMHeadModel', 'TFOpenAIGPTMainLayer', 'TFOpenAIGPTModel', 'TFOpenAIGPTPreTrainedModel', 'TFPegasusForConditionalGeneration', 'TFPegasusModel', 'TFPegasusPreTrainedModel', 'TFPreTrainedModel', 'TFRagModel', 'TFRagPreTrainedModel', 'TFRagSequenceForGeneration', 'TFRagTokenForGeneration', 'TFRegNetForImageClassification', 'TFRegNetModel', 'TFRegNetPreTrainedModel', 'TFRemBertForCausalLM', 'TFRemBertForMaskedLM', 'TFRemBertForMultipleChoice', 'TFRemBertForQuestionAnswering', 'TFRemBertForSequenceClassification', 'TFRemBertForTokenClassification', 'TFRemBertLayer', 'TFRemBertModel', 'TFRemBertPreTrainedModel', 'TFRepetitionPenaltyLogitsProcessor', 'TFResNetForImageClassification', 'TFResNetModel', 'TFResNetPreTrainedModel', 'TFRoFormerForCausalLM', 'TFRoFormerForMaskedLM', 'TFRoFormerForMultipleChoice', 'TFRoFormerForQuestionAnswering', 'TFRoFormerForSequenceClassification', 'TFRoFormerForTokenClassification', 'TFRoFormerLayer', 'TFRoFormerModel', 'TFRoFormerPreTrainedModel', 'TFRobertaForCausalLM', 'TFRobertaForMaskedLM', 'TFRobertaForMultipleChoice', 'TFRobertaForQuestionAnswering', 'TFRobertaForSequenceClassification', 'TFRobertaForTokenClassification', 'TFRobertaMainLayer', 'TFRobertaModel', 'TFRobertaPreLayerNormForCausalLM', 'TFRobertaPreLayerNormForMaskedLM', 'TFRobertaPreLayerNormForMultipleChoice', 'TFRobertaPreLayerNormForQuestionAnswering', 'TFRobertaPreLayerNormForSequenceClassification', 'TFRobertaPreLayerNormForTokenClassification', 'TFRobertaPreLayerNormMainLayer', 'TFRobertaPreLayerNormModel', 'TFRobertaPreLayerNormPreTrainedModel', 'TFRobertaPreTrainedModel', 'TFSamModel', 'TFSamPreTrainedModel', 'TFSegformerDecodeHead', 'TFSegformerForImageClassification', 'TFSegformerForSemanticSegmentation', 'TFSegformerModel', 'TFSegformerPreTrainedModel', 'TFSequenceSummary', 'TFSharedEmbeddings', 'TFSpeech2TextForConditionalGeneration', 'TFSpeech2TextModel', 'TFSpeech2TextPreTrainedModel', 'TFSuppressTokensAtBeginLogitsProcessor', 'TFSuppressTokensLogitsProcessor', 'TFSwinForImageClassification', 'TFSwinForMaskedImageModeling', 'TFSwinModel', 'TFSwinPreTrainedModel', 'TFT5EncoderModel', 'TFT5ForConditionalGeneration', 'TFT5Model', 'TFT5PreTrainedModel', 'TFTapasForMaskedLM', 'TFTapasForQuestionAnswering', 'TFTapasForSequenceClassification', 'TFTapasModel', 'TFTapasPreTrainedModel', 'TFTemperatureLogitsWarper', 'TFTopKLogitsWarper', 'TFTopPLogitsWarper', 'TFTrainer', 'TFTrainingArguments', 'TFTransfoXLForSequenceClassification', 'TFTransfoXLLMHeadModel', 'TFTransfoXLMainLayer', 'TFTransfoXLModel', 'TFTransfoXLPreTrainedModel', 'TFViTForImageClassification', 'TFViTMAEForPreTraining', 'TFViTMAEModel', 'TFViTMAEPreTrainedModel', 'TFViTModel', 'TFViTPreTrainedModel', 'TFVisionEncoderDecoderModel', 'TFVisionTextDualEncoderModel', 'TFWav2Vec2ForCTC', 'TFWav2Vec2ForSequenceClassification', 'TFWav2Vec2Model', 'TFWav2Vec2PreTrainedModel', 'TFWhisperForConditionalGeneration', 'TFWhisperModel', 'TFWhisperPreTrainedModel', 'TFXGLMForCausalLM', 'TFXGLMModel', 'TFXGLMPreTrainedModel', 'TFXLMForMultipleChoice', 'TFXLMForQuestionAnsweringSimple', 'TFXLMForSequenceClassification', 'TFXLMForTokenClassification', 'TFXLMMainLayer', 'TFXLMModel', 'TFXLMPreTrainedModel', 'TFXLMRobertaForCausalLM', 'TFXLMRobertaForMaskedLM', 'TFXLMRobertaForMultipleChoice', 'TFXLMRobertaForQuestionAnswering', 'TFXLMRobertaForSequenceClassification', 'TFXLMRobertaForTokenClassification', 'TFXLMRobertaModel', 'TFXLMRobertaPreTrainedModel', 'TFXLMWithLMHeadModel', 'TFXLNetForMultipleChoice', 'TFXLNetForQuestionAnsweringSimple', 'TFXLNetForSequenceClassification', 'TFXLNetForTokenClassification', 'TFXLNetLMHeadModel', 'TFXLNetMainLayer', 'TFXLNetModel', 'TFXLNetPreTrainedModel', 'TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_BLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CTRL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_CVT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DEIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_GPT2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LAYOUTLMV3_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_LXMERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MOBILEBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MOBILEVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING', 'TF_MODEL_FOR_MASKED_LM_MAPPING', 'TF_MODEL_FOR_MASK_GENERATION_MAPPING', 'TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING', 'TF_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING', 'TF_MODEL_FOR_PRETRAINING_MAPPING', 'TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING', 'TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING', 'TF_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING', 'TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING', 'TF_MODEL_FOR_TEXT_ENCODING_MAPPING', 'TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING', 'TF_MODEL_FOR_VISION_2_SEQ_MAPPING', 'TF_MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING', 'TF_MODEL_MAPPING', 'TF_MODEL_WITH_LM_HEAD_MAPPING', 'TF_MPNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_REGNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_REMBERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_RESNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROBERTA_PRELAYERNORM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_ROFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SAM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SEGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SPEECH_TO_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_T5_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_TAPAS_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_WAV_2_VEC_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_WEIGHTS_NAME', 'TF_WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XGLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'TF_XLNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'TIMESFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TIMESFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TIME_SERIES_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TIME_SERIES_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TOKENIZER_MAPPING', 'TRAJECTORY_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TRAJECTORY_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'TRANSFORMERS_CACHE', 'TRANSFO_XL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'TROCR_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TROCR_PRETRAINED_MODEL_ARCHIVE_LIST', 'TVLT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'TVLT_PRETRAINED_MODEL_ARCHIVE_LIST', 'TableQuestionAnsweringPipeline', 'TableTransformerConfig', 'TableTransformerForObjectDetection', 'TableTransformerModel', 'TableTransformerPreTrainedModel', 'TapasConfig', 'TapasForMaskedLM', 'TapasForQuestionAnswering', 'TapasForSequenceClassification', 'TapasModel', 'TapasPreTrainedModel', 'TapasTokenizer', 'TapexTokenizer', 'TemperatureLogitsWarper', 'TensorFlowBenchmark', 'TensorFlowBenchmarkArguments', 'TensorType', 'Text2TextGenerationPipeline', 'TextClassificationPipeline', 'TextDataset', 'TextDatasetForNextSentencePrediction', 'TextGenerationPipeline', 'TextIteratorStreamer', 'TextStreamer', 'TextToAudioPipeline', 'TimeSeriesTransformerConfig', 'TimeSeriesTransformerForPrediction', 'TimeSeriesTransformerModel', 'TimeSeriesTransformerPreTrainedModel', 'TimesformerConfig', 'TimesformerForVideoClassification', 'TimesformerModel', 'TimesformerPreTrainedModel', 'TimmBackbone', 'TimmBackboneConfig', 'TokenClassificationPipeline', 'TokenSpan', 'Tool', 'TopKLogitsWarper', 'TopPLogitsWarper', 'TrOCRConfig', 'TrOCRForCausalLM', 'TrOCRPreTrainedModel', 'TrOCRProcessor', 'Trainer', 'TrainerCallback', 'TrainerControl', 'TrainerState', 'TrainingArguments', 'TrajectoryTransformerConfig', 'TrajectoryTransformerModel', 'TrajectoryTransformerPreTrainedModel', 'TransfoXLConfig', 'TransfoXLCorpus', 'TransfoXLForSequenceClassification', 'TransfoXLLMHeadModel', 'TransfoXLModel', 'TransfoXLPreTrainedModel', 'TransfoXLTokenizer', 'TranslationPipeline', 'TvltConfig', 'TvltFeatureExtractor', 'TvltForAudioVisualClassification', 'TvltForPreTraining', 'TvltImageProcessor', 'TvltModel', 'TvltPreTrainedModel', 'TvltProcessor', 'TypicalLogitsWarper', 'UMT5Config', 'UMT5EncoderModel', 'UMT5ForConditionalGeneration', 'UMT5ForQuestionAnswering', 'UMT5ForSequenceClassification', 'UMT5Model', 'UMT5PreTrainedModel', 'UNISPEECH_PRETRAINED_CONFIG_ARCHIVE_MAP', 'UNISPEECH_PRETRAINED_MODEL_ARCHIVE_LIST', 'UNISPEECH_SAT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'UNISPEECH_SAT_PRETRAINED_MODEL_ARCHIVE_LIST', 'UnbatchedClassifierFreeGuidanceLogitsProcessor', 'UniSpeechConfig', 'UniSpeechForCTC', 'UniSpeechForPreTraining', 'UniSpeechForSequenceClassification', 'UniSpeechModel', 'UniSpeechPreTrainedModel', 'UniSpeechSatConfig', 'UniSpeechSatForAudioFrameClassification', 'UniSpeechSatForCTC', 'UniSpeechSatForPreTraining', 'UniSpeechSatForSequenceClassification', 'UniSpeechSatForXVector', 'UniSpeechSatModel', 'UniSpeechSatPreTrainedModel', 'UperNetConfig', 'UperNetForSemanticSegmentation', 'UperNetPreTrainedModel', 'VAN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VAN_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIDEOMAE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIDEOMAE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VILT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VILT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VISUAL_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VISUAL_BERT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITDET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITDET_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITMATTE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITMATTE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VITS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VITS_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_HYBRID_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_HYBRID_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_MAE_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_MAE_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_MSN_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_MSN_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VIVIT_PRETRAINED_CONFIG_ARCHIVE_MAP', 'VIVIT_PRETRAINED_MODEL_ARCHIVE_LIST', 'VanConfig', 'VanForImageClassification', 'VanModel', 'VanPreTrainedModel', 'ViTConfig', 'ViTFeatureExtractor', 'ViTForImageClassification', 'ViTForMaskedImageModeling', 'ViTHybridConfig', 'ViTHybridForImageClassification', 'ViTHybridImageProcessor', 'ViTHybridModel', 'ViTHybridPreTrainedModel', 'ViTImageProcessor', 'ViTMAEConfig', 'ViTMAEForPreTraining', 'ViTMAELayer', 'ViTMAEModel', 'ViTMAEPreTrainedModel', 'ViTMSNConfig', 'ViTMSNForImageClassification', 'ViTMSNModel', 'ViTMSNPreTrainedModel', 'ViTModel', 'ViTPreTrainedModel', 'VideoClassificationPipeline', 'VideoMAEConfig', 'VideoMAEFeatureExtractor', 'VideoMAEForPreTraining', 'VideoMAEForVideoClassification', 'VideoMAEImageProcessor', 'VideoMAEModel', 'VideoMAEPreTrainedModel', 'ViltConfig', 'ViltFeatureExtractor', 'ViltForImageAndTextRetrieval', 'ViltForImagesAndTextClassification', 'ViltForMaskedLM', 'ViltForQuestionAnswering', 'ViltForTokenClassification', 'ViltImageProcessor', 'ViltLayer', 'ViltModel', 'ViltPreTrainedModel', 'ViltProcessor', 'VisionEncoderDecoderConfig', 'VisionEncoderDecoderModel', 'VisionTextDualEncoderConfig', 'VisionTextDualEncoderModel', 'VisionTextDualEncoderProcessor', 'VisualBertConfig', 'VisualBertForMultipleChoice', 'VisualBertForPreTraining', 'VisualBertForQuestionAnswering', 'VisualBertForRegionToPhraseAlignment', 'VisualBertForVisualReasoning', 'VisualBertLayer', 'VisualBertModel', 'VisualBertPreTrainedModel', 'VisualQuestionAnsweringPipeline', 'VitDetBackbone', 'VitDetConfig', 'VitDetModel', 'VitDetPreTrainedModel', 'VitMatteConfig', 'VitMatteForImageMatting', 'VitMatteImageProcessor', 'VitMattePreTrainedModel', 'VitsConfig', 'VitsModel', 'VitsPreTrainedModel', 'VitsTokenizer', 'VivitConfig', 'VivitForVideoClassification', 'VivitImageProcessor', 'VivitModel', 'VivitPreTrainedModel', 'WAV2VEC2_CONFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAV2VEC2_CONFORMER_PRETRAINED_MODEL_ARCHIVE_LIST', 'WAVLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAVLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'WAV_2_VEC_2_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WAV_2_VEC_2_PRETRAINED_MODEL_ARCHIVE_LIST', 'WEIGHTS_NAME', 'WHISPER_PRETRAINED_CONFIG_ARCHIVE_MAP', 'WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST', 'WarmUp', 'Wav2Vec2CTCTokenizer', 'Wav2Vec2Config', 'Wav2Vec2ConformerConfig', 'Wav2Vec2ConformerForAudioFrameClassification', 'Wav2Vec2ConformerForCTC', 'Wav2Vec2ConformerForPreTraining', 'Wav2Vec2ConformerForSequenceClassification', 'Wav2Vec2ConformerForXVector', 'Wav2Vec2ConformerModel', 'Wav2Vec2ConformerPreTrainedModel', 'Wav2Vec2FeatureExtractor', 'Wav2Vec2ForAudioFrameClassification', 'Wav2Vec2ForCTC', 'Wav2Vec2ForMaskedLM', 'Wav2Vec2ForPreTraining', 'Wav2Vec2ForSequenceClassification', 'Wav2Vec2ForXVector', 'Wav2Vec2Model', 'Wav2Vec2PhonemeCTCTokenizer', 'Wav2Vec2PreTrainedModel', 'Wav2Vec2Processor', 'Wav2Vec2ProcessorWithLM', 'Wav2Vec2Tokenizer', 'WavLMConfig', 'WavLMForAudioFrameClassification', 'WavLMForCTC', 'WavLMForSequenceClassification', 'WavLMForXVector', 'WavLMModel', 'WavLMPreTrainedModel', 'WhisperConfig', 'WhisperFeatureExtractor', 'WhisperForAudioClassification', 'WhisperForCausalLM', 'WhisperForConditionalGeneration', 'WhisperModel', 'WhisperPreTrainedModel', 'WhisperProcessor', 'WhisperTimeStampLogitsProcessor', 'WhisperTokenizer', 'WhisperTokenizerFast', 'WordpieceTokenizer', 'XCLIPConfig', 'XCLIPModel', 'XCLIPPreTrainedModel', 'XCLIPProcessor', 'XCLIPTextConfig', 'XCLIPTextModel', 'XCLIPVisionConfig', 'XCLIPVisionModel', 'XCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XCLIP_PRETRAINED_MODEL_ARCHIVE_LIST', 'XGLMConfig', 'XGLMForCausalLM', 'XGLMModel', 'XGLMPreTrainedModel', 'XGLMTokenizer', 'XGLMTokenizerFast', 'XGLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XGLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLMConfig', 'XLMForMultipleChoice', 'XLMForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMForSequenceClassification', 'XLMForTokenClassification', 'XLMModel', 'XLMPreTrainedModel', 'XLMProphetNetConfig', 'XLMProphetNetDecoder', 'XLMProphetNetEncoder', 'XLMProphetNetForCausalLM', 'XLMProphetNetForConditionalGeneration', 'XLMProphetNetModel', 'XLMProphetNetPreTrainedModel', 'XLMProphetNetTokenizer', 'XLMRobertaConfig', 'XLMRobertaForCausalLM', 'XLMRobertaForMaskedLM', 'XLMRobertaForMultipleChoice', 'XLMRobertaForQuestionAnswering', 'XLMRobertaForSequenceClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaModel', 'XLMRobertaPreTrainedModel', 'XLMRobertaTokenizer', 'XLMRobertaTokenizerFast', 'XLMRobertaXLConfig', 'XLMRobertaXLForCausalLM', 'XLMRobertaXLForMaskedLM', 'XLMRobertaXLForMultipleChoice', 'XLMRobertaXLForQuestionAnswering', 'XLMRobertaXLForSequenceClassification', 'XLMRobertaXLForTokenClassification', 'XLMRobertaXLModel', 'XLMRobertaXLPreTrainedModel', 'XLMTokenizer', 'XLMWithLMHeadModel', 'XLM_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_PROPHETNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_PROPHETNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLM_ROBERTA_XL_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLM_ROBERTA_XL_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLNET_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XLNET_PRETRAINED_MODEL_ARCHIVE_LIST', 'XLNetConfig', 'XLNetForMultipleChoice', 'XLNetForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XLNetForSequenceClassification', 'XLNetForTokenClassification', 'XLNetLMHeadModel', 'XLNetModel', 'XLNetPreTrainedModel', 'XLNetTokenizer', 'XLNetTokenizerFast', 'XMOD_PRETRAINED_CONFIG_ARCHIVE_MAP', 'XMOD_PRETRAINED_MODEL_ARCHIVE_LIST', 'XmodConfig', 'XmodForCausalLM', 'XmodForMaskedLM', 'XmodForMultipleChoice', 'XmodForQuestionAnswering', 'XmodForSequenceClassification', 'XmodForTokenClassification', 'XmodModel', 'XmodPreTrainedModel', 'YOLOS_PRETRAINED_CONFIG_ARCHIVE_MAP', 'YOLOS_PRETRAINED_MODEL_ARCHIVE_LIST', 'YOSO_PRETRAINED_CONFIG_ARCHIVE_MAP', 'YOSO_PRETRAINED_MODEL_ARCHIVE_LIST', 'YolosConfig', 'YolosFeatureExtractor', 'YolosForObjectDetection', 'YolosImageProcessor', 'YolosModel', 'YolosPreTrainedModel', 'YosoConfig', 'YosoForMaskedLM', 'YosoForMultipleChoice', 'YosoForQuestionAnswering', 'YosoForSequenceClassification', 'YosoForTokenClassification', 'YosoLayer', 'YosoModel', 'YosoPreTrainedModel', 'ZeroShotAudioClassificationPipeline', 'ZeroShotClassificationPipeline', 'ZeroShotImageClassificationPipeline', 'ZeroShotObjectDetectionPipeline', '__all__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_class_to_module', '_import_structure', '_modules', '_name', '_objects', 'activations', 'add_end_docstrings', 'add_start_docstrings', 'apply_chunking_to_forward', 'audio_utils', 'benchmark', 'benchmark.benchmark', 'benchmark.benchmark_args', 'commands', 'configuration_utils', 'convert_graph_to_onnx', 'convert_slow_tokenizer', 'convert_slow_tokenizers_checkpoints_to_fast', 'convert_tf_hub_seq_to_seq_bert_to_pytorch', 'convert_tf_weight_name_to_pt_weight_name', 'create_optimizer', 'data', 'data.data_collator', 'data.datasets', 'data.metrics', 'data.processors', 'debug_utils', 'deepspeed', 'default_data_collator', 'dependency_versions_check', 'dependency_versions_table', 'dynamic_module_utils', 'enable_full_determinism', 'feature_extraction_sequence_utils', 'feature_extraction_utils', 'file_utils', 'generation', 'generation_utils', 'get_constant_schedule', 'get_constant_schedule_with_warmup', 'get_cosine_schedule_with_warmup', 'get_cosine_with_hard_restarts_schedule_with_warmup', 'get_inverse_sqrt_schedule', 'get_linear_schedule_with_warmup', 'get_polynomial_decay_schedule_with_warmup', 'get_scheduler', 'glue_compute_metrics', 'glue_convert_examples_to_features', 'glue_output_modes', 'glue_processors', 'glue_tasks_num_labels', 'hf_argparser', 'hyperparameter_search', 'image_processing_utils', 'image_transforms', 'image_utils', 'integrations', 'is_apex_available', 'is_bitsandbytes_available', 'is_clearml_available', 'is_comet_available', 'is_datasets_available', 'is_decord_available', 'is_faiss_available', 'is_flax_available', 'is_keras_nlp_available', 'is_neptune_available', 'is_optuna_available', 'is_phonemizer_available', 'is_psutil_available', 'is_py3nvml_available', 'is_pyctcdecode_available', 'is_ray_available', 'is_ray_tune_available', 'is_safetensors_available', 'is_scipy_available', 'is_sentencepiece_available', 'is_sigopt_available', 'is_sklearn_available', 'is_speech_available', 'is_tensorboard_available', 'is_tensorflow_text_available', 'is_tf_available', 'is_timm_available', 'is_tokenizers_available', 'is_torch_available', 'is_torch_neuroncore_available', 'is_torch_npu_available', 'is_torch_tpu_available', 'is_torch_xpu_available', 'is_torchvision_available', 'is_vision_available', 'is_wandb_available', 'launch_gradio_demo', 'load_pytorch_checkpoint_in_tf2_model', 'load_pytorch_model_in_tf2_model', 'load_pytorch_weights_in_tf2_model', 'load_tf2_checkpoint_in_pytorch_model', 'load_tf2_model_in_pytorch_model', 'load_tf2_weights_in_pytorch_model', 'load_tf_weights_in_albert', 'load_tf_weights_in_bert', 'load_tf_weights_in_bert_generation', 'load_tf_weights_in_big_bird', 'load_tf_weights_in_canine', 'load_tf_weights_in_convbert', 'load_tf_weights_in_electra', 'load_tf_weights_in_funnel', 'load_tf_weights_in_gpt2', 'load_tf_weights_in_gpt_neo', 'load_tf_weights_in_imagegpt', 'load_tf_weights_in_mobilebert', 'load_tf_weights_in_mobilenet_v1', 'load_tf_weights_in_mobilenet_v2', 'load_tf_weights_in_openai_gpt', 'load_tf_weights_in_qdqbert', 'load_tf_weights_in_realm', 'load_tf_weights_in_rembert', 'load_tf_weights_in_roc_bert', 'load_tf_weights_in_roformer', 'load_tf_weights_in_t5', 'load_tf_weights_in_tapas', 'load_tf_weights_in_transfo_xl', 'load_tf_weights_in_xlnet', 'load_tool', 'logging', 'modelcard', 'modeling_outputs', 'modeling_tf_pytorch_utils', 'modeling_utils', 'models', 'models.albert', 'models.align', 'models.altclip', 'models.audio_spectrogram_transformer', 'models.auto', 'models.autoformer', 'models.bark', 'models.bart', 'models.barthez', 'models.bartpho', 'models.beit', 'models.bert', 'models.bert_generation', 'models.bert_japanese', 'models.bertweet', 'models.big_bird', 'models.bigbird_pegasus', 'models.biogpt', 'models.bit', 'models.blenderbot', 'models.blenderbot_small', 'models.blip', 'models.blip_2', 'models.bloom', 'models.bridgetower', 'models.bros', 'models.byt5', 'models.camembert', 'models.canine', 'models.chinese_clip', 'models.clap', 'models.clip', 'models.clipseg', 'models.code_llama', 'models.codegen', 'models.conditional_detr', 'models.convbert', 'models.convnext', 'models.convnextv2', 'models.cpm', 'models.cpmant', 'models.ctrl', 'models.cvt', 'models.data2vec', 'models.deberta', 'models.deberta_v2', 'models.decision_transformer', 'models.deformable_detr', 'models.deit', 'models.deprecated', 'models.deprecated.bort', 'models.deprecated.mctct', 'models.deprecated.mmbt', 'models.deprecated.open_llama', 'models.deprecated.retribert', 'models.deprecated.tapex', 'models.deprecated.trajectory_transformer', 'models.deprecated.van', 'models.deta', 'models.detr', 'models.dialogpt', 'models.dinat', 'models.dinov2', 'models.distilbert', 'models.dit', 'models.donut', 'models.dpr', 'models.dpt', 'models.efficientformer', 'models.efficientnet', 'models.electra', 'models.encodec', 'models.encoder_decoder', 'models.ernie', 'models.ernie_m', 'models.esm', 'models.falcon', 'models.flaubert', 'models.flava', 'models.fnet', 'models.focalnet', 'models.fsmt', 'models.funnel', 'models.fuyu', 'models.git', 'models.glpn', 'models.gpt2', 'models.gpt_bigcode', 'models.gpt_neo', 'models.gpt_neox', 'models.gpt_neox_japanese', 'models.gpt_sw3', 'models.gptj', 'models.gptsan_japanese', 'models.graphormer', 'models.groupvit', 'models.herbert', 'models.hubert', 'models.ibert', 'models.idefics', 'models.imagegpt', 'models.informer', 'models.instructblip', 'models.jukebox', 'models.kosmos2', 'models.layoutlm', 'models.layoutlmv2', 'models.layoutlmv3', 'models.layoutxlm', 'models.led', 'models.levit', 'models.lilt', 'models.llama', 'models.longformer', 'models.longt5', 'models.luke', 'models.lxmert', 'models.m2m_100', 'models.marian', 'models.markuplm', 'models.mask2former', 'models.maskformer', 'models.mbart', 'models.mbart50', 'models.mega', 'models.megatron_bert', 'models.megatron_gpt2', 'models.mgp_str', 'models.mistral', 'models.mluke', 'models.mobilebert', 'models.mobilenet_v1', 'models.mobilenet_v2', 'models.mobilevit', 'models.mobilevitv2', 'models.mpnet', 'models.mpt', 'models.mra', 'models.mt5', 'models.musicgen', 'models.mvp', 'models.nat', 'models.nezha', 'models.nllb', 'models.nllb_moe', 'models.nougat', 'models.nystromformer', 'models.oneformer', 'models.openai', 'models.opt', 'models.owlv2', 'models.owlvit', 'models.pegasus', 'models.pegasus_x', 'models.perceiver', 'models.persimmon', 'models.phobert', 'models.pix2struct', 'models.plbart', 'models.poolformer', 'models.pop2piano', 'models.prophetnet', 'models.pvt', 'models.qdqbert', 'models.rag', 'models.realm', 'models.reformer', 'models.regnet', 'models.rembert', 'models.resnet', 'models.roberta', 'models.roberta_prelayernorm', 'models.roc_bert', 'models.roformer', 'models.rwkv', 'models.sam', 'models.seamless_m4t', 'models.segformer', 'models.sew', 'models.sew_d', 'models.speech_encoder_decoder', 'models.speech_to_text', 'models.speech_to_text_2', 'models.speecht5', 'models.splinter', 'models.squeezebert', 'models.swiftformer', 'models.swin', 'models.swin2sr', 'models.swinv2', 'models.switch_transformers', 'models.t5', 'models.table_transformer', 'models.tapas', 'models.time_series_transformer', 'models.timesformer', 'models.timm_backbone', 'models.transfo_xl', 'models.trocr', 'models.tvlt', 'models.umt5', 'models.unispeech', 'models.unispeech_sat', 'models.upernet', 'models.videomae', 'models.vilt', 'models.vision_encoder_decoder', 'models.vision_text_dual_encoder', 'models.visual_bert', 'models.vit', 'models.vit_hybrid', 'models.vit_mae', 'models.vit_msn', 'models.vitdet', 'models.vitmatte', 'models.vits', 'models.vivit', 'models.wav2vec2', 'models.wav2vec2_conformer', 'models.wav2vec2_phoneme', 'models.wav2vec2_with_lm', 'models.wavlm', 'models.whisper', 'models.x_clip', 'models.xglm', 'models.xlm', 'models.xlm_prophetnet', 'models.xlm_roberta', 'models.xlm_roberta_xl', 'models.xlnet', 'models.xmod', 'models.yolos', 'models.yoso', 'onnx', 'optimization', 'pipeline', 'pipelines', 'processing_utils', 'prune_layer', 'pytorch_utils', 'requires_backends', 'sagemaker', 'set_seed', 'shape_list', 'squad_convert_examples_to_features', 'testing_utils', 'tf_top_k_top_p_filtering', 'time_series_utils', 'tokenization_utils', 'tokenization_utils_base', 'tokenization_utils_fast', 'tools', 'top_k_top_p_filtering', 'torch_distributed_zero_first', 'trainer', 'trainer_callback', 'trainer_pt_utils', 'trainer_seq2seq', 'trainer_utils', 'training_args', 'training_args_seq2seq', 'training_args_tf', 'utils', 'utils.dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects', 'utils.dummy_flax_objects', 'utils.dummy_keras_nlp_objects', 'utils.dummy_sentencepiece_and_tokenizers_objects', 'utils.dummy_sentencepiece_objects', 'utils.dummy_tensorflow_text_objects', 'utils.dummy_tf_objects', 'utils.quantization_config', 'xnli_compute_metrics', 'xnli_output_modes', 'xnli_processors', 'xnli_tasks_num_labels']
2025-03-10 10:02:11,188 - INFO - Starting model loading process...
2025-03-10 10:02:11,440 - ERROR - Model loading failed with error: No module named 'transformers_modules.briaai.RMBG-2'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 45, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\configuration_auto.py", line 1057, in from_pretrained
    config_class = get_class_from_dynamic_module(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 499, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module.replace(".py", ""))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 199, in get_class_in_module
    module = importlib.import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:02:11,443 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:02:11,443 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.29s
2025-03-10 10:20:01,888 - INFO - Python version: 3.12.2
2025-03-10 10:20:01,889 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:20:01,889 - INFO - CUDA available: True
2025-03-10 10:20:01,889 - INFO - CUDA version: 12.4
2025-03-10 10:20:01,890 - INFO - Number of CUDA devices: 1
2025-03-10 10:20:01,894 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:20:01,894 - INFO -   Memory: 8.00GB
2025-03-10 10:20:01,894 - INFO -   CUDA Capability: 8.6
2025-03-10 10:20:01,993 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:20:01,993 - INFO - Final device selection: cuda
2025-03-10 10:20:02,125 - INFO - Starting Background Removal API server
2025-03-10 10:20:06,289 - INFO - Created new instance of ben2
2025-03-10 10:20:06,291 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.73s
2025-03-10 10:20:06,295 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:20:08,913 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:20:08,914 - INFO - Cache directory exists: True
2025-03-10 10:20:08,914 - INFO - Transformers version: 4.35.2
2025-03-10 10:20:08,914 - INFO - Starting model loading process...
2025-03-10 10:20:09,184 - ERROR - Model loading failed with error: No module named 'transformers_modules.briaai.RMBG-2'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 42, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\configuration_auto.py", line 1057, in from_pretrained
    config_class = get_class_from_dynamic_module(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 499, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module.replace(".py", ""))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 199, in get_class_in_module
    module = importlib.import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:20:09,187 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:20:09,187 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.27s
2025-03-10 10:22:44,933 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-10 10:22:44,938 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:22:52,779 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: ben2
2025-03-10 10:22:53,960 - INFO - Successfully processed Screenshot 2025-02-03 160220.png in 1.18s
2025-03-10 10:22:53,962 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.19s
2025-03-10 10:23:05,536 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-10 10:23:05,552 - INFO - Created new instance of birefnet
2025-03-10 10:23:05,553 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 4.21s
2025-03-10 10:23:05,559 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:23:07,073 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: birefnet
2025-03-10 10:23:07,073 - INFO - Original image size: (557, 590), mode: RGBA
2025-03-10 10:23:07,073 - INFO - Resizing image from (557, 590) to (576, 608) to ensure dimensions are multiples of 32
2025-03-10 10:23:07,091 - INFO - Expected patch count: 18x19, patch size: 32x32
2025-03-10 10:23:07,092 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-10 10:23:07,092 - INFO - Converting RGBA image to RGB with white background
2025-03-10 10:23:07,151 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 608, 576])
2025-03-10 10:23:07,152 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-10 10:23:07,153 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 608, 576])
2025-03-10 10:23:07,428 - INFO - Prediction successful, output shape: torch.Size([1, 1, 608, 576])
2025-03-10 10:23:07,591 - INFO - Successfully processed Screenshot 2025-02-03 160220.png in 0.52s
2025-03-10 10:23:07,591 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.52s
2025-03-10 10:23:16,188 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: birefnet
2025-03-10 10:23:16,188 - INFO - Original image size: (557, 590), mode: RGBA
2025-03-10 10:23:16,188 - INFO - Resizing image from (557, 590) to (576, 608) to ensure dimensions are multiples of 32
2025-03-10 10:23:16,206 - INFO - Expected patch count: 18x19, patch size: 32x32
2025-03-10 10:23:16,206 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-10 10:23:16,206 - INFO - Converting RGBA image to RGB with white background
2025-03-10 10:23:16,211 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 608, 576])
2025-03-10 10:23:16,212 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-10 10:23:16,214 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 608, 576])
2025-03-10 10:23:16,364 - INFO - Prediction successful, output shape: torch.Size([1, 1, 608, 576])
2025-03-10 10:23:16,521 - INFO - Successfully processed Screenshot 2025-02-03 160220.png in 0.33s
2025-03-10 10:23:16,522 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.34s
2025-03-10 10:24:35,492 - INFO - Python version: 3.12.2
2025-03-10 10:24:35,493 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:24:35,493 - INFO - CUDA available: True
2025-03-10 10:24:35,493 - INFO - CUDA version: 12.4
2025-03-10 10:24:35,494 - INFO - Number of CUDA devices: 1
2025-03-10 10:24:35,497 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:24:35,497 - INFO -   Memory: 8.00GB
2025-03-10 10:24:35,497 - INFO -   CUDA Capability: 8.6
2025-03-10 10:24:35,614 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:24:35,614 - INFO - Final device selection: cuda
2025-03-10 10:24:35,745 - INFO - Starting Background Removal API server
2025-03-10 10:24:40,041 - INFO - Created new instance of ben2
2025-03-10 10:24:40,043 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.50s
2025-03-10 10:24:40,049 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:24:41,585 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:24:41,585 - INFO - Cache directory exists: True
2025-03-10 10:24:41,586 - INFO - Transformers version: 4.35.2
2025-03-10 10:24:41,586 - INFO - Starting model loading process...
2025-03-10 10:24:41,586 - INFO - Loading model from: briaai/RMBG-1.4
2025-03-10 10:24:42,095 - ERROR - Model loading failed with error: No module named 'transformers_modules.briaai.RMBG-1'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 47, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\configuration_auto.py", line 1057, in from_pretrained
    config_class = get_class_from_dynamic_module(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 499, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module.replace(".py", ""))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 199, in get_class_in_module
    module = importlib.import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers_modules.briaai.RMBG-1'
2025-03-10 10:24:42,097 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-1'
2025-03-10 10:24:42,098 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.51s
2025-03-10 10:28:03,458 - INFO - Python version: 3.12.2
2025-03-10 10:28:03,459 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:28:03,460 - INFO - CUDA available: True
2025-03-10 10:28:03,460 - INFO - CUDA version: 12.4
2025-03-10 10:28:03,461 - INFO - Number of CUDA devices: 1
2025-03-10 10:28:03,464 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:28:03,464 - INFO -   Memory: 8.00GB
2025-03-10 10:28:03,464 - INFO -   CUDA Capability: 8.6
2025-03-10 10:28:03,545 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:28:03,545 - INFO - Final device selection: cuda
2025-03-10 10:28:03,667 - INFO - Starting Background Removal API server
2025-03-10 10:28:10,335 - INFO - Created new instance of ben2
2025-03-10 10:28:10,338 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.63s
2025-03-10 10:28:10,342 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:28:11,454 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:28:11,454 - INFO - Cache directory exists: True
2025-03-10 10:28:11,454 - INFO - Transformers version: 4.35.2
2025-03-10 10:28:11,454 - INFO - Starting model loading process...
2025-03-10 10:28:11,575 - ERROR - Model loading failed with error: briaai/RMBG is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_http.py", line 406, in hf_raise_for_status
    response.raise_for_status()
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/briaai/RMBG/resolve/2.0/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 1482, in _raise_on_head_call_error
    raise head_call_error
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 302, in _request_wrapper
    hf_raise_for_status(response)
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_http.py", line 454, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-67ceb0ac-27cd6c9e4719c6f226406648;bd04df14-cb9b-4c4a-9998-35044de79453)

Repository Not Found for url: https://huggingface.co/briaai/RMBG/resolve/2.0/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 47, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 488, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\utils\hub.py", line 451, in cached_file
    raise EnvironmentError(
OSError: briaai/RMBG is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-03-10 10:28:11,580 - ERROR - Failed to create model rmbg2: briaai/RMBG is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-03-10 10:28:11,581 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.13s
2025-03-10 10:29:45,370 - INFO - Python version: 3.12.2
2025-03-10 10:29:45,370 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:29:45,371 - INFO - CUDA available: True
2025-03-10 10:29:45,371 - INFO - CUDA version: 12.4
2025-03-10 10:29:45,373 - INFO - Number of CUDA devices: 1
2025-03-10 10:29:45,377 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:29:45,377 - INFO -   Memory: 8.00GB
2025-03-10 10:29:45,377 - INFO -   CUDA Capability: 8.6
2025-03-10 10:29:45,486 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:29:45,487 - INFO - Final device selection: cuda
2025-03-10 10:29:45,605 - INFO - Starting Background Removal API server
2025-03-10 10:30:06,755 - INFO - Created new instance of ben2
2025-03-10 10:30:06,757 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.74s
2025-03-10 10:30:06,762 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:30:09,694 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:30:09,694 - INFO - Cache directory exists: True
2025-03-10 10:30:09,694 - INFO - Transformers version: 4.35.2
2025-03-10 10:30:09,694 - INFO - Starting model loading process...
2025-03-10 10:30:09,830 - ERROR - Model loading failed with error: 2.0 is not a valid git identifier (branch name, tag name or commit id) that exists for this model name. Check the model page at 'https://huggingface.co/briaai/RMBG-2.0' for available revisions.
Traceback (most recent call last):
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_http.py", line 406, in hf_raise_for_status
    response.raise_for_status()
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/briaai/RMBG-2.0/resolve/2.0/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\utils\hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 923, in _hf_hub_download_to_cache_dir
    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(
                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\file_download.py", line 302, in _request_wrapper
    hf_raise_for_status(response)
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\huggingface_hub\utils\_http.py", line 413, in hf_raise_for_status
    raise _format(RevisionNotFoundError, message, response) from e
huggingface_hub.errors.RevisionNotFoundError: 404 Client Error. (Request ID: Root=1-67ceb123-5647331a7ca82f2d3b54af50;5b42b41a-0922-4b2a-b967-5d7a179405ef)

Revision Not Found for url: https://huggingface.co/briaai/RMBG-2.0/resolve/2.0/config.json.
Invalid rev id: 2.0

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 47, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 488, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\utils\hub.py", line 458, in cached_file
    raise EnvironmentError(
OSError: 2.0 is not a valid git identifier (branch name, tag name or commit id) that exists for this model name. Check the model page at 'https://huggingface.co/briaai/RMBG-2.0' for available revisions.
2025-03-10 10:30:09,833 - ERROR - Failed to create model rmbg2: 2.0 is not a valid git identifier (branch name, tag name or commit id) that exists for this model name. Check the model page at 'https://huggingface.co/briaai/RMBG-2.0' for available revisions.
2025-03-10 10:30:09,833 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.14s
2025-03-10 10:30:49,442 - INFO - Python version: 3.12.2
2025-03-10 10:30:49,442 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:30:49,442 - INFO - CUDA available: True
2025-03-10 10:30:49,442 - INFO - CUDA version: 12.4
2025-03-10 10:30:49,444 - INFO - Number of CUDA devices: 1
2025-03-10 10:30:49,446 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:30:49,448 - INFO -   Memory: 8.00GB
2025-03-10 10:30:49,448 - INFO -   CUDA Capability: 8.6
2025-03-10 10:30:49,547 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:30:49,548 - INFO - Final device selection: cuda
2025-03-10 10:30:49,676 - INFO - Starting Background Removal API server
2025-03-10 10:30:52,898 - INFO - Created new instance of ben2
2025-03-10 10:30:52,900 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.50s
2025-03-10 10:30:52,905 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:30:54,057 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:30:54,057 - INFO - Cache directory exists: True
2025-03-10 10:30:54,058 - INFO - Transformers version: 4.35.2
2025-03-10 10:30:54,058 - INFO - Starting model loading process...
2025-03-10 10:30:54,310 - ERROR - Model loading failed with error: No module named 'transformers_modules.briaai.RMBG-2'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 47, in load_model
    self.model = AutoModelForImageSegmentation.from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\configuration_auto.py", line 1057, in from_pretrained
    config_class = get_class_from_dynamic_module(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 499, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module.replace(".py", ""))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 199, in get_class_in_module
    module = importlib.import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:30:54,312 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:30:54,313 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.26s
2025-03-10 10:32:02,659 - INFO - Python version: 3.12.2
2025-03-10 10:32:02,659 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:32:02,659 - INFO - CUDA available: True
2025-03-10 10:32:02,660 - INFO - CUDA version: 12.4
2025-03-10 10:32:02,661 - INFO - Number of CUDA devices: 1
2025-03-10 10:32:02,663 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:32:02,663 - INFO -   Memory: 8.00GB
2025-03-10 10:32:02,663 - INFO -   CUDA Capability: 8.6
2025-03-10 10:32:02,772 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:32:02,772 - INFO - Final device selection: cuda
2025-03-10 10:32:02,927 - INFO - Starting Background Removal API server
2025-03-10 10:32:10,531 - INFO - Created new instance of ben2
2025-03-10 10:32:10,533 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.83s
2025-03-10 10:32:10,538 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:32:12,085 - INFO - Transformers cache directory: C:\Users\Merres/.cache\huggingface\hub
2025-03-10 10:32:12,086 - INFO - Cache directory exists: True
2025-03-10 10:32:12,086 - INFO - Transformers version: 4.35.2
2025-03-10 10:32:12,086 - INFO - Starting model loading process...
2025-03-10 10:32:12,347 - ERROR - Model loading failed with error: No module named 'transformers_modules.briaai.RMBG-2'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 47, in load_model
    self.model = model = AutoModelForImageSegmentation.from_pretrained("briaai/RMBG-2.0", trust_remote_code=True)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\models\auto\configuration_auto.py", line 1057, in from_pretrained
    config_class = get_class_from_dynamic_module(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 499, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module.replace(".py", ""))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\transformers\dynamic_module_utils.py", line 199, in get_class_in_module
    module = importlib.import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1310, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:32:12,351 - ERROR - Failed to create model rmbg2: No module named 'transformers_modules.briaai.RMBG-2'
2025-03-10 10:32:12,351 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.27s
2025-03-10 10:45:09,691 - INFO - Python version: 3.12.2
2025-03-10 10:45:09,691 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:45:09,692 - INFO - CUDA available: True
2025-03-10 10:45:09,692 - INFO - CUDA version: 12.4
2025-03-10 10:45:09,693 - INFO - Number of CUDA devices: 1
2025-03-10 10:45:09,696 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:45:09,696 - INFO -   Memory: 8.00GB
2025-03-10 10:45:09,696 - INFO -   CUDA Capability: 8.6
2025-03-10 10:45:09,826 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:45:09,826 - INFO - Final device selection: cuda
2025-03-10 10:45:09,969 - INFO - Starting Background Removal API server
2025-03-10 10:45:13,178 - INFO - Created new instance of ben2
2025-03-10 10:45:13,181 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.75s
2025-03-10 10:45:13,185 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:45:20,718 - INFO - Starting model download and loading process...
2025-03-10 10:45:21,079 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 10:45:21,351 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 10:45:21,639 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 10:48:45,133 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 10:48:45,646 - ERROR - Model loading failed with error: attempted relative import with no known parent package
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 70, in load_model
    spec.loader.exec_module(birefnet_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py", line 1974, in <module>
    from .BiRefNet_config import BiRefNetConfig
ImportError: attempted relative import with no known parent package
2025-03-10 10:48:45,648 - ERROR - Failed to create model rmbg2: attempted relative import with no known parent package
2025-03-10 10:48:45,649 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 204.93s
2025-03-10 10:57:16,326 - INFO - Python version: 3.12.2
2025-03-10 10:57:16,326 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 10:57:16,327 - INFO - CUDA available: True
2025-03-10 10:57:16,327 - INFO - CUDA version: 12.4
2025-03-10 10:57:16,329 - INFO - Number of CUDA devices: 1
2025-03-10 10:57:16,331 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 10:57:16,332 - INFO -   Memory: 8.00GB
2025-03-10 10:57:16,332 - INFO -   CUDA Capability: 8.6
2025-03-10 10:57:16,469 - INFO - CUDA test successful - tensor operation completed
2025-03-10 10:57:16,469 - INFO - Final device selection: cuda
2025-03-10 10:57:16,665 - INFO - Starting Background Removal API server
2025-03-10 10:58:22,793 - INFO - Created new instance of ben2
2025-03-10 10:58:22,795 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 2.06s
2025-03-10 10:58:22,801 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 10:58:25,307 - INFO - Starting model download and loading process...
2025-03-10 10:58:25,663 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 10:58:25,790 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 10:58:25,910 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 10:58:26,319 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 10:58:26,323 - INFO - Fixed imports in downloaded files
2025-03-10 10:58:28,946 - ERROR - Model loading failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 93, in load_model
    state_dict = torch.load(model_files['model.safetensors'], map_location=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\serialization.py", line 1494, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-03-10 10:58:28,949 - ERROR - Failed to create model rmbg2: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-03-10 10:58:28,951 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 3.64s
2025-03-10 11:04:29,594 - INFO - Python version: 3.12.2
2025-03-10 11:04:29,594 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:04:29,594 - INFO - CUDA available: True
2025-03-10 11:04:29,595 - INFO - CUDA version: 12.4
2025-03-10 11:04:29,596 - INFO - Number of CUDA devices: 1
2025-03-10 11:04:29,600 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:04:29,600 - INFO -   Memory: 8.00GB
2025-03-10 11:04:29,600 - INFO -   CUDA Capability: 8.6
2025-03-10 11:04:29,701 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:04:29,702 - INFO - Final device selection: cuda
2025-03-10 11:04:29,834 - INFO - Starting Background Removal API server
2025-03-10 11:04:58,849 - INFO - Created new instance of ben2
2025-03-10 11:04:58,850 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.91s
2025-03-10 11:04:58,856 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:05:00,494 - INFO - Starting model download and loading process...
2025-03-10 11:05:00,620 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:05:00,746 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:05:01,008 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:05:01,443 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:05:01,447 - INFO - Fixed imports in downloaded files
2025-03-10 11:05:04,252 - INFO - Loading model with weights_only=False to handle the safetensors file
2025-03-10 11:05:04,256 - ERROR - Model loading failed with error: invalid load key, '`'.
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 98, in load_model
    state_dict = torch.load(
                 ^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\serialization.py", line 1495, in load
    return _legacy_load(
           ^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\serialization.py", line 1744, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_pickle.UnpicklingError: invalid load key, '`'.
2025-03-10 11:05:04,258 - ERROR - Failed to create model rmbg2: invalid load key, '`'.
2025-03-10 11:05:04,261 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 3.77s
2025-03-10 11:06:58,160 - INFO - Python version: 3.12.2
2025-03-10 11:06:58,161 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:06:58,161 - INFO - CUDA available: True
2025-03-10 11:06:58,161 - INFO - CUDA version: 12.4
2025-03-10 11:06:58,162 - INFO - Number of CUDA devices: 1
2025-03-10 11:06:58,165 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:06:58,165 - INFO -   Memory: 8.00GB
2025-03-10 11:06:58,166 - INFO -   CUDA Capability: 8.6
2025-03-10 11:06:58,273 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:06:58,275 - INFO - Final device selection: cuda
2025-03-10 11:06:58,438 - INFO - Starting Background Removal API server
2025-03-10 11:07:13,944 - INFO - Created new instance of ben2
2025-03-10 11:07:13,946 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.89s
2025-03-10 11:07:13,950 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:07:15,091 - INFO - Starting model download and loading process...
2025-03-10 11:07:15,217 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:07:15,343 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:07:15,462 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:07:15,923 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:07:15,927 - INFO - Fixed imports in downloaded files
2025-03-10 11:07:18,261 - INFO - Loading model weights with safetensors
2025-03-10 11:07:18,284 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:07:18,427 - INFO - Model loaded successfully
2025-03-10 11:07:18,842 - INFO - Model moved to device: cuda
2025-03-10 11:07:18,845 - INFO - Model set to eval mode
2025-03-10 11:07:18,872 - INFO - Model converted to half precision
2025-03-10 11:07:18,873 - INFO - Created new instance of rmbg2
2025-03-10 11:07:18,946 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.85s
2025-03-10 11:07:18,951 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:07:31,489 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: rmbg2
2025-03-10 11:07:32,130 - ERROR - Error processing T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:07:32,131 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.65s
2025-03-10 11:08:19,890 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 0.00s
2025-03-10 11:08:19,894 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:08:21,234 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: ben2
2025-03-10 11:08:22,113 - INFO - Successfully processed T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png in 0.88s
2025-03-10 11:08:22,116 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.88s
2025-03-10 11:08:29,596 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-10 11:08:29,617 - INFO - Created new instance of birefnet
2025-03-10 11:08:29,619 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 3.81s
2025-03-10 11:08:29,623 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: birefnet
2025-03-10 11:08:29,624 - INFO - Original image size: (512, 512), mode: RGB
2025-03-10 11:08:29,632 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 512, 512])
2025-03-10 11:08:29,632 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-10 11:08:29,633 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 512, 512])
2025-03-10 11:08:29,928 - INFO - Prediction successful, output shape: torch.Size([1, 1, 512, 512])
2025-03-10 11:08:30,051 - INFO - Successfully processed T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png in 0.43s
2025-03-10 11:08:30,053 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.43s
2025-03-10 11:08:30,054 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:09:24,246 - INFO - Python version: 3.12.2
2025-03-10 11:09:24,246 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:09:24,247 - INFO - CUDA available: True
2025-03-10 11:09:24,247 - INFO - CUDA version: 12.4
2025-03-10 11:09:24,249 - INFO - Number of CUDA devices: 1
2025-03-10 11:09:24,251 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:09:24,252 - INFO -   Memory: 8.00GB
2025-03-10 11:09:24,252 - INFO -   CUDA Capability: 8.6
2025-03-10 11:09:24,354 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:09:24,354 - INFO - Final device selection: cuda
2025-03-10 11:09:24,480 - INFO - Starting Background Removal API server
2025-03-10 11:09:27,751 - INFO - Starting model download and loading process...
2025-03-10 11:09:27,980 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:09:28,109 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:09:28,350 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:09:28,840 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:09:28,842 - INFO - Fixed imports in downloaded files
2025-03-10 11:09:31,172 - INFO - Loading model weights with safetensors
2025-03-10 11:09:31,193 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:09:31,334 - INFO - Model loaded successfully
2025-03-10 11:09:31,675 - INFO - Model moved to device: cuda
2025-03-10 11:09:31,679 - INFO - Model set to eval mode
2025-03-10 11:09:31,738 - INFO - Model converted to half precision
2025-03-10 11:09:31,738 - INFO - Created new instance of rmbg2
2025-03-10 11:09:31,810 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 4.06s
2025-03-10 11:09:31,813 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:09:36,475 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: rmbg2
2025-03-10 11:09:36,573 - INFO - Input tensor converted to half precision
2025-03-10 11:09:37,195 - ERROR - Error during prediction: expected scalar type Half but found Float
2025-03-10 11:09:37,196 - ERROR - Error processing T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:09:37,196 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.73s
2025-03-10 11:11:22,049 - INFO - Python version: 3.12.2
2025-03-10 11:11:22,049 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:11:22,049 - INFO - CUDA available: True
2025-03-10 11:11:22,049 - INFO - CUDA version: 12.4
2025-03-10 11:11:22,050 - INFO - Number of CUDA devices: 1
2025-03-10 11:11:22,053 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:11:22,053 - INFO -   Memory: 8.00GB
2025-03-10 11:11:22,055 - INFO -   CUDA Capability: 8.6
2025-03-10 11:11:22,142 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:11:22,143 - INFO - Final device selection: cuda
2025-03-10 11:11:22,267 - INFO - Starting Background Removal API server
2025-03-10 11:11:24,395 - INFO - Starting model download and loading process...
2025-03-10 11:11:24,595 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:11:24,743 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:11:24,869 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:11:25,323 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:11:25,326 - INFO - Fixed imports in downloaded files
2025-03-10 11:11:28,119 - INFO - Model converted to half precision before loading weights
2025-03-10 11:11:28,236 - INFO - Model moved to device: cuda
2025-03-10 11:11:28,236 - INFO - Loading model weights with safetensors
2025-03-10 11:11:28,495 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:11:28,599 - INFO - Model loaded successfully
2025-03-10 11:11:28,602 - INFO - Model set to eval mode
2025-03-10 11:11:28,602 - INFO - Created new instance of rmbg2
2025-03-10 11:11:28,610 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 4.22s
2025-03-10 11:11:28,615 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:11:31,547 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: rmbg2
2025-03-10 11:11:31,656 - INFO - Input tensor converted to half precision
2025-03-10 11:11:31,656 - ERROR - Error during prediction: 'Tensor' object has no attribute 'is_half'
2025-03-10 11:11:31,658 - ERROR - Error processing T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png: Error processing image: 'Tensor' object has no attribute 'is_half'
2025-03-10 11:11:31,658 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.12s
2025-03-10 11:14:33,254 - INFO - Python version: 3.12.2
2025-03-10 11:14:33,255 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:14:33,256 - INFO - CUDA available: True
2025-03-10 11:14:33,256 - INFO - CUDA version: 12.4
2025-03-10 11:14:33,256 - INFO - Number of CUDA devices: 1
2025-03-10 11:14:33,260 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:14:33,260 - INFO -   Memory: 8.00GB
2025-03-10 11:14:33,260 - INFO -   CUDA Capability: 8.6
2025-03-10 11:14:33,353 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:14:33,354 - INFO - Final device selection: cuda
2025-03-10 11:14:33,487 - INFO - Starting Background Removal API server
2025-03-10 11:14:40,930 - INFO - Created new instance of ben2
2025-03-10 11:14:40,931 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.65s
2025-03-10 11:14:40,937 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:14:42,093 - INFO - Starting model download and loading process...
2025-03-10 11:14:42,220 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:14:42,349 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:14:42,473 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:14:42,991 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:14:42,993 - INFO - Fixed imports in downloaded files
2025-03-10 11:14:45,241 - INFO - Model converted to half precision before loading weights
2025-03-10 11:14:45,559 - INFO - Model moved to device: cuda
2025-03-10 11:14:45,559 - INFO - Loading model weights with safetensors
2025-03-10 11:14:45,782 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:14:45,933 - INFO - Model loaded successfully
2025-03-10 11:14:45,935 - INFO - Model set to eval mode
2025-03-10 11:14:45,935 - INFO - Created new instance of rmbg2
2025-03-10 11:14:45,937 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.84s
2025-03-10 11:14:45,940 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:14:47,347 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: rmbg2
2025-03-10 11:14:47,398 - INFO - Input tensor converted to half precision
2025-03-10 11:14:47,993 - ERROR - Error during prediction: expected scalar type Half but found Float
2025-03-10 11:14:47,995 - ERROR - Error processing T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:14:47,995 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.65s
2025-03-10 11:17:31,217 - INFO - Python version: 3.12.2
2025-03-10 11:17:31,218 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:17:31,218 - INFO - CUDA available: True
2025-03-10 11:17:31,218 - INFO - CUDA version: 12.4
2025-03-10 11:17:31,219 - INFO - Number of CUDA devices: 1
2025-03-10 11:17:31,226 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:17:31,226 - INFO -   Memory: 8.00GB
2025-03-10 11:17:31,226 - INFO -   CUDA Capability: 8.6
2025-03-10 11:17:31,321 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:17:31,322 - INFO - Final device selection: cuda
2025-03-10 11:17:31,451 - INFO - Starting Background Removal API server
2025-03-10 11:17:40,863 - INFO - Created new instance of ben2
2025-03-10 11:17:40,866 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.76s
2025-03-10 11:17:40,871 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:17:42,377 - INFO - Starting model download and loading process...
2025-03-10 11:17:42,505 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:17:42,633 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:17:42,766 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:17:43,293 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:17:43,297 - INFO - Fixed imports in downloaded files
2025-03-10 11:17:45,834 - INFO - Model moved to device: cuda
2025-03-10 11:17:45,836 - INFO - Loading model weights with safetensors
2025-03-10 11:17:45,860 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:17:46,361 - INFO - Model loaded successfully
2025-03-10 11:17:46,363 - INFO - Model set to eval mode
2025-03-10 11:17:46,363 - INFO - Created new instance of rmbg2
2025-03-10 11:17:46,428 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 4.05s
2025-03-10 11:17:46,433 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:17:54,404 - INFO - Processing image: IMG_7438.jpg with model: rmbg2
2025-03-10 11:17:55,527 - INFO - Model outputs don't have 'logits' attribute, using outputs directly
2025-03-10 11:17:55,527 - ERROR - Error during prediction: 'list' object has no attribute 'float'
2025-03-10 11:17:55,528 - ERROR - Error processing IMG_7438.jpg: Error processing image: 'list' object has no attribute 'float'
2025-03-10 11:17:55,528 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 1.13s
2025-03-10 11:20:04,893 - INFO - Python version: 3.12.2
2025-03-10 11:20:04,894 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:20:04,894 - INFO - CUDA available: True
2025-03-10 11:20:04,894 - INFO - CUDA version: 12.4
2025-03-10 11:20:04,895 - INFO - Number of CUDA devices: 1
2025-03-10 11:20:04,898 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:20:04,898 - INFO -   Memory: 8.00GB
2025-03-10 11:20:04,898 - INFO -   CUDA Capability: 8.6
2025-03-10 11:20:04,999 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:20:04,999 - INFO - Final device selection: cuda
2025-03-10 11:20:05,134 - INFO - Starting Background Removal API server
2025-03-10 11:20:15,728 - INFO - Created new instance of ben2
2025-03-10 11:20:15,731 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.88s
2025-03-10 11:20:15,736 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:20:17,288 - INFO - Starting model download and loading process...
2025-03-10 11:20:17,418 - INFO - Successfully copied BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\BiRefNet_config.py
2025-03-10 11:20:17,540 - INFO - Successfully copied birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\birefnet.py
2025-03-10 11:20:17,661 - INFO - Successfully copied config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\config.json
2025-03-10 11:20:18,153 - INFO - Successfully copied model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\rmbg_model\model.safetensors
2025-03-10 11:20:18,156 - INFO - Fixed imports in downloaded files
2025-03-10 11:20:20,798 - INFO - Model moved to device: cuda
2025-03-10 11:20:20,798 - INFO - Loading model weights with safetensors
2025-03-10 11:20:20,815 - INFO - Successfully loaded weights with safetensors
2025-03-10 11:20:21,300 - INFO - Model loaded successfully
2025-03-10 11:20:21,302 - INFO - Model set to eval mode
2025-03-10 11:20:21,302 - INFO - Created new instance of rmbg2
2025-03-10 11:20:21,370 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 4.08s
2025-03-10 11:20:21,375 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:20:29,536 - INFO - Processing image: DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp with model: rmbg2
2025-03-10 11:20:30,683 - INFO - Model outputs is a list, using the last element
2025-03-10 11:20:31,161 - INFO - Successfully processed DALL·E 2025-02-06 16.45.06 - A superior, ultra-modern, and minimalist lettermark logo for 'BLAUFUNK,' designed for a mission management and administration tool for emergency servi.webp in 1.62s
2025-03-10 11:20:31,164 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.63s
2025-03-10 11:20:51,947 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: rmbg2
2025-03-10 11:20:52,608 - INFO - Model outputs is a list, using the last element
2025-03-10 11:20:52,927 - INFO - Successfully processed T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png in 0.98s
2025-03-10 11:20:52,928 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.98s
2025-03-10 11:20:59,939 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-10 11:20:59,962 - INFO - Created new instance of birefnet
2025-03-10 11:20:59,964 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 3.67s
2025-03-10 11:20:59,966 - INFO - Processing image: T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png with model: birefnet
2025-03-10 11:20:59,967 - INFO - Original image size: (512, 512), mode: RGB
2025-03-10 11:20:59,974 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 512, 512])
2025-03-10 11:20:59,975 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-10 11:20:59,975 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 512, 512])
2025-03-10 11:21:00,345 - INFO - Prediction successful, output shape: torch.Size([1, 1, 512, 512])
2025-03-10 11:21:00,470 - INFO - Successfully processed T05GAC6U811-U063CE0M0F5-b91c81b9aea7-512.png in 0.50s
2025-03-10 11:21:00,472 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.51s
2025-03-10 11:21:00,473 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:21:58,755 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 0.00s
2025-03-10 11:21:58,759 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:22:02,139 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 11:22:02,634 - INFO - Model outputs is a list, using the last element
2025-03-10 11:22:03,097 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 0.96s
2025-03-10 11:22:03,098 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.96s
2025-03-10 11:22:21,541 - INFO - Processing image: omnitraklogo.png with model: rmbg2
2025-03-10 11:22:22,008 - INFO - Model outputs is a list, using the last element
2025-03-10 11:22:22,189 - INFO - Successfully processed omnitraklogo.png in 0.65s
2025-03-10 11:22:22,189 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 0.65s
2025-03-10 11:34:06,500 - INFO - Python version: 3.12.2
2025-03-10 11:34:06,502 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:34:06,502 - INFO - CUDA available: True
2025-03-10 11:34:06,502 - INFO - CUDA version: 12.4
2025-03-10 11:34:06,503 - INFO - Number of CUDA devices: 1
2025-03-10 11:34:06,506 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:34:06,507 - INFO -   Memory: 8.00GB
2025-03-10 11:34:06,507 - INFO -   CUDA Capability: 8.6
2025-03-10 11:34:06,634 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:34:06,635 - INFO - Final device selection: cuda
2025-03-10 11:34:06,798 - INFO - Starting Background Removal API server
2025-03-10 11:36:30,419 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:36:30,423 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:36:37,876 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-10 11:36:37,927 - INFO - Created new instance of birefnet
2025-03-10 11:36:37,928 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 4.34s
2025-03-10 11:36:37,933 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:36:37,977 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: birefnet
2025-03-10 11:36:37,983 - INFO - Original image size: (557, 590), mode: RGBA
2025-03-10 11:36:37,983 - INFO - Resizing image from (557, 590) to (576, 608) to ensure dimensions are multiples of 32
2025-03-10 11:36:37,999 - INFO - Expected patch count: 18x19, patch size: 32x32
2025-03-10 11:36:38,000 - INFO - Expected flattened patch dimension: 3072 channels
2025-03-10 11:36:38,000 - INFO - Converting RGBA image to RGB with white background
2025-03-10 11:36:38,005 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 608, 576])
2025-03-10 11:36:38,006 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-10 11:36:38,007 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 608, 576])
2025-03-10 11:36:39,449 - INFO - Prediction successful, output shape: torch.Size([1, 1, 608, 576])
2025-03-10 11:36:39,611 - INFO - Successfully processed Screenshot 2025-02-03 160220.png in 1.63s
2025-03-10 11:36:39,613 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.64s
2025-03-10 11:39:47,913 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:39:52,509 - INFO - Starting model download and loading process...
2025-03-10 11:39:52,635 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:39:52,758 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:39:52,905 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:39:53,039 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:39:53,043 - ERROR - Model loading failed with error: attempted relative import with no known parent package
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 70, in load_model
    spec.loader.exec_module(birefnet_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py", line 1974, in <module>
    from .BiRefNet_config import BiRefNetConfig
ImportError: attempted relative import with no known parent package
2025-03-10 11:39:53,044 - ERROR - Failed to create model rmbg2: attempted relative import with no known parent package
2025-03-10 11:39:53,046 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.54s
2025-03-10 11:40:30,562 - INFO - Python version: 3.12.2
2025-03-10 11:40:30,563 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:40:30,563 - INFO - CUDA available: True
2025-03-10 11:40:30,563 - INFO - CUDA version: 12.4
2025-03-10 11:40:30,564 - INFO - Number of CUDA devices: 1
2025-03-10 11:40:30,568 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:40:30,569 - INFO -   Memory: 8.00GB
2025-03-10 11:40:30,569 - INFO -   CUDA Capability: 8.6
2025-03-10 11:40:30,671 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:40:30,672 - INFO - Final device selection: cuda
2025-03-10 11:40:30,806 - INFO - Starting Background Removal API server
2025-03-10 11:41:13,187 - INFO - Created new instance of ben2
2025-03-10 11:41:13,189 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.95s
2025-03-10 11:41:13,194 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:41:14,879 - INFO - Starting model download and loading process...
2025-03-10 11:41:14,995 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:41:15,115 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:41:15,233 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:41:15,357 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:41:15,717 - ERROR - Model loading failed with error: attempted relative import with no known parent package
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 70, in load_model
    spec.loader.exec_module(birefnet_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py", line 1974, in <module>
    from .BiRefNet_config import BiRefNetConfig
ImportError: attempted relative import with no known parent package
2025-03-10 11:41:15,719 - ERROR - Failed to create model rmbg2: attempted relative import with no known parent package
2025-03-10 11:41:15,720 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 0.84s
2025-03-10 11:45:33,615 - INFO - Python version: 3.12.2
2025-03-10 11:45:33,615 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:45:33,615 - INFO - CUDA available: True
2025-03-10 11:45:33,616 - INFO - CUDA version: 12.4
2025-03-10 11:45:33,616 - INFO - Number of CUDA devices: 1
2025-03-10 11:45:33,619 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:45:33,620 - INFO -   Memory: 8.00GB
2025-03-10 11:45:33,620 - INFO -   CUDA Capability: 8.6
2025-03-10 11:45:33,718 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:45:33,718 - INFO - Final device selection: cuda
2025-03-10 11:45:33,866 - INFO - Starting Background Removal API server
2025-03-10 11:45:38,404 - INFO - Created new instance of ben2
2025-03-10 11:45:38,406 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.70s
2025-03-10 11:45:38,411 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:45:39,694 - INFO - Starting model download and loading process...
2025-03-10 11:45:39,814 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:45:39,944 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:45:40,063 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:45:40,194 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:45:42,849 - ERROR - Model loading failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 73, in load_model
    state_dict = torch.load(model_files['model.safetensors'], map_location=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\serialization.py", line 1494, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-03-10 11:45:42,852 - ERROR - Failed to create model rmbg2: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 96

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-03-10 11:45:42,854 - INFO - Method: POST Path: /models/rmbg2/load Status: 404 Duration: 3.16s
2025-03-10 11:48:47,799 - INFO - Python version: 3.12.2
2025-03-10 11:48:47,799 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:48:47,799 - INFO - CUDA available: True
2025-03-10 11:48:47,799 - INFO - CUDA version: 12.4
2025-03-10 11:48:47,800 - INFO - Number of CUDA devices: 1
2025-03-10 11:48:47,804 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:48:47,804 - INFO -   Memory: 8.00GB
2025-03-10 11:48:47,804 - INFO -   CUDA Capability: 8.6
2025-03-10 11:48:47,912 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:48:47,913 - INFO - Final device selection: cuda
2025-03-10 11:48:48,042 - INFO - Starting Background Removal API server
2025-03-10 11:49:13,317 - INFO - Created new instance of ben2
2025-03-10 11:49:13,319 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.75s
2025-03-10 11:49:13,323 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:49:16,615 - INFO - Starting model download and loading process...
2025-03-10 11:49:16,732 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:49:16,853 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:49:16,994 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:49:17,123 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:49:19,657 - INFO - Model loaded successfully
2025-03-10 11:49:20,086 - INFO - Model moved to device: cuda
2025-03-10 11:49:20,088 - INFO - Model set to eval mode
2025-03-10 11:49:20,114 - INFO - Model converted to half precision
2025-03-10 11:49:20,114 - INFO - Created new instance of rmbg2
2025-03-10 11:49:20,209 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.59s
2025-03-10 11:49:20,215 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:49:26,001 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 11:49:26,590 - ERROR - Error processing signal-2023-02-04-212737.jpeg: Error processing image: expected scalar type Half but found Float
2025-03-10 11:49:26,591 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.59s
2025-03-10 11:52:21,826 - INFO - Python version: 3.12.2
2025-03-10 11:52:21,826 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:52:21,827 - INFO - CUDA available: True
2025-03-10 11:52:21,827 - INFO - CUDA version: 12.4
2025-03-10 11:52:21,828 - INFO - Number of CUDA devices: 1
2025-03-10 11:52:21,831 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:52:21,831 - INFO -   Memory: 8.00GB
2025-03-10 11:52:21,831 - INFO -   CUDA Capability: 8.6
2025-03-10 11:52:21,928 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:52:21,928 - INFO - Final device selection: cuda
2025-03-10 11:52:22,055 - INFO - Starting Background Removal API server
2025-03-10 11:52:27,389 - INFO - Created new instance of ben2
2025-03-10 11:52:27,391 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.70s
2025-03-10 11:52:27,399 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:52:28,302 - INFO - Starting model download and loading process...
2025-03-10 11:52:28,420 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:52:28,555 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:52:28,680 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:52:28,808 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:52:31,487 - INFO - Model loaded successfully
2025-03-10 11:52:31,849 - INFO - Model moved to device: cuda
2025-03-10 11:52:31,852 - INFO - Model set to eval mode
2025-03-10 11:52:31,882 - INFO - Model converted to half precision
2025-03-10 11:52:31,883 - INFO - Created new instance of rmbg2
2025-03-10 11:52:31,989 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.69s
2025-03-10 11:52:31,996 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:52:36,894 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: rmbg2
2025-03-10 11:52:37,488 - ERROR - Error processing Screenshot 2025-02-03 160220.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:52:37,489 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.60s
2025-03-10 11:55:44,237 - INFO - Python version: 3.12.2
2025-03-10 11:55:44,237 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:55:44,237 - INFO - CUDA available: True
2025-03-10 11:55:44,237 - INFO - CUDA version: 12.4
2025-03-10 11:55:44,238 - INFO - Number of CUDA devices: 1
2025-03-10 11:55:44,243 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:55:44,243 - INFO -   Memory: 8.00GB
2025-03-10 11:55:44,243 - INFO -   CUDA Capability: 8.6
2025-03-10 11:55:44,364 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:55:44,364 - INFO - Final device selection: cuda
2025-03-10 11:55:44,500 - INFO - Starting Background Removal API server
2025-03-10 11:55:48,384 - INFO - Created new instance of ben2
2025-03-10 11:55:48,387 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.65s
2025-03-10 11:55:48,392 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:55:49,570 - INFO - Starting model download and loading process...
2025-03-10 11:55:49,690 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:55:49,823 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:55:49,941 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:55:50,073 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:55:52,312 - INFO - Model loaded successfully
2025-03-10 11:55:52,713 - INFO - Model moved to device: cuda
2025-03-10 11:55:52,714 - INFO - Model set to eval mode
2025-03-10 11:55:52,743 - INFO - Model converted to half precision
2025-03-10 11:55:52,744 - INFO - Created new instance of rmbg2
2025-03-10 11:55:52,841 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.27s
2025-03-10 11:55:52,846 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:55:56,421 - INFO - Processing image: omnitraklogo.png with model: rmbg2
2025-03-10 11:55:56,986 - ERROR - Error processing omnitraklogo.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:55:56,987 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.57s
2025-03-10 11:56:31,414 - INFO - Python version: 3.12.2
2025-03-10 11:56:31,414 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:56:31,414 - INFO - CUDA available: True
2025-03-10 11:56:31,414 - INFO - CUDA version: 12.4
2025-03-10 11:56:31,416 - INFO - Number of CUDA devices: 1
2025-03-10 11:56:31,419 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:56:31,419 - INFO -   Memory: 8.00GB
2025-03-10 11:56:31,419 - INFO -   CUDA Capability: 8.6
2025-03-10 11:56:31,520 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:56:31,520 - INFO - Final device selection: cuda
2025-03-10 11:56:31,644 - INFO - Starting Background Removal API server
2025-03-10 11:56:35,217 - INFO - Created new instance of ben2
2025-03-10 11:56:35,219 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.52s
2025-03-10 11:56:35,224 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:56:36,056 - INFO - Starting model download and loading process...
2025-03-10 11:56:36,178 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:56:36,294 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:56:36,413 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:56:36,539 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:56:38,844 - INFO - Model loaded successfully
2025-03-10 11:56:39,162 - INFO - Model moved to device: cuda
2025-03-10 11:56:39,164 - INFO - Model set to eval mode
2025-03-10 11:56:39,194 - INFO - Model converted to half precision
2025-03-10 11:56:39,194 - INFO - Created new instance of rmbg2
2025-03-10 11:56:39,304 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.25s
2025-03-10 11:56:39,308 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:56:44,138 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 11:56:44,748 - ERROR - Error processing signal-2023-02-04-212737.jpeg: Error processing image: expected scalar type Half but found Float
2025-03-10 11:56:44,749 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.61s
2025-03-10 11:58:36,752 - INFO - Python version: 3.12.2
2025-03-10 11:58:36,752 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 11:58:36,752 - INFO - CUDA available: True
2025-03-10 11:58:36,752 - INFO - CUDA version: 12.4
2025-03-10 11:58:36,753 - INFO - Number of CUDA devices: 1
2025-03-10 11:58:36,757 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 11:58:36,757 - INFO -   Memory: 8.00GB
2025-03-10 11:58:36,757 - INFO -   CUDA Capability: 8.6
2025-03-10 11:58:36,872 - INFO - CUDA test successful - tensor operation completed
2025-03-10 11:58:36,872 - INFO - Final device selection: cuda
2025-03-10 11:58:37,012 - INFO - Starting Background Removal API server
2025-03-10 11:58:48,645 - INFO - Created new instance of ben2
2025-03-10 11:58:48,648 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.63s
2025-03-10 11:58:48,652 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:58:49,760 - INFO - Starting model download and loading process...
2025-03-10 11:58:49,877 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 11:58:52,863 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 11:58:52,983 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 11:58:53,117 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 11:58:55,409 - INFO - Model loaded successfully
2025-03-10 11:58:55,724 - INFO - Model moved to device: cuda
2025-03-10 11:58:55,726 - INFO - Model set to eval mode
2025-03-10 11:58:55,752 - INFO - Model converted to half precision
2025-03-10 11:58:55,753 - INFO - Created new instance of rmbg2
2025-03-10 11:58:55,864 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 6.10s
2025-03-10 11:58:55,870 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 11:59:00,390 - INFO - Processing image: bike.png with model: rmbg2
2025-03-10 11:59:00,933 - ERROR - Error processing bike.png: Error processing image: expected scalar type Half but found Float
2025-03-10 11:59:00,934 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.55s
2025-03-10 12:00:44,365 - INFO - Python version: 3.12.2
2025-03-10 12:00:44,366 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:00:44,366 - INFO - CUDA available: True
2025-03-10 12:00:44,366 - INFO - CUDA version: 12.4
2025-03-10 12:00:44,367 - INFO - Number of CUDA devices: 1
2025-03-10 12:00:44,371 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:00:44,371 - INFO -   Memory: 8.00GB
2025-03-10 12:00:44,372 - INFO -   CUDA Capability: 8.6
2025-03-10 12:00:44,484 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:00:44,484 - INFO - Final device selection: cuda
2025-03-10 12:00:44,623 - INFO - Starting Background Removal API server
2025-03-10 12:01:33,340 - INFO - Created new instance of ben2
2025-03-10 12:01:33,343 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.91s
2025-03-10 12:01:33,348 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:02:41,989 - INFO - Starting model download and loading process...
2025-03-10 12:02:42,107 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:02:42,232 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:02:42,354 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:02:42,477 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:02:45,335 - INFO - Model loaded successfully
2025-03-10 12:02:45,696 - INFO - Model moved to device: cuda
2025-03-10 12:02:45,697 - INFO - Model set to eval mode
2025-03-10 12:02:45,729 - INFO - Model converted to half precision
2025-03-10 12:02:45,729 - INFO - Created new instance of rmbg2
2025-03-10 12:02:45,859 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.87s
2025-03-10 12:02:45,865 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:02:49,205 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: rmbg2
2025-03-10 12:02:49,212 - INFO - Model parameters dtype: torch.float16
2025-03-10 12:02:49,305 - INFO - Preprocessed tensor dtype: torch.float16
2025-03-10 12:02:49,307 - INFO - Final tensor dtype before prediction: torch.float16
2025-03-10 12:02:49,751 - ERROR - Error processing image: expected scalar type Half but found Float
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 173, in __call__
    pred = self.predict(input_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 136, in predict
    outputs = self.model(image)
              ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2072, in forward
    scaled_preds, class_preds = self.forward_ori(x)
                                ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2061, in forward_ori
    (x1, x2, x3, x4), class_preds = self.forward_enc(x)
                                    ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2029, in forward_enc
    x1, x2, x3, x4 = self.bb(x)
                     ^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1195, in forward
    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)
                             ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1002, in forward
    x = blk(x, attn_mask)
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 840, in forward
    attn_windows = self.attn(x_windows, mask=attn_mask)  # nW*B, window_size*window_size, C
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 756, in forward
    x = (attn @ v).transpose(1, 2).reshape(B_, N, C)
         ~~~~~^~~
RuntimeError: expected scalar type Half but found Float
2025-03-10 12:02:49,754 - ERROR - Error processing Screenshot 2025-02-03 160220.png: expected scalar type Half but found Float
2025-03-10 12:02:49,755 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.55s
2025-03-10 12:04:23,075 - INFO - Python version: 3.12.2
2025-03-10 12:04:23,075 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:04:23,075 - INFO - CUDA available: True
2025-03-10 12:04:23,075 - INFO - CUDA version: 12.4
2025-03-10 12:04:23,077 - INFO - Number of CUDA devices: 1
2025-03-10 12:04:23,080 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:04:23,080 - INFO -   Memory: 8.00GB
2025-03-10 12:04:23,080 - INFO -   CUDA Capability: 8.6
2025-03-10 12:04:23,160 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:04:23,160 - INFO - Final device selection: cuda
2025-03-10 12:04:23,300 - INFO - Starting Background Removal API server
2025-03-10 12:04:31,678 - INFO - Created new instance of ben2
2025-03-10 12:04:31,680 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.85s
2025-03-10 12:04:31,684 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:04:32,694 - INFO - Starting model download and loading process...
2025-03-10 12:04:32,817 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:04:32,935 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:04:33,076 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:04:33,219 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:04:35,488 - INFO - Converting state_dict to half precision before loading
2025-03-10 12:04:35,823 - INFO - Model loaded successfully
2025-03-10 12:04:36,223 - INFO - Model moved to device: cuda
2025-03-10 12:04:36,226 - INFO - Model set to eval mode
2025-03-10 12:04:36,255 - INFO - Model converted to half precision
2025-03-10 12:04:36,256 - INFO - Created new instance of rmbg2
2025-03-10 12:04:36,362 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.67s
2025-03-10 12:04:36,367 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:04:37,261 - INFO - Processing image: Screenshot 2025-02-03 160220.png with model: rmbg2
2025-03-10 12:04:37,268 - INFO - Model parameters dtype: torch.float16
2025-03-10 12:04:37,353 - INFO - Preprocessed tensor dtype: torch.float16
2025-03-10 12:04:37,353 - INFO - Final tensor dtype before prediction: torch.float16
2025-03-10 12:04:37,724 - ERROR - Error processing image: expected scalar type Half but found Float
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 181, in __call__
    pred = self.predict(input_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 144, in predict
    outputs = self.model(image)
              ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2072, in forward
    scaled_preds, class_preds = self.forward_ori(x)
                                ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2061, in forward_ori
    (x1, x2, x3, x4), class_preds = self.forward_enc(x)
                                    ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2029, in forward_enc
    x1, x2, x3, x4 = self.bb(x)
                     ^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1195, in forward
    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)
                             ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1002, in forward
    x = blk(x, attn_mask)
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 840, in forward
    attn_windows = self.attn(x_windows, mask=attn_mask)  # nW*B, window_size*window_size, C
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 756, in forward
    x = (attn @ v).transpose(1, 2).reshape(B_, N, C)
         ~~~~~^~~
RuntimeError: expected scalar type Half but found Float
2025-03-10 12:04:37,729 - ERROR - Error processing Screenshot 2025-02-03 160220.png: expected scalar type Half but found Float
2025-03-10 12:04:37,730 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.47s
2025-03-10 12:07:30,619 - INFO - Python version: 3.12.2
2025-03-10 12:07:30,619 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:07:30,621 - INFO - CUDA available: True
2025-03-10 12:07:30,621 - INFO - CUDA version: 12.4
2025-03-10 12:07:30,622 - INFO - Number of CUDA devices: 1
2025-03-10 12:07:30,626 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:07:30,627 - INFO -   Memory: 8.00GB
2025-03-10 12:07:30,627 - INFO -   CUDA Capability: 8.6
2025-03-10 12:07:30,716 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:07:30,716 - INFO - Final device selection: cuda
2025-03-10 12:07:30,852 - INFO - Starting Background Removal API server
2025-03-10 12:07:36,602 - INFO - Created new instance of ben2
2025-03-10 12:07:36,603 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.65s
2025-03-10 12:07:36,614 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:07:38,548 - INFO - Starting model download and loading process...
2025-03-10 12:07:38,680 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:07:38,802 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:07:38,926 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:07:39,122 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:07:41,246 - INFO - Converting state_dict to half precision before loading
2025-03-10 12:07:41,500 - INFO - Model loaded successfully
2025-03-10 12:07:41,915 - INFO - Model moved to device: cuda
2025-03-10 12:07:41,917 - INFO - Model set to eval mode
2025-03-10 12:07:41,955 - INFO - Model converted to half precision with all tensors and buffers checked
2025-03-10 12:07:41,956 - INFO - Created new instance of rmbg2
2025-03-10 12:07:42,058 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.51s
2025-03-10 12:07:42,064 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:07:48,681 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 12:07:48,688 - INFO - Model parameters dtype: torch.float16
2025-03-10 12:07:48,829 - INFO - Preprocessed tensor dtype: torch.float16
2025-03-10 12:07:48,831 - INFO - Final tensor dtype before prediction: torch.float16
2025-03-10 12:07:49,446 - ERROR - Error processing image: expected scalar type Half but found Float
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 200, in __call__
    pred = self.predict(input_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 163, in predict
    outputs = self.model(image)
              ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2072, in forward
    scaled_preds, class_preds = self.forward_ori(x)
                                ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2061, in forward_ori
    (x1, x2, x3, x4), class_preds = self.forward_enc(x)
                                    ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2029, in forward_enc
    x1, x2, x3, x4 = self.bb(x)
                     ^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1195, in forward
    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)
                             ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1002, in forward
    x = blk(x, attn_mask)
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 840, in forward
    attn_windows = self.attn(x_windows, mask=attn_mask)  # nW*B, window_size*window_size, C
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 756, in forward
    x = (attn @ v).transpose(1, 2).reshape(B_, N, C)
         ~~~~~^~~
RuntimeError: expected scalar type Half but found Float
2025-03-10 12:07:49,450 - ERROR - Error processing signal-2023-02-04-212737.jpeg: expected scalar type Half but found Float
2025-03-10 12:07:49,451 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.77s
2025-03-10 12:10:08,389 - INFO - Python version: 3.12.2
2025-03-10 12:10:08,390 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:10:08,390 - INFO - CUDA available: True
2025-03-10 12:10:08,390 - INFO - CUDA version: 12.4
2025-03-10 12:10:08,391 - INFO - Number of CUDA devices: 1
2025-03-10 12:10:08,394 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:10:08,394 - INFO -   Memory: 8.00GB
2025-03-10 12:10:08,394 - INFO -   CUDA Capability: 8.6
2025-03-10 12:10:08,490 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:10:08,491 - INFO - Final device selection: cuda
2025-03-10 12:10:08,621 - INFO - Starting Background Removal API server
2025-03-10 12:10:12,607 - INFO - Created new instance of ben2
2025-03-10 12:10:12,610 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 1.62s
2025-03-10 12:10:12,615 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:10:13,341 - INFO - Starting model download and loading process...
2025-03-10 12:10:13,463 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:10:13,582 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:10:13,700 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:10:13,825 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:10:16,055 - INFO - Converting state_dict to half precision before loading
2025-03-10 12:10:16,313 - INFO - Model loaded successfully
2025-03-10 12:10:16,631 - INFO - Model moved to device: cuda
2025-03-10 12:10:16,633 - INFO - Model set to eval mode
2025-03-10 12:10:16,672 - INFO - Model converted to half precision with all tensors and buffers checked
2025-03-10 12:10:16,672 - INFO - Created new instance of rmbg2
2025-03-10 12:10:16,775 - INFO - Method: POST Path: /models/rmbg2/load Status: 200 Duration: 3.43s
2025-03-10 12:10:16,780 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 12:10:17,506 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 12:10:17,513 - INFO - Model memory format: True
2025-03-10 12:10:17,597 - INFO - After preprocess - tensor dtype: torch.float16, device: cuda:0
2025-03-10 12:10:17,597 - INFO - Tensor requires grad: False
2025-03-10 12:10:17,597 - INFO - Tensor memory format: True
2025-03-10 12:10:17,597 - INFO - Final tensor stats - dtype: torch.float16, shape: torch.Size([1, 3, 1024, 1024]), device: cuda:0
2025-03-10 12:10:17,597 - INFO - Predict input tensor dtype: torch.float16
2025-03-10 12:10:17,600 - WARNING - Buffer bb.layers.0.blocks.0.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,600 - WARNING - Buffer bb.layers.0.blocks.1.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,600 - WARNING - Buffer bb.layers.1.blocks.0.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,600 - WARNING - Buffer bb.layers.1.blocks.1.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,601 - WARNING - Buffer bb.layers.2.blocks.0.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,601 - WARNING - Buffer bb.layers.2.blocks.1.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,601 - WARNING - Buffer bb.layers.2.blocks.2.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,601 - WARNING - Buffer bb.layers.2.blocks.3.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,602 - WARNING - Buffer bb.layers.2.blocks.4.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,602 - WARNING - Buffer bb.layers.2.blocks.5.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,602 - WARNING - Buffer bb.layers.2.blocks.6.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,602 - WARNING - Buffer bb.layers.2.blocks.7.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,603 - WARNING - Buffer bb.layers.2.blocks.8.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,603 - WARNING - Buffer bb.layers.2.blocks.9.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,603 - WARNING - Buffer bb.layers.2.blocks.10.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,603 - WARNING - Buffer bb.layers.2.blocks.11.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,604 - WARNING - Buffer bb.layers.2.blocks.12.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,604 - WARNING - Buffer bb.layers.2.blocks.13.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,604 - WARNING - Buffer bb.layers.2.blocks.14.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,604 - WARNING - Buffer bb.layers.2.blocks.15.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer bb.layers.2.blocks.16.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer bb.layers.2.blocks.17.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer bb.layers.3.blocks.0.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer bb.layers.3.blocks.1.attn.relative_position_index has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer squeeze_module.0.dec_att.aspp1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,605 - WARNING - Buffer squeeze_module.0.dec_att.aspp_deforms.0.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.dec_att.aspp_deforms.1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.dec_att.aspp_deforms.2.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.dec_att.global_avg_pool.2.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.dec_att.bn1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.bn_in.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer squeeze_module.0.bn_out.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer decoder.decoder_block4.dec_att.aspp1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,606 - WARNING - Buffer decoder.decoder_block4.dec_att.aspp_deforms.0.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.dec_att.aspp_deforms.1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.dec_att.aspp_deforms.2.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.dec_att.global_avg_pool.2.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.dec_att.bn1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.bn_in.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block4.bn_out.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block3.dec_att.aspp1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block3.dec_att.aspp_deforms.0.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,607 - WARNING - Buffer decoder.decoder_block3.dec_att.aspp_deforms.1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block3.dec_att.aspp_deforms.2.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block3.dec_att.global_avg_pool.2.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block3.dec_att.bn1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block3.bn_in.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block3.bn_out.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.aspp1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.aspp_deforms.0.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.aspp_deforms.1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.aspp_deforms.2.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.global_avg_pool.2.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.dec_att.bn1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,609 - WARNING - Buffer decoder.decoder_block2.bn_in.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block2.bn_out.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.aspp1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.aspp_deforms.0.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.aspp_deforms.1.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.aspp_deforms.2.bn.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.global_avg_pool.2.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.dec_att.bn1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.bn_in.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,611 - WARNING - Buffer decoder.decoder_block1.bn_out.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,612 - WARNING - Buffer decoder.gdt_convs_4.1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,612 - WARNING - Buffer decoder.gdt_convs_3.1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,612 - WARNING - Buffer decoder.gdt_convs_2.1.num_batches_tracked has dtype torch.int64
2025-03-10 12:10:17,612 - INFO - After explicit half conversion dtype: torch.float16
2025-03-10 12:10:17,612 - INFO - Checking backbone layer dtypes:
2025-03-10 12:10:17,613 - INFO - Layer patch_embed.proj weight dtype: torch.float16
2025-03-10 12:10:17,989 - ERROR - Error processing image: expected scalar type Half but found Float
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 222, in __call__
    pred = self.predict(input_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 184, in predict
    outputs = self.model(image)
              ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2072, in forward
    scaled_preds, class_preds = self.forward_ori(x)
                                ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2061, in forward_ori
    (x1, x2, x3, x4), class_preds = self.forward_enc(x)
                                    ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 2029, in forward_enc
    x1, x2, x3, x4 = self.bb(x)
                     ^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1195, in forward
    x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)
                             ^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 1002, in forward
    x = blk(x, attn_mask)
        ^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 840, in forward
    attn_windows = self.attn(x_windows, mask=attn_mask)  # nW*B, window_size*window_size, C
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Merres\Documents\Coding\pictransformer_birefnet\venv\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\patched_birefnet.py", line 756, in forward
    x = (attn @ v).transpose(1, 2).reshape(B_, N, C)
         ~~~~~^~~
RuntimeError: expected scalar type Half but found Float
2025-03-10 12:10:17,993 - ERROR - Error processing signal-2023-02-04-212737.jpeg: expected scalar type Half but found Float
2025-03-10 12:10:17,995 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 0.49s
2025-03-10 12:11:47,654 - INFO - Python version: 3.12.2
2025-03-10 12:11:47,655 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:11:47,655 - INFO - CUDA available: True
2025-03-10 12:11:47,655 - INFO - CUDA version: 12.4
2025-03-10 12:11:47,656 - INFO - Number of CUDA devices: 1
2025-03-10 12:11:47,660 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:11:47,660 - INFO -   Memory: 8.00GB
2025-03-10 12:11:47,660 - INFO -   CUDA Capability: 8.6
2025-03-10 12:11:47,762 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:11:47,762 - INFO - Final device selection: cuda
2025-03-10 12:11:47,903 - INFO - Starting Background Removal API server
2025-03-10 12:11:57,657 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 12:11:57,658 - INFO - Starting model download and loading process...
2025-03-10 12:11:57,833 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:11:57,976 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:11:58,099 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:11:58,226 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:12:00,467 - INFO - Converting state_dict to half precision before loading
2025-03-10 12:12:00,714 - INFO - Model loaded successfully
2025-03-10 12:12:01,082 - INFO - Model moved to device: cuda
2025-03-10 12:12:01,083 - INFO - Model set to eval mode
2025-03-10 12:12:01,149 - INFO - Model converted to half precision with all tensors and buffers checked
2025-03-10 12:12:01,150 - INFO - Created new instance of rmbg2
2025-03-10 12:12:01,257 - INFO - Model memory format: True
2025-03-10 12:12:01,282 - INFO - After preprocess - tensor dtype: torch.float16, device: cuda:0
2025-03-10 12:12:01,282 - INFO - Tensor requires grad: False
2025-03-10 12:12:01,283 - INFO - Tensor memory format: True
2025-03-10 12:12:01,283 - INFO - Final tensor stats - dtype: torch.float16, shape: torch.Size([1, 3, 1024, 1024]), device: cuda:0
2025-03-10 12:12:01,283 - INFO - Predict input tensor dtype: torch.float16
2025-03-10 12:12:01,284 - INFO - After explicit half conversion dtype: torch.float16
2025-03-10 12:12:03,291 - ERROR - Error processing image: 'list' object has no attribute 'logits'
Traceback (most recent call last):
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 221, in __call__
    pred = self.predict(input_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\rmbg.py", line 183, in predict
    pred = outputs.logits.sigmoid().cpu()
           ^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'logits'
2025-03-10 12:12:03,292 - ERROR - Error processing signal-2023-02-04-212737.jpeg: 'list' object has no attribute 'logits'
2025-03-10 12:12:03,294 - INFO - Method: POST Path: /remove-background/ Status: 500 Duration: 5.64s
2025-03-10 12:13:50,230 - INFO - Python version: 3.12.2
2025-03-10 12:13:50,230 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:13:50,232 - INFO - CUDA available: True
2025-03-10 12:13:50,232 - INFO - CUDA version: 12.4
2025-03-10 12:13:50,233 - INFO - Number of CUDA devices: 1
2025-03-10 12:13:50,236 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:13:50,236 - INFO -   Memory: 8.00GB
2025-03-10 12:13:50,236 - INFO -   CUDA Capability: 8.6
2025-03-10 12:13:50,328 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:13:50,328 - INFO - Final device selection: cuda
2025-03-10 12:13:50,457 - INFO - Starting Background Removal API server
2025-03-10 12:15:27,556 - INFO - Python version: 3.12.2
2025-03-10 12:15:27,556 - INFO - PyTorch version: 2.6.0+cu124
2025-03-10 12:15:27,557 - INFO - CUDA available: True
2025-03-10 12:15:27,557 - INFO - CUDA version: 12.4
2025-03-10 12:15:27,558 - INFO - Number of CUDA devices: 1
2025-03-10 12:15:27,562 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-10 12:15:27,562 - INFO -   Memory: 8.00GB
2025-03-10 12:15:27,563 - INFO -   CUDA Capability: 8.6
2025-03-10 12:15:27,658 - INFO - CUDA test successful - tensor operation completed
2025-03-10 12:15:27,659 - INFO - Final device selection: cuda
2025-03-10 12:15:27,792 - INFO - Starting Background Removal API server
2025-03-10 12:16:11,288 - INFO - Processing image: signal-2023-02-04-212737.jpeg with model: rmbg2
2025-03-10 12:16:11,289 - INFO - Starting model download and loading process...
2025-03-10 12:16:11,466 - INFO - Successfully downloaded BiRefNet_config.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\BiRefNet_config.py
2025-03-10 12:16:11,629 - INFO - Successfully downloaded birefnet.py to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\birefnet.py
2025-03-10 12:16:11,792 - INFO - Successfully downloaded config.json to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\config.json
2025-03-10 12:16:11,919 - INFO - Successfully downloaded model.safetensors to C:\Users\Merres\Documents\Coding\pictransformer_birefnet\models\..\downloaded_models\rmbg2\models--briaai--RMBG-2.0\snapshots\8466043b7b29ea0e0d1f4cc95b2bca1f5fcf8ae0\model.safetensors
2025-03-10 12:16:14,369 - INFO - Converting state_dict to half precision before loading
2025-03-10 12:16:14,735 - INFO - Model loaded successfully
2025-03-10 12:16:15,180 - INFO - Model moved to device: cuda
2025-03-10 12:16:15,181 - INFO - Model set to eval mode
2025-03-10 12:16:15,245 - INFO - Model converted to half precision with all tensors and buffers checked
2025-03-10 12:16:15,246 - INFO - Created new instance of rmbg2
2025-03-10 12:16:15,354 - INFO - Model memory format: True
2025-03-10 12:16:15,377 - INFO - After preprocess - tensor dtype: torch.float16, device: cuda:0
2025-03-10 12:16:15,377 - INFO - Tensor requires grad: False
2025-03-10 12:16:15,377 - INFO - Tensor memory format: True
2025-03-10 12:16:15,378 - INFO - Final tensor stats - dtype: torch.float16, shape: torch.Size([1, 3, 1024, 1024]), device: cuda:0
2025-03-10 12:16:15,378 - INFO - Predict input tensor dtype: torch.float16
2025-03-10 12:16:15,379 - INFO - After explicit half conversion dtype: torch.float16
2025-03-10 12:16:17,782 - INFO - Successfully processed signal-2023-02-04-212737.jpeg in 6.49s
2025-03-10 12:16:17,838 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 6.55s
2025-03-10 12:19:58,460 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-10 14:12:28,031 - INFO - Method: GET Path: / Status: 200 Duration: 0.01s
2025-03-10 14:12:28,879 - INFO - Method: GET Path: /favicon.ico Status: 404 Duration: 0.00s
2025-03-10 14:12:29,772 - INFO - Method: GET Path: /sitemap.xml Status: 404 Duration: 0.00s
2025-03-10 14:12:30,727 - INFO - Method: GET Path: /robots.txt Status: 404 Duration: 0.00s
2025-03-10 18:59:43,747 - INFO - Method: GET Path: / Status: 200 Duration: 0.02s
2025-03-17 15:36:48,799 - INFO - Python version: 3.12.2
2025-03-17 15:36:48,801 - INFO - PyTorch version: 2.6.0+cu124
2025-03-17 15:36:48,801 - INFO - CUDA available: True
2025-03-17 15:36:48,801 - INFO - CUDA version: 12.4
2025-03-17 15:36:48,802 - INFO - Number of CUDA devices: 1
2025-03-17 15:36:48,812 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-03-17 15:36:48,812 - INFO -   Memory: 8.00GB
2025-03-17 15:36:48,813 - INFO -   CUDA Capability: 8.6
2025-03-17 15:36:49,029 - INFO - CUDA test successful - tensor operation completed
2025-03-17 15:36:49,030 - INFO - Final device selection: cuda
2025-03-17 15:36:49,680 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-17 15:36:49,684 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-17 15:36:59,637 - INFO - Model configuration: Config {
  "IoU_finetune_last_epochs": -50,
  "SDPA_enabled": false,
  "auxiliary_classification": false,
  "batch_size": 4,
  "batch_size_valid": 1,
  "bb": "swin_v1_l",
  "compile": true,
  "cxt": [
    384,
    768,
    1536
  ],
  "cxt_num": 3,
  "data_root_dir": "C:\\Users\\Merres\\datasets/dis",
  "dec_att": "ASPPDeformable",
  "dec_blk": "BasicDecBlk",
  "dec_channels_inter": "fixed",
  "dec_ipt": true,
  "dec_ipt_split": true,
  "device": 0,
  "ender": "",
  "freeze_bb": false,
  "lambda_adv_d": 0.0,
  "lambda_adv_g": 0.0,
  "lambdas_cls": {
    "ce": 5.0
  },
  "lambdas_pix_last": {
    "bce": 30,
    "cnt": 0,
    "iou": 0.5,
    "iou_patch": 0.0,
    "mse": 0,
    "reg": 0,
    "ssim": 10,
    "structure": 0,
    "triplet": 0
  },
  "lat_blk": "BasicLatBlk",
  "lateral_channels_in_collection": [
    3072,
    1536,
    768,
    384
  ],
  "load_all": true,
  "lr": 0.0001,
  "lr_decay_epochs": [
    100000.0
  ],
  "lr_decay_rate": 0.5,
  "model": "BiRefNet",
  "ms_supervision": true,
  "mul_scl_ipt": "cat",
  "num_workers": 4,
  "only_S_MAE": false,
  "optimizer": "AdamW",
  "out_ref": true,
  "precisionHigh": true,
  "preproc_methods": [
    "flip",
    "enhance",
    "rotate",
    "pepper"
  ],
  "progressive_ref": "",
  "prompt4loc": "dense",
  "rand_seed": 7,
  "refine": "",
  "refine_iteration": 1,
  "scale": "",
  "size": 1024,
  "squeeze_block": "BasicDecBlk_x1",
  "sys_home_dir": "C:\\Users\\Merres",
  "task": "DIS5K",
  "training_set": "DIS-TR",
  "transformers_version": "4.35.2",
  "use_fp16": false,
  "verbose_eval": true,
  "weights": {
    "pvt_v2_b0": "C:\\Users\\Merres\\weights\\pvt_v2_b0.pth",
    "pvt_v2_b1": "C:\\Users\\Merres\\weights\\pvt_v2_b1.pth",
    "pvt_v2_b2": "C:\\Users\\Merres\\weights\\pvt_v2_b2.pth",
    "pvt_v2_b5": "C:\\Users\\Merres\\weights\\pvt_v2_b5.pth",
    "swin_v1_b": "C:\\Users\\Merres\\weights\\swin_base_patch4_window12_384_22kto1k.pth",
    "swin_v1_l": "C:\\Users\\Merres\\weights\\swin_large_patch4_window12_384_22kto1k.pth",
    "swin_v1_s": "C:\\Users\\Merres\\weights\\swin_small_patch4_window7_224_22kto1k_finetune.pth",
    "swin_v1_t": "C:\\Users\\Merres\\weights\\swin_tiny_patch4_window7_224_22kto1k_finetune.pth"
  },
  "weights_root_dir": "C:\\Users\\Merres\\weights"
}

2025-03-17 15:36:59,762 - INFO - Created new instance of birefnet
2025-03-17 15:36:59,764 - INFO - Method: POST Path: /models/birefnet/load Status: 200 Duration: 6.07s
2025-03-17 15:36:59,772 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-17 15:37:00,772 - INFO - Processing image: 0_2 (1).jpeg with model: birefnet
2025-03-17 15:37:00,791 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-17 15:37:00,902 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:37:00,902 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-17 15:37:00,905 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:37:07,831 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-17 15:37:08,009 - INFO - Successfully processed 0_2 (1).jpeg in 7.24s
2025-03-17 15:37:08,012 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 7.24s
2025-03-17 15:37:38,477 - INFO - Processing image: 0_1.jpeg with model: birefnet
2025-03-17 15:37:38,477 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-17 15:37:38,494 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:37:38,494 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-17 15:37:38,496 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:37:39,902 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-17 15:37:40,080 - INFO - Successfully processed 0_1.jpeg in 1.60s
2025-03-17 15:37:40,083 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.61s
2025-03-17 15:37:58,753 - INFO - Processing image: 0_2.jpeg with model: birefnet
2025-03-17 15:37:58,754 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-17 15:37:58,767 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:37:58,767 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-17 15:37:58,773 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:38:00,242 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-17 15:38:00,365 - INFO - Successfully processed 0_2.jpeg in 1.61s
2025-03-17 15:38:00,368 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.62s
2025-03-17 15:38:57,946 - INFO - Processing image: 0_2 (2).jpeg with model: birefnet
2025-03-17 15:38:57,948 - INFO - Original image size: (1024, 1024), mode: RGB
2025-03-17 15:38:57,966 - INFO - Preprocessed tensor shape: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:38:57,966 - INFO - Tensor device: cpu, dtype: torch.float32
2025-03-17 15:38:57,970 - INFO - Input tensor shape before prediction: torch.Size([1, 3, 1024, 1024])
2025-03-17 15:38:59,374 - INFO - Prediction successful, output shape: torch.Size([1, 1, 1024, 1024])
2025-03-17 15:38:59,568 - INFO - Successfully processed 0_2 (2).jpeg in 1.62s
2025-03-17 15:38:59,570 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 1.63s
2025-03-17 15:39:07,581 - INFO - Created new instance of ben2
2025-03-17 15:39:07,582 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 2.44s
2025-03-17 15:39:07,595 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-03-17 15:39:12,236 - INFO - Processing image: 0_2 (2).jpeg with model: ben2
2025-03-17 15:39:15,478 - INFO - Successfully processed 0_2 (2).jpeg in 3.24s
2025-03-17 15:39:15,481 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 3.25s
2025-03-17 15:44:59,532 - INFO - Processing image: 0_1 (1).jpeg with model: ben2
2025-03-17 15:45:02,720 - INFO - Successfully processed 0_1 (1).jpeg in 3.19s
2025-03-17 15:45:02,723 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 3.19s
2025-04-07 12:56:57,129 - INFO - Python version: 3.12.2
2025-04-07 12:56:57,131 - INFO - PyTorch version: 2.6.0+cu124
2025-04-07 12:56:57,131 - INFO - CUDA available: True
2025-04-07 12:56:57,131 - INFO - CUDA version: 12.4
2025-04-07 12:56:57,132 - INFO - Number of CUDA devices: 1
2025-04-07 12:56:57,141 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-04-07 12:56:57,142 - INFO -   Memory: 8.00GB
2025-04-07 12:56:57,142 - INFO -   CUDA Capability: 8.6
2025-04-07 12:56:57,364 - INFO - CUDA test successful - tensor operation completed
2025-04-07 12:56:57,364 - INFO - Final device selection: cuda
2025-04-07 12:57:20,249 - INFO - Python version: 3.12.2
2025-04-07 12:57:20,250 - INFO - PyTorch version: 2.6.0+cu124
2025-04-07 12:57:20,250 - INFO - CUDA available: True
2025-04-07 12:57:20,251 - INFO - CUDA version: 12.4
2025-04-07 12:57:20,251 - INFO - Number of CUDA devices: 1
2025-04-07 12:57:20,262 - INFO - GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU
2025-04-07 12:57:20,262 - INFO -   Memory: 8.00GB
2025-04-07 12:57:20,262 - INFO -   CUDA Capability: 8.6
2025-04-07 12:57:20,518 - INFO - CUDA test successful - tensor operation completed
2025-04-07 12:57:20,519 - INFO - Final device selection: cuda
2025-04-07 13:00:24,890 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:00:24,907 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:00:32,281 - INFO - Created new instance of ben2
2025-04-07 13:00:32,282 - INFO - Method: POST Path: /models/ben2/load Status: 200 Duration: 4.69s
2025-04-07 13:00:32,290 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:00:37,670 - INFO - Processing image: ChatGPT Image 31. März 2025, 10_32_21.png with model: ben2
2025-04-07 13:00:42,536 - INFO - Successfully processed ChatGPT Image 31. März 2025, 10_32_21.png in 4.87s
2025-04-07 13:00:42,538 - INFO - Method: POST Path: /remove-background/ Status: 200 Duration: 4.89s
2025-04-07 13:03:15,854 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:03:15,860 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:15,596 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:15,725 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:24,558 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:24,564 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:57,164 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:04:57,172 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:47:59,869 - INFO - Method: GET Path: /models Status: 200 Duration: 0.25s
2025-04-07 13:47:59,927 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
2025-04-07 13:48:07,686 - INFO - Method: GET Path: /models Status: 200 Duration: 0.00s
